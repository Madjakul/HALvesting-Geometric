<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Combining Syntax &amp; Ontologies for Information Extraction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Amalia</forename><surname>Todirascu</surname></persName>
							<email>todirasc@loria.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">INRIA Lorraine LORIA</orgName>
								<address>
									<addrLine>Campus scientifique BP 239</addrLine>
									<postCode>54506</postCode>
									<settlement>Vandoeuvre-lès-Nancy Cedex</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Laurent</forename><surname>Romary</surname></persName>
							<email>romary@loria.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">INRIA Lorraine LORIA</orgName>
								<address>
									<addrLine>Campus scientifique BP 239</addrLine>
									<postCode>54506</postCode>
									<settlement>Vandoeuvre-lès-Nancy Cedex</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dalila</forename><surname>Bekhouche</surname></persName>
							<email>bekhouche@loria.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">INRIA Lorraine LORIA</orgName>
								<address>
									<addrLine>Campus scientifique BP 239</addrLine>
									<postCode>54506</postCode>
									<settlement>Vandoeuvre-lès-Nancy Cedex</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Combining Syntax &amp; Ontologies for Information Extraction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">7A21871B97AEAD8F6EB2BD0939072820</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-08-24T15:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents an information extraction system, dedicated to message filtering for a specific domain (security systems). The paper focuses on a method for identifying domain-specific ontology elements (terms and concepts), using syntactic information and an existing domain ontology. The domain ontology is represented using description logics. The system uses description logics inference mechanisms to validate the candidate concepts.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Information Extraction applications identify relevant entities in texts, for a given domain. They use shallow natural language processing techniques for identifying relevant data, and, in some cases, domain-specific knowledge to validate these entities. Most IE systems lack portability due to language-dependent linguistic resources and domain-dependent knowledge.</p><p>The IE systems' portability depends on the domain model (ontology) portability. Predefined or fixed ontologies are often incomplete and the costs of adapting them to another domain or application are enormous. Existing ontologies, like WordNet <ref type="bibr" target="#b14">(Miller et al., 1990)</ref> and Corelex <ref type="bibr" target="#b4">(Buitelaar, 1998)</ref>, are useful for IE application on free texts but they do not contain domain-specific senses.</p><p>IE systems' portability might be increased using semiautomatically extracted ontologies. Several methods of extending existing ontologies have been proposed: statistical methods <ref type="bibr" target="#b8">(Daille, 1996)</ref>, as well as methods using logical inferences <ref type="bibr" target="#b20">(Vilain, 1999)</ref>. We used an inference-based method for extending ontologies to improve our system's portability.</p><p>Due to large amounts of processed texts, most IE systems propose candidate concepts among the noun phrases, noun-noun collocations <ref type="bibr" target="#b10">(Heid, 2000)</ref>, applying shallow Natural Language Processing (NLP) techniques: finite-state methods <ref type="bibr" target="#b6">(Chanod, 1999)</ref> and simple pattern matching <ref type="bibr" target="#b8">(Daille, 1996;</ref><ref type="bibr" target="#b16">Riloff et al., 1999)</ref>. Some systems use domain-specific patterns to build a semantic representation from the syntactic structures <ref type="bibr" target="#b17">(Riloff et al., 1997)</ref>. Other methods extract domain-specific morphemes to filter the noun-to-noun and noun-to-adjective collocations <ref type="bibr" target="#b10">(Heid, 2000)</ref>. Special named entity recognisers have been proposed <ref type="bibr" target="#b7">(Cunningham et al., 1996)</ref>.</p><p>Most IE tools are highly language-dependent. It is difficult to adapt them for another language or domain. For this reason, we use linguistic tools and resources which are highly modular and which could be parameterized (the Lexical Tree Adjoining Grammar parser <ref type="bibr" target="#b13">(Lopez, 1999)</ref>), for identifying candidate concepts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Goal of the paper</head><p>The main goal of the paper is to present a methodology for extending a domain ontology with new concepts extracted from text. The paper focuses on the interface between syntax and semantics, in the context of a specific domain.</p><p>The method we propose uses partial syntactic structures provided by a Lexical Tree Adjoining Grammars (LTAG) parser to identify candidate concepts, as well as logical inferences from Description Logics, for knowledge representation. The method is tested with a specific application for filtering electronic messages about computer security problems. The corpus contains various errors (spelling, syntactic), wrong segmentations and computer commands. Due to these properties, a concept instance identification method based on partial parsing results is required for this corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The architecture</head><p>The methodology proposed includes several steps in order to identify the key elements of the ontology: the concept instances, the relations between the concepts and the relations between the instances and the concepts. Concepts instances are identified among the results of partial parsing, while relations between concepts and between instances and the concepts requires domainspecific resources.</p><p>The system includes several modules for identifying domain concepts: the LTAG parser, the module handling the domain ontology and a module linking the syntax and semantics. The semantic representations, built from the syntactic structures and from some domain-specific resources (the semantic lexicon), will be validated by the domain ontology.</p><p>For our specific application, we developed modules for extracting lexicons or other resources from reference corpora (see figure <ref type="figure">1</ref>). The reference corpus is used, together with the LTAG grammar and lexicon, to create a domain-specific lexicon (containing syntactic information). The corpus is also used by the human expert for designing the ontology.</p><p>We also built a module assigning concepts to each word, as well as assigning conceptual descriptions to grammar trees. The domain-specific lexicon is used by the LTAG parser to identify potential concept instances, among simple noun phrases and verbs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Ontologies</head><p>Domain knowledge is a key element in an information extraction system. It is used to validate the entities identified in the texts. Existing generic ontologies (WordNet <ref type="bibr" target="#b14">(Miller et al., 1990)</ref>, Corelex (Buitelaar 1998)) are useful for providing synonyms if the application is designed for free texts. Domain-specific ontologies often contain specific senses that would not be found in a general-purpose ontology.</p><p>To avoid the main drawback of domain-specific ontology, the low portability, statistical-based and inference-based methods for automatically extracting ontologies have been proposed. The methods identify candidate terms in texts, create classes of similar terms and identify relations between these classes.</p><p>Statistical methods group terms with similar contexts into classes associated with a unique concept <ref type="bibr" target="#b1">(Assadi et al., 2000)</ref>, <ref type="bibr" target="#b8">(Daille, 1996)</ref>. Relations between various classes are identified by interpreting syntactic structures <ref type="bibr" target="#b5">(Capponi et al., 2000)</ref> or using statistical information <ref type="bibr" target="#b4">(Bouaud et al, 2000)</ref>. Statistical methods require large, stable, training corpora to extract the classes, as well as human experts for validating and interpreting the results.</p><p>Figure <ref type="figure">1</ref>. System architecture Inference-based methods use semi-automatic methods to check the validity of the existing knowledge. New concepts, deduced by inference rules, are added to the domain hierarchy if they are coherent with the existing knowledge <ref type="bibr" target="#b19">(Todirascu, 2001)</ref>. Relations are identified using syntactic knowledge, as subcategorisation <ref type="bibr" target="#b5">(Capponi et al., 2000)</ref>. Concept overgeneration and the cost of checking knowledge incoherence and inconsistency are the main drawbacks of these approaches. Several formalisms have been proposed to avoid these problems, and among them description logics are very promising for representing domain knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Description Logics</head><p>Description Logics are knowledge representation formalisms derived from semantic nets, that provide welldefined syntax and semantics. They also have features of object-oriented systems, frame-based systems and modal logics.</p><p>DLs provide a hierarchical organization of knowledge structuring it on a conceptual level (the T-Box), describing abstract classes of objects relevant for domain modeling, and an assertional level (the A-Box), containing the instances of the classes. The classes of objects (concepts) are described by their relations (named roles) with other concepts and their attributes (roles with atomic values).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1.">Syntax and Semantics</head><p>The DL operators are inspired by first order logics: Table <ref type="table">1</ref>: The DL operators Using all these operators, or only a part of them, we define our knowledge items: the definition of concepts and roles ALC (Attributive Language with Complements) (using atomic concept names and roles, the SOME, ALL, AND, OR, NOT operators, concept axioms), the possibility of handling transitive roles (R+), of inverse roles (I), of role hierarchy (H), of attributes (f) or numeric constraints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DL</head><p>A few examples of the DL commands are given below. CN is a concept name, C is a conceptual description (any combination of AND, SOME, NOT, ALL operators). The DL commands are KRSS-like <ref type="bibr" target="#b15">(Patel-Schneider et Swartout, 1993)</ref>, <ref type="bibr" target="#b2">(Baader et Hollunder, 1991</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input text</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Entities Conceptual representations</head><p>3) (implies C1 C2) -introduces a new concept axiom, defining necessary conditions C1 for the conceptual description C2; DLs are deterministic fragments of first order logics. They provide decidable algorithms for coherence and consistency checking. DLs propose logical mechanisms to identify concept subsumption, instance retrieval and role paths relating concepts. Classification is a partial ordering of the concept hierarchy due to the subsumption relation.</p><p>Some example of commands (using KRSS-like <ref type="bibr">(Baader &amp; all, 1991)</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Description Logics for IE Systems</head><p>The role of domain knowledge in an IE system is to validate the semantic representation of the potentially relevant entities identified in the text using NLP techniques. These entities could be used for adding new concepts to the existing ontology. Most IE systems use shallow NLP techniques and some candidate entities might not have a valid semantic interpretation. IE systems might use some implicit knowledge, the case of hyponymy/hyperonymy relations being just an example.</p><p>Unlike frame-based systems, DLs deal with semistructured or incomplete data. There is no requirement to explicitly define some values as concept instances. Unlike frame-based systems, default values are not used by DLs. Some role fillers are left unspecified as in the following example.</p><p>(define-concept Administrator (and Person (some hasHandleType OSystem) (some hasName Name))) (define-primitive-concept Name) (define-primitive-concept OSystem) (instance harry1 (and Administrator (some hasHandleType Linux)))</p><p>In this example, we illustrate that implicit definitions are supported by DLs (Linux is not defined explicitly as an instance or a subconcept of the concept OSystem). The filler of the role hasName is not provided.</p><p>These properties are interesting for our application, while errors are possible, and the domain knowledge is incomplete.</p><p>Hyperonymy or hyponymy are handled by subsumptions between domain concepts. For example, if a candidate concept is identified in the text as (instance x (and PC (some hasOperatingSystem Linux))) (define-concept PCcomputer (and computer (some hasType PC)))</p><p>x is also an instance of the concept computer.</p><p>(instance y (and File (some hasOwner Root))) (define-concept File (and Object (some hasName Name) (some hasPartOf OSystem) (some hasOwner User))) (define-concept Root (and User (some hasRight ilimited)))</p><p>y is an instance of the concept File and it is related to the concept Root, which is also a User.</p><p>Semantic networks or frame-based systems provide hyponymy/hyperonymy handling, but the possibility of expressing negations is an argument in the favor of using description logics as knowledge representation. However, the interpretation of negation as the complement of the concept is not always very useful in a NLP application.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Functionalities</head><p>To choose the best DL classifier for our application, we identify precisely the functionalities that we require for representing knowledge.</p><p>We need to define concepts, roles and attributes to describe domain ontology. This is a feature, as well as axiom definitions, provided by all existing DL systems. Transitive roles are necessary in computing path roles between various concepts. Inverse roles must be avoided due to cyclical definitions which makes computing processes undecidable.</p><p>The input text contains proper nouns, data, person and organization names, which are represented in Description Logics as instances. Reasoning with instances is a necessary feature. We chose RACER <ref type="bibr" target="#b11">(Haarslev, Muller, 2001)</ref>, which is one of the few classifiers featuring such reasoning. It also has an XML-like representation of the ontology. Our aim is to build portable ontologies, and we intend to adopt a standard format for ontology representationthe Ontology Inference Layer (OIL) <ref type="bibr" target="#b9">(Fensel et al., 2000)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1.">The Ontology</head><p>The ontology is designed by a human expert. From the reference corpus, the human expert extracts a list of the most frequent words, except the functional words (the determiners, the pronouns, the auxiliaries). The list of nouns and verbs (considered as main candidates to identify primitive concepts) are evaluated by the human expert who assigns to each word a number (5-very relevant, 1-not very relevant) representing relevance of the word to the security domain. Some examples of words and their relevance:  <ref type="table">3</ref>: Verbs and their relevance to domain From these words, the experts created a set of 35 primitive concepts and a set of concept axioms and roles. The concept candidates are added to the ontology if the ontology coherence is not violated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Verb</head><p>The human expert also selects concept instances (the terms which are associated with each primitive concept). The expert asks the Racer classifier to test the coherence of the knowledge base.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">NLP tools and resources</head><p>This section presents a short description of NLP resources and tools, as well as of the small ontology used for our application. The system is still under development. We developed the various NLP tools and resources, the modules extracting the lexicons and we built the initial ontology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">The Resources</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1.">The Reference corpus</head><p>The reference corpus used for generating the lexicon and for creating the ontology is a collection of phrases extracted from e-mail messages. It contains about 50,000 tokens (4039 word forms). The list of the most significant words, used also to design the domain concept hierarchy, was extracted from this reference corpus.</p><p>The corpus contains a lot of abbreviations, organization, system, program and function names (UNIX functions, constants, variable names), patterns introducing the content of a dialogue ("X wrote:"), DOS or UNIX commands, which require special preprocessing modules using finite state automata designed for entity recognition.</p><p>The corpus contains syntax or spelling errors, so we applied robust, fault-tolerant, shallow NLP techniques for identifying potential concept instances. Another major problem of the corpus is that the sentences are not very well delimited, which is one of the sources of tagging errors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2.">The lexicon</head><p>We used the reference corpus for building a lexicon. The lexicon is encoded using a subset of XML dedicated to represent TAG grammars: TAGML (Tree Adjoining Grammar Markup Language) <ref type="bibr" target="#b3">(Bonhomme et al., 2000)</ref>. The English LTAG lexicon (511 lexicon entries), available in TAGML format, was incomplete for our security domain. We built a module that semiautomatically created the lexicon from the reference corpus and from the existing English lexicon. For this, we used the TreeTagger POS tagger <ref type="bibr" target="#b18">(Schmid, 1994)</ref>, which annotates words with their lexical category and extracts the lemmas. Noun and adjective entries are generated automatically from the existing lexicon. Verbs must be added manually.</p><p>The list of POS tags provided by the TreeTagger is compatible with the lexical categories encoded into the lexicon.</p><p>The POS-tagging results must be validated by a human expert. We detected a set of errors including: spelling errors, POS tagging errors due to bad sentence construction and Unix commands (which must be preprocessed by a separate module) which must be deleted from the list of entries:  The resulting lexicon has 3000 entries, distributed as follows: 1400 nouns, 787 adjectives, 300 verbs, 105 prepositions and 379 adverbs. The lexicon also contains a set of syntagms ("one of", "kind of", "number of").</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.3.">The grammar</head><p>The initial English LTAG grammar <ref type="bibr" target="#b12">(Joshi, 1987</ref>) contains about 420 elementary trees. The grammar is represented, as the lexicon is, in TAGML format. We concentrate at this stage on simple noun phrases (without relative clauses) and simple verb phrases, which will be the candidate concepts.</p><p>LTAG grammars have an interesting property, making them suitable for our application: the extended domain locality. It creates a context of each word, formed by a set of elementary trees. This property is used to avoid some candidate trees and to select a small subgrammar.</p><p>The local grammar built for this application consists of the noun phrase trees (trees associated with nouns, nouns and adjectives that might modify nouns, past participle verbs playing the role of the modifiers, comparative adverbs and adjectives), proper nouns and prepositions relating two nouns. We do not yet include verb trees handling long-distance dependency trees or relative clauses in the local grammar.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">The parser</head><p>The parser we use is a current version of <ref type="bibr">Lopez's parser (1999)</ref> that is modular and supports TAGML-like input and output. We chose this parser due to its ability to produce partial parsing results, and due to the existing TAG grammars (being available in TAGML format for French and for English). It is able to identify candidate terms, even if an error (e.g. syntactic or spelling) occurs. It is implemented in Java. The parser loads only a part of the lexicon and of the grammar (the entries associated with the current sentence).</p><p>TAG parsers combine the set of elementary trees associated with input words, using two operations: adjunction and substitution. TAG parsers produce as output a set of derived trees (which represent the syntactic structures identified in the text) as well as a set of derivation trees. Derivation trees are usually used to generate a dependency tree: a semantic representation. TAG parsing provides a large set of derived and derivation trees. The derivation trees are used to create a semantic representation and this representation is validated by the domain ontology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Linking syntax and domain ontology</head><p>This section presents in detail the relations between ontology concepts and roles to lexicons, grammars and parsing output. The interface between syntax and semantics consists of a list of pairs (lemma, concept), a set of conceptual descriptions built for each Elementary tree and an algorithm building conceptual descriptions from derivation trees.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">The Semantic Lexicon</head><p>The LTAG lexicon entries contain references to lemmas associated with the current word, and each lemma is associated with a set of elementary trees and coanchors. While each lemma might be associated with a different sense, we should obviously associate a different concept with each lemma.</p><p>Nouns are associated with one or several domain concepts. They are also associated with an entry describing the situation of a noun playing the role of a modifier. In this case the semantic description is a DL formula as (some hasMod Concept). Adjectives might be modifiers, but could also be predicative (and the DL representation is similar to verbal entries).</p><p>The verbs are associated with the concept and have some constraints on their arguments' type.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Example.</head><p>-for the noun 'system': &lt;sem concept="system" lemma="system"/&gt; -for the adjective 'main': &lt;sem concept="(some hasMod main)" lemma="main"/&gt; -for the verb 'connect': &lt;sem concept="connect" lemma="connect"&gt; &lt;constr arg0="Substitution" address = "1"/&gt; &lt;constr arg1="Substitution" address = "3"/&gt; &lt;/sem&gt; Some lexicon entries are highly ambiguous: prepositions might represent several domain-specific relations or general relations (type, possession). For example, the preposition 'of' could be represented as: &lt;sem concept="(some hasType)" lemma="of"/&gt; &lt;sem concept="(some hasPoss)" lemma="of"/&gt; If we define a function Sem taking as argument a lemma and returning a DL concept as a value:</p><formula xml:id="formula_0">Sem(lemma)=Concept  Constraint1  …  ConstraintJ</formula><p>The concepts will be associated with words using a method similar to <ref type="bibr">(Riloff et Sheperd, 1997)</ref>, starting from a set of seed words and concepts (words extracted from the list of the most relevant words).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Elementary Trees</head><p>The elementary trees are related to the lemmas associated with each word. The semantic representation associated with each lemma is a primary concept and a set of constraints. We define an algorithm building a DL conceptual description for each elementary tree and the lemma associated to it.</p><p>Sem(ElementaryTree) = Sem(lemma), if no substitution or adjunction is found in the tree;</p><p>Sem(ElementaryTree) = (and Sem(lemma) (some hasSubstitution A))  (implies (some hasSubstition A) (some argi A)), if a substitution is found in the tree and A is a generic concept.</p><p>Sem(ElementaryTree) = (some hasAdjunction Sem(lemma)).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">Derivation Trees</head><p>The derivation tree encodes all the operations (substitution, adjunction) applied for building a tree from elementary trees and other derivation trees. We define an algorithm for extracting complex representations from derivation trees. where Sem(A), Sem(B) and Sem(C) are defined recursively, if B or C are derivation trees, and as in the previous subsection if A is elementary tree. (constraints B) represents the information related to the arguments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.1.">Some Examples</head><p>The phrase "the root passwords" is parsed by the LTAG parser, and the results are two derivation trees (figure <ref type="figure">2</ref> </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>R C x (xRC) there is at least one instance of C related by the relation R D = ALL R C x(xRC) restricts the co-domain of the relation least n objects of the concept C in relation R with D</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>):1) (define-concept CN C) -defines a new concept as a conceptual description;2) (instance IN C) -defines an instance of a given concept;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>syntax) are: (concept-subsumes? C1 C2) tests if C1 subsumes C2 (concept-parents C) retrieves the direct ancestors of the concept C (concept-children C) retrieves the children of C (classify-tbox) computes all the subsumption relations between all the concepts defined in the T-Box (concept-instances C) retrieves the instances of the concept C</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Figure 1. A derivation tree where A, B and C are also elementary or derivation tree The algorithm building the DL representation for the tree from the fig. 1: Sem(Tree) = (and Sem(A) (Some hasSubstitution Sem(B)) Sem(C))  (constraints B)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Fig. 2 Derivation trees for "the root password"</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>The results of POS tagging and tagging errors</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgements. Amalia Todirascu worked on this project as a post-doctoral fellowship in LORIA, sponsored by the European Research Consortium for Informatics and Mathematics (ERCIM) group.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Sem(1) = (and Password (some hasMod Root)(some hasDef definite))</p><p>Sem(2) = (and Password (some hasMod (and Root (some hasDef definite))))</p><p>The phrase "The hacker connected to the server" results into the following derivation trees (fig. <ref type="figure">3</ref>).</p><p>The conceptual descriptions associated with each lemma are:</p><p>Sem(connected_to) = Connect  (implies (some hasSubst A) (some arg0 A))  (implies (some hasSubst B))</p><p>Sem(hacker) = Hacker Sem(server) = Server Sem(the) = (some hasDefine Defined)</p><p>Fig. <ref type="figure">3</ref> Derivation trees for "the hacker connected to the server"</p><p>The representations of the trees substituted to the elementary tree anchored by 'connected' are:</p><p>(and Hacker (some hasDefine Defined)) (and Server (some hasDefine Defined))</p><p>The representation associated with the elementary tree anchored by 'connected' is the set of axioms:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(and Connect (some hasSubst A)(some hasSubst B)) (implies (some hasSubst A)(some arg0 A)) (implies (some hasSubst B)(some arg1 B))</head><p>In the derivation tree we found the values for A and B:</p><p>(implies A (and hacker (some hasDefine Defined))) (implies B (and server (some hasDefine Defined)))</p><p>The concept associated with the derivation tree:</p><p>(and Connect (some arg0 (and hacker (some hasDefine Defined))) (some arg1 (and server (some hasDefine Defined))))</p><p>is satisfiable by the existing knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Extending the ontology</head><p>We use the results of partial parsing to identify a set of relevant entities. Some of them might be added to the existing ontology, after a human expert validates them.</p><p>The corpus contains a lot of errors and a complete parsing will never result in a correct syntactic structure.</p><p>Example from corpus:</p><p>Remains the question how are you going to run DOS programs if the first thing that the computer does after the password protected BIOS is coming up with a lilo prompt for a password ?</p><p>The entities identified in the text are : run, DOS, the first thing, the computer, the password protected BIOS, a lilo prompt for a password.</p><p>We obtained the following conceptual descriptions:</p><p>(and run (some has arg1 (and program (some hasType DOS)))) (and computer (some hasdef Definite)) (and entity (some hasname BIOS) (some hasProp (and password (some hasType protected) (some hasdef definite))) (and prompt (some hasType lilo) (some hasdef indefinite) (some hasPurpose (and password (some hasdef indefinite))))</p><p>These representation are validated by the existing ontology. We might add a new concept run with an argument restricted to the type program.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Conclusion and further work</head><p>The paper presents a methodology for extracting concepts from texts, using partial syntactic analysis and domain knowledge. It focuses on the relation between the syntax and the domain-specific knowledge, in order to build candidate concepts for the domain ontology. We intend to use a meta-grammar for generating automatically the elementary trees. We will extend this meta-grammar to generate conceptual descriptions together with the elementary trees. We will also develop a method for generating verbs lexicon entries automatically.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Analyse syntaxique et statistique pour la construction d&apos;ontologies à partir des textes</title>
		<author>
			<persName><forename type="first">H</forename><surname>Assadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bourigault</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Ingénierie des connaissances -Evolutions récentes et nouveaux défis</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Charlet</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Zacklad</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Kassel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Bourigault</surname></persName>
		</editor>
		<imprint>
			<publisher>Eyrolles Publishing House</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="243" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A Terminological Knowledge Representation Systems with Complete Inference Algorithms</title>
		<author>
			<persName><forename type="first">F</forename><surname>Baader</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hollunder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Processing Declarative Knowledge</title>
		<meeting>the Workshop on Processing Declarative Knowledge</meeting>
		<imprint>
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">TAGML: XML encoding of Resources for Lexicalized Tree Adjoining Grammars</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bonhomme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lopez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC 2000</title>
		<meeting>LREC 2000<address><addrLine>Athens</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Regroupements issus de dépendances syntaxiques sur un corpus de spécialité: catégorisation et confrontation à deux conceptualisations du domaine</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bouaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Habert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nazarenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Zweigenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Buitelaar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Ingénierie des connaissances -Evolutions récentes et nouveaux défis</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Charlet</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Zacklad</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Kassel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Bourigault</surname></persName>
		</editor>
		<imprint>
			<publisher>Eyrolles Publishing House</publisher>
			<date type="published" when="1998">2000. 1998</date>
			<biblScope unit="page" from="243" to="256" />
		</imprint>
		<respStmt>
			<orgName>Brandeis University, Department of Computer Science</orgName>
		</respStmt>
	</monogr>
	<note>CORELEX: Systematic Polysemy and Underspecification. Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Interprétation de classes de termes par généralisation de structures prédicatargument</title>
		<author>
			<persName><forename type="first">N</forename><surname>Capponi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Toussaint</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Ingénierie des connaissances -Evolutions récentes et nouveaux défis</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Charlet</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Zacklad</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Kassel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Bourigault</surname></persName>
		</editor>
		<imprint>
			<publisher>Eyrolles Publishing House</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="337" to="356" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Natural Language Processing and Digital Libraries</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Chanod</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information Extraction</title>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Pazienza</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">1714</biblScope>
			<biblScope unit="page" from="17" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">New Methods, Current Trends and Software Infrastructure for NLP</title>
		<author>
			<persName><forename type="first">H</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wilks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Gaizauskas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the conference on New Methods in Natural Language Processing</title>
		<meeting>the conference on New Methods in Natural Language Processing<address><addrLine>Turkey</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996">1996. 1996</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
		<respStmt>
			<orgName>Bilkent University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Study and Implementation of Combined Techniques for Automatic Extraction of Terminology</title>
		<author>
			<persName><forename type="first">B</forename><surname>Daille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Balancing Act -Combining Symbolic and Statistical Approaches to Language</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Klavans</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Resnik</surname></persName>
		</editor>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="49" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">OIL in a nutshell</title>
		<author>
			<persName><forename type="first">D</forename><surname>Fensel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Knowledge Acquisition, Modeling, and Management, Proceedings of the European Knowledge Acquisition Conference (EKAW-2000)</title>
		<title level="s">Lecture Notes in Artificial Intelligence</title>
		<editor>
			<persName><forename type="first">R</forename><surname>Dieng</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">LNAI</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A linguistic bootstrapping approach to the extraction of term candidates from German text</title>
		<author>
			<persName><forename type="first">U</forename><surname>Heid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Terminology</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="161" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Description of the RACER System and its Applications</title>
		<author>
			<persName><forename type="first">V</forename><surname>Haarslev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Muller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Workshop on Description Logics (DL-2001)</title>
		<meeting>the International Workshop on Description Logics (DL-2001)<address><addrLine>Stanford, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-08">2001. August 2001</date>
			<biblScope unit="page" from="132" to="141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">An Introduction to Tree Adjoining Grammars</title>
		<author>
			<persName><forename type="first">A</forename><surname>Joshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mathematics of Language</title>
		<meeting><address><addrLine>Amsterdam/Philadelphia</addrLine></address></meeting>
		<imprint>
			<publisher>John Benjamins Publishing</publisher>
			<date type="published" when="1987">1987</date>
			<biblScope unit="page" from="87" to="115" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Robust Parsing with Lexicalized Tree Adjoining Grammars</title>
		<author>
			<persName><forename type="first">P</forename><surname>Lopez</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<pubPlace>Nancy, France</pubPlace>
		</imprint>
		<respStmt>
			<orgName>INRIA</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D.Thesis</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Introduction to WordNet: An On-Line Lexical Database</title>
		<author>
			<persName><forename type="first">G</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Beckwith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fellbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Lexicography</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="302" to="312" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Description logic specification from the KRSS effort</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Patel-Schneider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Swartout</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>ARPA Knowledge Sharing Effort Project</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Extraction-based Text Categorization Generating Domain-Specific Role Relationships Automatically</title>
		<author>
			<persName><forename type="first">E</forename><surname>Riloff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lorenzen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Information Retrieval</title>
		<imprint>
			<biblScope unit="page" from="167" to="196" />
			<date type="published" when="1999">1999</date>
			<publisher>Kluwer Academic Publishers</publisher>
		</imprint>
	</monogr>
	<note>In ed. T.Strzalkowski</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A Corpus-Based Approach for Building Semantic Lexicons</title>
		<author>
			<persName><forename type="first">E</forename><surname>Riloff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shepherd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Second Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Probabilistic Part-of-Speech Tagging Using Decision Trees</title>
		<author>
			<persName><forename type="first">H</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on New Methods in Language Processing</title>
		<meeting>the International Conference on New Methods in Language Processing<address><addrLine>Manchester, United Kingdom</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Semantic Indexing for Information Retrieval Systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Todirascu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
		<respStmt>
			<orgName>University Louis Pasteur of Strasbourg</orgName>
		</respStmt>
	</monogr>
	<note>Ph.D. Thesis</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Inferential Information Extraction</title>
		<author>
			<persName><forename type="first">M</forename><surname>Vilain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information Extraction, LNAI 1714</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Pazienza</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="95" to="119" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
