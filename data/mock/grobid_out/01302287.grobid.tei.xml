<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Reference Resolution as a facilitating process towards robust Multimodal Dialogue Management : A Cognitive Grammar Approach</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Ashwani</forename><surname>Kumar</surname></persName>
							<email>ashwani.kumar@loria.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Laboratory LORIA Campus Scientifique</orgName>
								<address>
									<postBox>B.P. 239</postBox>
									<postCode>54506</postCode>
									<settlement>Vandoeuvre-lès-Nancy</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Susanne</forename><surname>Salmon-Alt</surname></persName>
							<email>susanne.alt@loria.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Laboratory LORIA Campus Scientifique</orgName>
								<address>
									<postBox>B.P. 239</postBox>
									<postCode>54506</postCode>
									<settlement>Vandoeuvre-lès-Nancy</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Laurent</forename><surname>Romary</surname></persName>
							<email>laurent.romary@loria.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Laboratory LORIA Campus Scientifique</orgName>
								<address>
									<postBox>B.P. 239</postBox>
									<postCode>54506</postCode>
									<settlement>Vandoeuvre-lès-Nancy</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Reference Resolution as a facilitating process towards robust Multimodal Dialogue Management : A Cognitive Grammar Approach</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">BA9119CBAB7B93D45635DB8F7F6835DA</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-08-24T15:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper tries to fit a novel reference resolution mechanism into a multimodal dialogue system framework. Essentially, our aim is to show that a typical multimodal dialogue system can actually benefit from the cognitive grammar approach that we adopt for reference resolution. The central idea is to construct and update reference and context models in a manner that imparts adequate level of under-specificity to multimodal semantics. Context-independent semantic representations are constructed based upon the surface structure of the referring expressions and syntactic constraints within an utterance. The reference resolution algorithm assimilates these semantic representations into a coherent context model, resulting in the profiling of the intended referent. The resolution model is built upon discursive, perceptual and conceptual cues, thus successfully accounting for multiple modalities and a multi-dimensional application domain model.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The complexity of reference resolution is due, in part, to the variety of referring expressions, including indefinites, definite descriptions, pronominal reference and ellipses or oneanaphora. The problem is aggravated by the apparent variety of mechanisms required to deal with even one of these types of referring expressions. For example, the referent of a definite description may be linked to a prior discourse entity with the same head, associated to a prior entity from which it can be inferred, or extracted from a larger situation <ref type="bibr">(Poesio and Vieira, 1998)</ref>. As a result, much current work on reference centers around pronominal reference (cf. Centering Theory: <ref type="bibr" target="#b13">Grosz et al., 1995;</ref><ref type="bibr" target="#b21">McCoy and Strube, 1999)</ref>. The treatment of other types of referring expressions is often seen as an extension of or variation on the basic coreferential mechanism (DRT and it extensions: <ref type="bibr" target="#b16">Kamp and Reyle, 1993;</ref><ref type="bibr" target="#b3">Bos et al., 1995)</ref>.</p><p>Additionally, the interpretation of referring expressions is based on both discourse and perceptive context. For example, "another one" cannot be understood without previous discourse mention of, let's say "a romantic song". The need of perceptive information is evident for expressions like "the last two song writers" referring to a list displayed on a screen. What we need then is a unified framework to represent and update dynamically the information provided by both discourse and perceptive context and to constrain the access to this information. DRT, for example, provides access to all previously mentioned entities, while Centering Theory considers the previous discourse unit only. On the other hand, within the list of identified potential referents, Centering Theory provides a precise account of relative salience, whereas DRT specifies only general syntactic constraints to narrow the list. Some recent models attempt to apply more precise selectional criteria to global discourse <ref type="bibr" target="#b2">(Asher, 1993;</ref><ref type="bibr" target="#b14">Hahn and Strube, 1997)</ref>. However, all rely on some prior segmentation, implicitly assuming that discourse structure informs reference resolution, and ignoring the possibility of determining structure based on referential devices or on perceptive information.</p><p>Finally, we notice a gap between the predictions made by approaches in analysis and the generation of referring expressions. In an example like "Select a song and play it / the song", DRT-like models do not predict any difference between pronominal and nominal anaphora whereas a generation model based on <ref type="bibr">Dale and Reiter (Dale, 1992;</ref><ref type="bibr" target="#b10">Dale and Reiter, 1996)</ref> would largely prefer the pronoun. For all these reasons, we concentrate on a model for reference resolution that attempts to overcome the diversity of resolution mechanisms. It is based on the fundamental assumption that all reference (independent of the type of referring expression) is accomplished via access to and restructuring of Reference Domains (RD) rather than by direct linkage to the entities themselves. It includes the same updating mechanisms for both discourse and perceptive information and is intended to be predictive in both language analysis and language generation -a particularly important feature for a model to be integrated into a dialogue system framework.</p><p>There have been efforts towards characterizing relationship between referential and discourse structures <ref type="bibr" target="#b27">(Schauer, 2000;</ref><ref type="bibr" target="#b28">Seville, 1999)</ref>. However, there does not seem to be much work on how the reference model could be used for robust multimodal dialogue processing. In this paper, we advocate a model which closely hinges the dialogue model on the reference model. The rest of the paper is structured as follows. The MIAMM framework is briefly described in Section 2. Section 3 describes the basic cognitive grammar hypothesis that we incorporate in our reference model. Section 4 describes our reference and dialogue framework in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">MIAMM Framework</head><p>The main objective of the MIAMM 1 project <ref type="bibr" target="#b24">(Reithinger et al., 2002)</ref> is to provide an integrated and comprehensive framework (cf. Figure <ref type="figure">1</ref>) for the design of modular multimodal dialogue systems that allow fast and natural access to multidimensional application databases.</p><p>1 www.miamm.org</p><p>The MIAMM emulator integrates a speech interface with a graphic interface, which consists of haptic-tactile buttons and a visual display. The user can interact with the device using speech and/or the haptic buttons to search, select and play tunes from an underlying musical database</p><p>The application domain model, MiaDoMo realizes an intelligent uniform interface between the dialogue module and the various musical databases to be accessed for content selection. Requests could be as simple as "some country music" or as complex as "the soprano-alto duet piece by Charpentier" or "some Mozart-style happy orchestral music". Essentially, the domain model is multidimensional in the sense that the application objects can have associated attributes along multiple discrete, as well as continuous dimensions. For example, information related to a musical band can be stored in the form of discrete dimensions such as band name, member artist names, genre objects. A main task of the visualisation functionality is to make it easy for the user to navigate in the visualisation using speech, pointing and haptic interaction., various albums produced, etc. and/or in the form of continuous dimensions such as temporal duration. Therefore, a query to MiaDoMo results in an information matrix which resides in the dynamic memory of the Visual-Haptic (VisHapTac) processor. The various dimensions of the data model as represented in the information matrix define the visualisation space in which the users can navigate. The restrictions of the display require for condensation and concentration of the visible objects. A main task of the visualization functionality is to make it easy for the user to navigate in the visualization using speech, pointing and haptic interaction.</p><p>The MIAMM framework allows vague and incomplete multimodal inputs as well as information aggravation and re-structuring along various dimensions. Such a complex scenario entails heavy usage of referring expressions, anaphoric as well as deictic. Apart from the common indefinites, definites and demonstratives, bridging expressions such as "the swing", referring to the musical city currently focussed on the map visualization, are quite frequent. At the dialogue level, the multimodal utterances are terse and potentially ambiguous in nature. However, for the sake of simplicity and naturalness, we are mostly concerned with task-oriented mixed-initiative dialogues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">From Cognitive Grammar to Reference Resolution</head><p>Cognitive Grammar <ref type="bibr" target="#b19">(Langacker, 1986</ref><ref type="bibr" target="#b20">(Langacker, , 1991) )</ref> situates linguistic competence within a more general framework of cognitive faculties by assuming that language is neither self-contained, nor describable without reference to cognitive processing. As a fundamental assumption of Cognitive Grammar, sense cannot be represented by logical forms. The first reason is that semantic structures are characterised relative to openended knowledge systems. The second reason is that an expression's meaning cannot be reduced to an objective characterization of the situation described: equally important for semantics is how the speaker chooses to construe the situation. Therefore, Cognitive Grammar assumes conceptual rather than truth-conditional semantics, considering that meaning consists of a process of conceptualisation, i.e. activation of conceptions in a hearer's mind.</p><p>More precisely, the conceptualization of an expression is said to impose a particular image on its domain, where domain is defined as a cognitive structure which is presupposed by the semantics of an expression. As an example, the definite in "Select the first song and play it" presupposes as its domain an ordered set of songs. In MIAMM, this domain could be a visual representation for a list of songs, displayed on the screen.</p><p>The particular image imposed by the expression results in profiling a substructure of the domain, namely that substructure which the expression designates. In the aforementioned example, this would be the part of the list representing the intended referent. As a result of the interpretation process, the profiled subpart of a domain is hypothesized to be more prominent or more activated than the rest of the domain.</p><p>Since an expression is always said to be interpreted within a limited domain, our context model -or multi-modal dialogue history -is built upon the notion of reference domains <ref type="bibr" target="#b26">(Salmon-Alt, 2001)</ref>. These domains are identifying representations for subsets of contextual entities to which it is possible to refer, including individual objects and collections of objects. A first important point is that these domains are not primarily linguistic constructs, since they are created and updated dynamically via discursive information, visual perception, haptic events and conceptual knowledge. The second important characteristic of our domains is that they present the entities from a particular cognitive viewpoint, for which we assume in the following that it is the most likely to be activated for referential access to the entity. In this sense, our model predicts optimal use of referring expressions, whereas fallback strategies can always be applied to failing interpretations. Taking up again the previous example "Select the first song and play it", we will, for instance be able to predict that in this context of an activated domain of songs, a one-anaphora such as "Delete the last one" has to be interpreted preferentially as referring to a song, even if the visual interface displays at the same time, for example, a list of song authors.</p><p>Based on a context modeled by Reference Domains, the interpretation process for referring expressions is seen as an extension of the hypotheses of Cognitive Grammar about the representation of grammatical meaning in terms of abstract symbolic schemas. More precisely, we assume that the semantics of a given expression can be represented by a schema which corresponds to an under-specified reference domain. This under-specified domain is calculated by combining abstract schemas for nouns, modifiers and determiners, taken from a lexical knowledge base.</p><p>The interpretation process consists of two steps:</p><p>1) The under-specified domain has to be matched to suitable RDs from the context model;</p><p>2) A restructuring operation updates the domain by profiling a substructure of the same domain as the referent.</p><p>An interesting point here is the fact that the same mechanism acts for linguistic expressions and for gestures: for example, a pointing gesture to a particular CD cover on the screen highlights this entity as the referent, whereas the other CD covers are considered as the reference domain. In this way, an expression like "Delete the other ones" will then be interpreted as referring to the rest of covers, even if there are other visual elements on the screen, (for example, portraits of song writers).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">From Reference Resolution to</head><p>Dialogue Management</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dialogue Functional Specification</head><p>In line with the Cognitive Grammar hypothesis, we assert that the dialogue functional behavior is essentially guided by the underlying processes which a multimodal system undertakes for input interpretation, fusion, fission and output generation. The system should be able to map the communicative behaviors within a multimodal utterance onto the communicative functions and vice versa <ref type="bibr" target="#b7">(Cassell, 2001)</ref>. This requires specification of how the interpretation or generation of the utterance changes the system's information state such as domain model, discourse model, user model, and task model <ref type="bibr" target="#b5">(Bunt et al., 2002)</ref>.</p><p>The interpretation of a multimodal input, such as a spoken utterance combined with a haptic gesture, will often have stages of modalityspecific processing, resulting in representations of the semantic content of the interactive behavior in each of the separate modalities involved. Other stages of interpretation combine and integrate these representations, and take contextual information into account, such as information from the domain model, the discourse model and the user model. Therefore functionally, the multimodal dialogue strategy ought to be incremental so as to account for lowlevel modality processing as well as high-level unified semantics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Underspecified Semantics</head><p>In MIAMM, we adhere to multi-level approach to semantics. Various modalities and their respective functional behaviors vary significantly as regards to the distribution of semantics across the modality channels. Besides, the modularity constraint within the system architecture (cf.</p><p>Figure <ref type="figure">1</ref>) provides that every module does not have access to every available static or dynamic knowledge resource. Essentially, due to these reasons any conventional ambiguity resolution/multiple hypothesis algorithm <ref type="bibr" target="#b0">(Alexandersson, 2001)</ref> will lead to various possible readings, resulting in the combinatorial explosion problem. Therefore, we resort to the Underspecification (van Deemter and Peters, 1996; Pinkal 1999) approach towards semantic specification. The choice fits perfectly with our integrated framework of reference resolution and incremental dialogue processing as our approach tries to specify the multimodal semantics in a context, which builds up incrementally.</p><p>The context-independent syntactic-semantic representations from SPIN (cf. Figure <ref type="figure">1</ref>) and visualization representations from VisHapTac are encoded in MMIL (MultiModal Interface Language, <ref type="bibr" target="#b25">Romary 2002)</ref>. MMIL serves as the central representation format within the MIAMM architecture as it accounts for the transmission of data between the dialogue manager and both the multi-modal inputs and outputs and the application. It also forms the basis for the content of the dialogue history in MIAMM, both from the point of view of the objects being manipulated and the various events occurring during a dialogue session. MMIL incorporates FOL-type binary predicate-based semantics into a flat XML structure, maintaining two primitive levels of representation -events and participants - <ref type="bibr" target="#b18">(Kumar et al., 2003)</ref>. For example, the underspecified semantic representation for a simple referring expression, "the song" encoded in MMIL, will look like as follows: &lt;participant id = "p1"&gt; &lt;objType&gt;tune&lt;/objType&gt; &lt;individuation&gt;singular&lt;/individuation&gt; &lt;refType&gt;definite&lt;/refType&gt; &lt;refStatus&gt;pending&lt;/refStatus&gt; &lt;/participant&gt;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Specifying Semantics, Incorporating Pragmatics and Resolving References</head><p>There have been various attempts towards characterizing reference resolution models such as coreference model <ref type="bibr" target="#b29">(Tetreault, 2001)</ref>, sense model <ref type="bibr">(Hobbs, 1988)</ref>, extensions model <ref type="bibr" target="#b1">(Allen et al., 1996)</ref>. However, none of these models account for the complete range of reference phenomena found in conversational language. <ref type="bibr" target="#b6">Byron (2002)</ref> construes the ideal resolution model as a mapping from initial referring expression (RE) descriptions to final logical term descriptions. The under-specified representations as described in the previous section resemble the context independent description structures. However, an important distinction is that our aim is not to construct final logical term descriptions. What we are aiming at instead is the maximum<ref type="foot" target="#foot_0">2</ref> possible resolution, which may not always result into final logical forms, at the same time maintaining certain degree of under-specificity as it is necessitated for the continuity of the dialogue progress. For example, the user can command, "play me the pop one", while there exists only jazz tunes in the context. In this case an effort to construct a final logical term for the referring expression "the pop song", would not lead to the desired response from the system. Instead, in such cases of perceptual mismatch, we maintain the level of under-specificity, while informing the Action Planner (AP) about the level of feature mismatch. AP then initiates proper meta-communication with the user, presenting him with the choice to play the jazz tunes. MMIL also has this nice additional feature of percolating lexical information at various levels of processing, which provides for the fall back strategy of lexical semantic specification. Essentially, our algorithm models resolution as a contextual (dynamic) and conceptual (static) mapping from the underspecified RE representations to a maximally specified cognitive description, which in our case are Reference Domains (cf. Figure <ref type="figure" target="#fig_0">2</ref>).</p><p>The semantic representations as introduced in the previous section are assimilated into the typetheoretic models of RDs <ref type="bibr" target="#b26">(Salmon-Alt, 2001)</ref>. These domains are minimally identified by an Id, which serves as a domain index and type, which is extracted from the conceptual hierarchy accessible to the dialogue manager. The important features of a reference domain are its partitions, which reflect the cognitive viewpoint towards the domain. More specifically, these partitions in conjunction with focus and salience criteria define the accessibility criteria for appropriate referent profiling. The partition types are discursive cues such as role properties, perceptual information such as Haptic SelectionStatus, and/or conceptual cues such as domain level information. The data structural representation for RD has the following form: It is important to note here that depending upon the current discursive or perceptual state, there might not exist any partition within a RD. This is crucial so as to limit the accessibility of possible referents, as well as to provide finegrained semantic resolution. During the dialogue progress, if certain partition is rendered out of scope by the resolution algorithm, it is deleted so that it does not lead to wrong extraction of the referent. Similarly, a tune set might not have any partition to begin with. However, by the usage of a discursive trigger like "the one by Madonna", it can be further resolved at the level of artist resulting in a new partition.</p><p>The MultiModalFusion (MMF) component of the Dialogue Module, maintains an incremental dialogue state by constructing under-specified RD representations for the referring expressions within the current utterance and by composing them with the existing context structure. The typical compositional operations are carried upon in the following stages: 1) Grouping: The under-specified RDs within a multimodal utterance are first evaluated for grouping. Based upon discursive triggers such as prepositions, conjunctions, disjunctions and/or perceptual triggers such as haptic gesture resulting in an item selection, RDs are grouped together if they match type, cardinality and temporal proximity constraints. For example, for the utterance "download the one by Madonna and this one + [haptic selection]", to begin with, the interpretation process results in 3 under-specified RDs: first for the definite RE, second for the demonstrative RE and third for the haptic event.</p><p>Using the demonstrative cue and the temporal proximity, the resolution groups 2 nd and 3 rd RD, resulting in a further-specified RD, which is then composed with the 1 st RD owing to the discursive trigger, i.e. the conjunctive and. The grouped RD has zero or one partition depending upon whether the 2 RDs have the same or different artists. It is to be noted that in this particular case the demonstrative is resolved at an early stage while the definite is still pending. 2) Assimilation: Depending upon the type of referring expressions, the context model tries to assimilate the under-specified RDs in differing but coherent ways <ref type="bibr" target="#b26">(Salmon-Alt, 2001;</ref><ref type="bibr" target="#b17">Kumar, 2002)</ref>. Essentially, owing to structural recursiveness and compositional nature, these RDs lead to a directed acyclic graph like context structure. The leaf RDs are at the level of maximum possible resolution at any stage of the dialogue processing. Firstly, a suitable node in the graph is selected. This selection is usually guided by two algorithms: the first one goes through the contextual domains, according to their activation level and starting with the most activated one, while the second one is intended to test the compatibility depending upon type, individuation, partition types etc. Secondly, the intended referent is extracted by profiling the sub-structure, resulting in re-structuring of the domains. For example, within an existing context of a tune list on the graphic display, the reference interpretation process for the speech utterance, " play the third song", would involve finding a node within the context structure representing an RD of tunes and having an index based partition of the member tunes.</p><p>In the following section, we provide a sample dialogue processing illustrating how this reference mechanism is useful for the MIAMM multimodal dialogue system framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Facilitating Dialogue Management</head><p>The following is a typical mixed-initiative dialogue within our framework: To begin with, there exists a multimodal dialogue history for the system's perusal in the form of a stack of context structures, while the discursive and perceptual current context is empty. The definite RE in U[1], "the list" gives rise to an under-specified RD of type /entity-list/ (say, @L1). As @L1 holds predicative relationship with a past event, the reference interpretation algorithm evaluates existing context structures within the dialogue history to assimilate @L1, subject to the identification of a unique RD matching the type and predicative constraints. In this case, the system is able to locate 2 RDs (say @tL1 and @tL2) of type /tunelist/, which is subsumed by the type /entity-list/ in the conceptual hierarchy. Also, these 2 RDs match the predicative relational constraint as imposed on @L1 by U[1]. However, the possible referent is not unique, as it should be for identifying the target referent for a definite RE.</p><p>It is important to note that even though a referring action is intended to accomplish the referential communicative goal <ref type="bibr" target="#b9">(Dale et al., 1995)</ref>, i.e., to help the hearer in identifying the target referent, it might not always lead to the hearer identifying the referent as conceived by the speaker <ref type="bibr" target="#b23">(Poesio et al., 2000)</ref>. This is partly, because each agent involved in a dialogue can have potentially disparate knowledge resources and cognitive descriptions at his disposal. <ref type="bibr" target="#b11">Goodman (1986)</ref> characterizes various possible causes of miscommunication leading to an inappropriate or sub-optimal usage of referring expressions.</p><p>Within a multimodal setting, it is quite natural that miscommunications are frequent as it is strongly coupled to affordances (or rather, misaffordances) of various modalities, as well as to the complexity of the multimodal context. Therefore, in order to impart robustness to any such system, it is imperative that the dialogue progress is incrementally enhanced in a nonmonotonic way. In case of dialogue (1), the system retrieves the tune-lists which are in a predicative relation with any past event occurring /this morning/<ref type="foot" target="#foot_1">3</ref> . The RD @L1 thus obtained, is partitioned along the partition type of /event-Type/. The RD within this partition corresponding to the partTypeValue, /played/<ref type="foot" target="#foot_2">4</ref> is profiled as the possible referent and a list of 2 items is displayed along with an information-seeking speech response. This also brings the sub-structured partition under focus, implying that the objects within this partition are most likely to be referred by the user in the subsequent utterances, provided the dialogue continuity is maintained <ref type="bibr" target="#b4">(Brennan, 2000)</ref>.</p><p>In U[3], the user makes the referring action depending upon which attribute is in his perceptual context i.e. either indexicals such as "the first one", the domain attributes such as "the one by Madonna" or deictic such as [a haptic selection]. While in other scenario, say (2), the user after getting this response from the system, can recognize his mistake, rephrasing his actual request in U[3] as, "No, the one I downloaded".</p><p>Our reference and context model captures these dialogue intricacies in a coherent manner. In the first scenario, the system builds an underspecified RD for the RE, say "the one by Madonna", having /entity/ as type and /Madonna/ as an absolute modifier -a domain attribute. The activated partition of @L1, contains objects which match in type<ref type="foot" target="#foot_3">5</ref> with the under-specified domain. If there exits any tune-list by Madonna within this partition, the partition is further partitioned into a new partition, profiling the RD having Madonna as an artist, as the identified referent and bringing it under focus. In the other scenario, the RD corresponding to the partTypeValue, /downloaded/ is profiled and focussed. Besides, it is also evident that in U[5], the usage of pronominal is the most optimal one, as a pronominal RE marks monotonic dialogue continuity.</p><p>Thus structurally, the notion of reference domains allows transversal as well as horizontal access and update mechanisms. This enables the reference model to mimic the non-monotonic nature of dialogues, resulting into a unified description as provided by multiple modalities at the same time maintaining unified multimodal semantics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>We have outlined a reference resolution mechanism based on the cognitive grammar approach. The discussion is by no means exhaustive and complete owing to space limitations. Besides, our main objective here is to illustrate how this mechanism can be seamlessly integrated into a dialogue framework especially in a multimodal setting. Also, we argue that the particular choice of reference mechanism does have some important implications for dialogue management. In this light, it is agreeable that the reference model can be used towards building and updating dialogue structure <ref type="bibr" target="#b28">(Seville 1999)</ref>. Still, it remains to be seen how this model handles further complicated dialogue issues such as conceptual entrainment <ref type="bibr" target="#b4">(Brennan 2000)</ref>, use of absolute vs relative modifiers, mutual grounding etc. As a future activity, we plan to take up these issues by subsequent evaluation of our algorithm with respect to various reference phenomena encountered in a multimodal dialogue system framework.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 -</head><label>2</label><figDesc>Figure 2 -Reference domain for a group of two tunes (@T)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>: Play me the list I listened to this morning. S[2]: Which one do you want to listen? + [displays a list of 2 tune-list items] U[3]: the first one/ the one by Madonna. S[4]: [plays the tune list] U[5]: Save it/ * Save this/ *Save the list. S[6]: [Saves]</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>maximality refers to the most basic level of attributes associated with any object.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>We follow similar mechanism for temporal reference resolution</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>user request for /listen/ corresponds to system action of /play/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3"><p>based on the subsumption criteria.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Overlay as the Basic Operation for Discourse Processing in a Multimodal Dialogue System</title>
		<author>
			<persName><forename type="first">J</forename><surname>Alexandersson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Becker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IJCAI Workshop ``Knowledge and Reasoning in Practical Dialogue Systems</title>
		<meeting>the IJCAI Workshop ``Knowledge and Reasoning in Practical Dialogue Systems<address><addrLine>Seattle</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A robust system for natural spoken dialogue</title>
		<author>
			<persName><forename type="first">J</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ringger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sikoski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14 th Annual Meeting of the Association for Computational Linguistics (ACL &apos;96)</title>
		<meeting>the 14 th Annual Meeting of the Association for Computational Linguistics (ACL &apos;96)</meeting>
		<imprint>
			<date type="published" when="1996-06">1996. June</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Reference to Abstract Objects in Discourse</title>
		<author>
			<persName><forename type="first">N</forename><surname>Asher</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>Kluwer Academic Publishers</publisher>
			<pubPlace>Dordrecht, Boston, London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Bridging as Coercive Accommodation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A-M</forename><surname>Mineur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Buitelaar</surname></persName>
		</author>
		<idno>Number 52</idno>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
		<respStmt>
			<orgName>Department of Computational Linguistics, Universität Saarbrücken</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Processes that Shape Conversation and their Implications for Computational Linguistics</title>
		<author>
			<persName><forename type="first">S</forename><surname>Brennan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">38th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting><address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-01-08">2000. 1-8 October 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Towards Multimodal Content Representation</title>
		<author>
			<persName><forename type="first">H</forename><surname>Bunt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Romary</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Standards of Terminology and Language Resources Management, LREC</title>
		<meeting><address><addrLine>Las Palmas (Spain)</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">What&apos;s a Reference Resolution Module to do? Redefining the Role of Reference in Language Understanding Systems</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Byron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Allen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
	<note>In the proceedings of the 4th Discourse Anaphora and Anaphor Resolution Colloquium</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Embodied Conversational Agents: Representation and Intelligence in User Interface</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cassell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI Magazine</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="67" to="83" />
			<date type="published" when="2001">2001. 2001</date>
			<pubPlace>Winter</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Generating Referring Expressions: Constructing Descriptions in a Domain of Objects and Processes</title>
		<author>
			<persName><forename type="first">R</forename><surname>Dale</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992">1992</date>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Computational Interpretation of the Gricean Maxims in the Generation of Referring Expressions</title>
		<author>
			<persName><forename type="first">R</forename><surname>Dale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Reiter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="233" to="263" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The Role of Gricean Maxims in the Generation of Referring Expressions</title>
		<author>
			<persName><forename type="first">R</forename><surname>Dale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Reiter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 1996 AAAI Spring Symposium on Computational Models of Conversational Implicature</title>
		<editor>
			<persName><forename type="first">.</forename><forename type="middle">K</forename><surname>Deemter V</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Peters</surname></persName>
		</editor>
		<meeting>of the 1996 AAAI Spring Symposium on Computational Models of Conversational Implicature<address><addrLine>California; Stanford</addrLine></address></meeting>
		<imprint>
			<publisher>CSLI</publisher>
			<date type="published" when="1996">1996. 1996</date>
		</imprint>
		<respStmt>
			<orgName>Stanford University</orgName>
		</respStmt>
	</monogr>
	<note>Semantic Ambiguity and Underspecication</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Reference Identification and Reference Identification Failures</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="273" to="305" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Attention, Intention and the Structure of Discourse</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Grosz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sidner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="175" to="204" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Centering: A framework for modeling the local coherence of discourse</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Grosz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Weinstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="203" to="225" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Centered Segmentation: Scaling Up the Centering Model to Global Discourse Structure</title>
		<author>
			<persName><forename type="first">U</forename><surname>Hahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Strube</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EACL/ACL&apos;97</title>
		<meeting>of EACL/ACL&apos;97<address><addrLine>Madrid</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="104" to="111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Resolving pronoun reference</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hobbs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Readings in Natural Language Processing</title>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1986">1986</date>
			<biblScope unit="page" from="339" to="352" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">From Discourse to Logic</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kamp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Reyle</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>Kluwer Academic Publishers</publisher>
			<pubPlace>Dordrecht, Boston, London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<title level="m">Dialog Module Technical Specification. Project MIAMM -Multidimensional Information Access using Multiple Modalities. EU project IST-20000-29487, Deliverable D5.1. LORIA</title>
		<meeting><address><addrLine>Nancy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A Comprehensive Framework for Multimodal Meaning Representation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Romary</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on computational Semantics (IWCS-5)</title>
		<meeting><address><addrLine>Tilburg, Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Foundations of Cognitive Grammar</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Langacker</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986">1986</date>
			<publisher>Stanford University Press</publisher>
			<pubPlace>Stanford</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Concept, image, and symbol : the cognitive basis of grammar</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Langacker</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991">1991</date>
			<publisher>Mouton de Gruyter</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Taking Time to Structure Discourse : Pronoun Generation Beyond Accessibility</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">F</forename><surname>Mccoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Strube</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 21th Annual Conference of the Cognitive Science Society</title>
		<meeting>of the 21th Annual Conference of the Cognitive Science Society<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-08">1999. Aug. 19-21, 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">On Semantic Underspecification</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pinkal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd International Workshop on Computational Linguistics (IWCS 2)</title>
		<editor>
			<persName><forename type="first">H</forename><surname>Bunt</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Muskens</surname></persName>
		</editor>
		<meeting>the 2nd International Workshop on Computational Linguistics (IWCS 2)</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Underspecification in Reference: Some Evidence from Corpora</title>
		<author>
			<persName><forename type="first">M</forename><surname>Poesio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Reyle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the KR-2000 Workshop on Semantic Approximation, Granularity, and Vagueness</title>
		<meeting>of the KR-2000 Workshop on Semantic Approximation, Granularity, and Vagueness<address><addrLine>Breckenridge</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-04">2000. April</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">MIAMM: Multidimensional Information Access using multiple modalities</title>
		<author>
			<persName><forename type="first">N</forename><surname>Reithinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Romary</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International CLASS Workshop on Natural, Intelligent and Effective Interaction in Multimodal Dialogue Systems</title>
		<meeting>the International CLASS Workshop on Natural, Intelligent and Effective Interaction in Multimodal Dialogue Systems<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-06">2002. June. 2002</date>
			<biblScope unit="page" from="28" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Romary</surname></persName>
		</author>
		<title level="m">MMIL technical specification. Project MIAMM -Multidimensional Information Access using Multiple Modalities. EU project IST-20000-29487</title>
		<meeting><address><addrLine>Nancy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
	<note>Deliverable D6.3. LORIA</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Reference Resolution within the Framework of Cognitive Grammar</title>
		<author>
			<persName><forename type="first">S</forename><surname>Salmon-Alt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Colloquium on Cognitive Science</title>
		<imprint>
			<date type="published" when="2001-05">2001. May 2001</date>
			<pubPlace>San Sebastian, Spain</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Schauer</surname></persName>
		</author>
		<title level="m">Referential Structure and Coherence Structure in Proceedings of the TALN 2000, 7e conférence annuelle sur le traitement automatique des langues naturelles, 16-18 October</title>
		<meeting><address><addrLine>Lausanne, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="327" to="336" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Reference-based Discourse Structure for Reference Resolution</title>
		<author>
			<persName><forename type="first">H</forename><surname>Seville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ramsay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL&apos;99 Workshop on Discourse Structure and Reference</title>
		<imprint>
			<date type="published" when="1999-06">1999. June</date>
		</imprint>
		<respStmt>
			<orgName>University of Maryland</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A corpus-based evaluation of centering and pronoun resolution</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Tetreault</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="507" to="520" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">An Empirically-Based System for Processing Definite Descriptions</title>
		<author>
			<persName><forename type="first">R</forename><surname>Vieira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Poesio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="525" to="579" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
