<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="fr">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Digital 3D Objects in Art and Humanities: challenges of creation, interoperability and preservation. White paper</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Pierre</forename><surname>Alliez</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Laurent</forename><surname>Bergerot</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jean-François</forename><surname>Bernard</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Clotilde</forename><surname>Boust</surname></persName>
						</author>
						<author>
							<persName><forename type="first">George</forename><surname>Bruseker</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Nicola</forename><surname>Carboni</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Mehdi</forename><surname>Chayani</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Matteo</forename><surname>Dellepiane</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Dell&apos;Unto</orgName>
								<address>
									<addrLine>Bruno Dutailly</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="laboratory">LARROUSSE</orgName>
								<orgName type="institution" key="instit1">Coordinators Adeline JOFFRES</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">TGIR Huma-Num</orgName>
								<address>
									<country>France. Nicolas</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">CNRS</orgName>
								<orgName type="institution" key="instit2">TGIR Huma-Num</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution" key="instit1">Stéphane POUYLLAU</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">TGIR Huma-Num</orgName>
								<address>
									<addrLine>Marie PUREN</addrLine>
									<settlement>Inria</settlement>
									<country>France, France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">Charles RIONDET</orgName>
								<address>
									<settlement>Inria</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="institution">Laurent ROMARY</orgName>
								<address>
									<settlement>Inria</settlement>
									<country>France. Roberto</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="institution" key="instit1">SCOPIGNO</orgName>
								<orgName type="institution" key="instit2">CNR</orgName>
								<orgName type="institution" key="instit3">ISTI Lab</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff7">
								<orgName type="department">Authors Pierre ALLIEZ</orgName>
								<orgName type="institution">BERGEROT</orgName>
								<address>
									<settlement>Inria</settlement>
									<country>France. Laurent</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff8">
								<orgName type="laboratory">MAP Lab</orgName>
								<orgName type="institution">CNRS</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff9">
								<orgName type="laboratory">Archeovision Lab</orgName>
								<orgName type="institution" key="instit1">Jean-François BERNARD</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<address>
									<country>France. Clotilde</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff10">
								<orgName type="institution">BOUST</orgName>
								<address>
									<postCode>C2RMF</postCode>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff11">
								<orgName type="department">FORTH</orgName>
								<orgName type="institution">George BRUSEKER</orgName>
								<address>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff12">
								<orgName type="laboratory">MAP Lab</orgName>
								<orgName type="institution" key="instit1">Nicola CARBONI</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<address>
									<country>France. Mehdi</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff13">
								<orgName type="laboratory">Archeovision Lab</orgName>
								<orgName type="institution" key="instit1">CHAYANI</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff14">
								<orgName type="department">DELL&apos;UNTO</orgName>
								<orgName type="institution" key="instit1">Matteo DELLEPIANE</orgName>
								<orgName type="institution" key="instit2">CNR</orgName>
								<orgName type="institution" key="instit3">ISTI Lab</orgName>
								<address>
									<country>Italy. Nicolo</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff15">
								<orgName type="department">Department of Archaeology and Ancient History</orgName>
								<orgName type="institution">Lund University</orgName>
								<address>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff16">
								<orgName type="laboratory">Archeovision Lab</orgName>
								<orgName type="institution" key="instit1">Bruno DUTAILLY</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff17">
								<orgName type="institution" key="instit1">Hélène GAUTIER</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">TGIR Huma-Num</orgName>
								<address>
									<country>France. Gabriele</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff18">
								<orgName type="institution" key="instit1">GUIDI</orgName>
								<orgName type="institution" key="instit2">Politecnico di Milano</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff19">
								<orgName type="laboratory">LAROCHE</orgName>
								<orgName type="institution" key="instit1">Adeline JOFFRES</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">TGIR Huma-Num</orgName>
								<address>
									<country>France. Florent</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff20">
								<orgName type="institution">Ecole Centrale de Nantes</orgName>
								<address>
									<postCode>LS2N</postCode>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff21">
								<orgName type="laboratory">MAP Lab</orgName>
								<orgName type="institution" key="instit1">Adeline MANUEL</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff22">
								<orgName type="department">FORTH, IMS Lab, Greece. Alain MICHEL</orgName>
								<orgName type="institution" key="instit1">Maria Cristina MANZETTI</orgName>
								<orgName type="institution" key="instit2">Univ. of Evry</orgName>
								<orgName type="institution" key="instit3">IDHES Lab</orgName>
								<address>
									<country>France. Anthony</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff23">
								<orgName type="department">PONCE</orgName>
								<orgName type="laboratory">MAP Lab</orgName>
								<orgName type="institution" key="instit1">PAMART</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<address>
									<country>France. Jean</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff24">
								<orgName type="institution">Inria-ENS</orgName>
								<address>
									<addrLine>Marie PUREN</addrLine>
									<settlement>Inria</settlement>
									<country>France, France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff25">
								<orgName type="institution">Charles RIONDET</orgName>
								<address>
									<settlement>Inria</settlement>
									<country>France. Karina</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff26">
								<orgName type="institution" key="instit1">RODRIGUEZ ECHAVARRIA</orgName>
								<orgName type="institution" key="instit2">Brighton University</orgName>
								<address>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff27">
								<orgName type="institution">Lauren ROMARY</orgName>
								<address>
									<settlement>Inria</settlement>
									<country>France. Roberto</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff28">
								<orgName type="institution" key="instit1">SCOPIGNO</orgName>
								<orgName type="institution" key="instit2">CNR-ISTI</orgName>
								<address>
									<country>Italy. Sarah</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff29">
								<orgName type="laboratory">Archeovision Lab</orgName>
								<orgName type="institution" key="instit1">TOURNON-VALIENTE</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Digital 3D Objects in Art and Humanities: challenges of creation, interoperability and preservation. White paper</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E47FE5FB06DA73BBEE127CFC46328709</idno>
					<note type="submission">Submitted on 24 May 2017 Distributed under a Creative Commons Attribution| 4.0 International License</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-08-24T15:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>HAL is a multi-disciplinary open access archive for the deposit and dissemination of scientific research documents, whether they are published or not. The documents may come from teaching and research institutions in France or abroad, or from public or private research centers. L'archive ouverte pluridisciplinaire HAL, est destinée au dépôt et à la diffusion de documents scientifiques de niveau recherche, publiés ou non, émanant des établissements d'enseignement et de recherche français ou étrangers, des laboratoires publics ou privés.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="fr">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Digital 3D Objects in Art and</head><p>Humanities: challenges of creation, interoperability and preservation</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>White paper</head><p>May 2017</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction and rationale</head><p>Today, the digital model has become essential for scientific documentation and analysis. However, with the rapid development and spread of 3D technology, there is an urgent need to integrate and customize the related visualization and analysis tools to support the specific needs of users within the Arts and Humanities research communities. Since the number of models produced increases exponentially, the need of efficient archival systems able to provide effective search and retrieval functionalities is also growing. This White Paper is the result of a workshop organized by CNR (Italy), CNRS (France) and Inria (France) within in the scope of Work Package 4 on Standardization, with support from the technical partners and on behalf of the PARTHENOS Research Infrastructure. This was held in Bordeaux (France), from November 30th to December 2 nd , 2016, and entitled "Digital 3D objects in Art and Humanities: challenges of creation, interoperability and preservation". The workshop was also supported by the work of Huma-Num's 3D-SHS consortium.</p><p>The workshop was attended by selected PARTHENOS partners as well as some external experts, representative of both the technological and humanities domains (see the programme in the Appendix).</p><p>It aimed at enriching technical knowledge about 3D models, standards and tools in the PARTHENOS framework, addressing the common issues and epistemological questions related to the creation, use, reuse and preservation of 3D models.</p><p>More precisely, the objectives were to:</p><p>• Identify best practices and standards to ensure interoperability and sustainability;</p><p>• Expand knowledge for scholars and researchers to support 3D projects in arts, social science and humanities;</p><p>• Bridge the gap between technical people and humanities scholars (contributing to a better understanding of technologies potential and user needs);</p><p>• Share general and targeted knowledge on 3D objects issues in Art and Humanities;</p><p>• Contribute to best practices in the digitization domain for archaeologists and human sciences scholars (including 3D preservation issues: representation schemas, viewers, etc.).</p><p>We selected four main topics to focus on during the workshop, corresponding to the life cycle and the various uses of 3D objects in the Humanities: (a) production and processing, (b) visualization and analysis, (c) description and preservation, and (d) bridges between Cultural Heritage and Museology. For each one of those, a number of sub-topics and issues have been discussed by domain specialists in brief presentations followed by a free discussion. Those topics are the basis of the core chapters of this white paper.</p><p>In this, we intended to provide a framework for the current status of technologies, the needs and perception of digital heritage (DH) scholars/users, and a glimpse of the near future (how can we consolidate and extend technologies by the use of standardised practices? How could we use them in an innovative manner to solve DH problems?).</p><p>The goal is to assess the needs and potentialities beyond the PARTHENOS community and to ensure that the background of the project participants will not bias the results of the discussion. While the reference domain is digital humanities and archaeology, we also aimed at including all related domains, such as museology, or cultural heritage at large. As a consequence, this white paper is based on contributions from all the participants, reporting the main conclusions of the discussion. Such a framework may be further enriched by other experts of the field who will take advantage of the event's video recording. Indeed, you can access to the short videos that have been recorded and edited through the French Canal-u platform following those links:</p><p>• The interviews: https://www.canal-u.tv/producteurs/humanum/parthenos/parthenos_3d_ws_interviews,</p><p>• The presentations: https://www.canal-u.tv/producteurs/humanum/parthenos/parthenos_3d_ws_presentations and also through the PARTHENOS web platform 1 .</p><p>We report here the results of the discussion at the workshop, further improved and extended by subsequent work done after the workshop by the participants involved. Our aim with this White Paper is to briefly review the status of the technologies concerning digital 3D objects, highlighting current issues and the potential for the application of those technologies in the Digital Humanities domain. Some suggestions on potential activities that could be planned and implemented in the framework of the PARTHENOS project are also presented at the end of each core section.</p><p>In order to make this white paper more informative, we decided to add some short introductory text on a few basic themes. The less informed reader will find there a brief overview of the subject and some suggested bibliographic references for building some knowledge on the specific theme. Those sections, called "Overview Box", are graphically highlighted in the text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Production and Processing of 3D Objects Mission Statement</head><p>While planning the workshop session on "Production and Processing of 3D Objects", some basic questions arose regarding our mission:</p><p>• Production of 3D models: is this a solved problem? Status of 3D scanning and photogrammetry technologies: are they sufficiently consolidated and reliable? Are the related tools satisfactory to fulfil the goals of our community?</p><p>• Checking consistency of 3D file formats from syntactic towards semantic checks?</p><p>• Relevance and interest for researchers to share 3D models in an interoperable way at European level?</p><p>• Annotation over 3D models: is it a major missing feature?</p><p>The work of the session was organized consequently and this section presents the results of the discussion and the insights gathered.</p><p>Overview Box 1 -3D digitization for the Humanities: a first glance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. Guidi, Politecnico di Milano, Italy</head><p>Digitizing cultural heritage for generating 3D models of objects, sculptures, buildings, cities and even larger territories has become increasingly popular during the last 20 years <ref type="bibr">[1,</ref><ref type="bibr">2]</ref>. Although coming from the technical domains of Optoelectronics, Computer Vision, Computer Graphics, Geomatics and Virtual Reality, the technologies for 3D modelling the real world have been targeted by several applicative areas of the Humanities ranging from Archaeology to Art History, Museology, Architecture, Urban Planning, Restoration, Archival sciences, etc. due to the potential of this approach for documenting heritage artefacts.</p><p>We can probably identify the Stanford's Digital Michelangelo project <ref type="bibr">[3]</ref>, involving the 3D acquisition of the worldwide famous 5m tall sculpture of David by Michelangelo, as an important turning point.</p><p>Few pioneering works were made before in the 90s', but thanks to significant coverage not only in the scientific literature, Digital Michelangelo made clear also to the public how information not accessible with a standard documentation approach could be originated by 3D digitizing at high resolution for such a complex object. However, from the first applications it was clear that to exploit such extraordinary potential, a lot of resources were needed in terms of time for the acquisition of the 3D data and, particularly, for the following post-processing leading to the final digital 3D object. Considering that such digital objects represents just the starting point for other possible applications in the Humanities, like for example creating Virtual Museums or producing physical reproductions of artworks, the research community and several EU financed projects have made great efforts in making shorter, simpler and mostly automatic all the pipeline processes for generating 3D models from the real world. Nevertheless, the technology chosen and the related processing pipeline change depending on the 3D digitization scenario and the final goal of the resulting 3D model. On the "heritage scenario" side, a first distinction can be made according to the size of the object to be digitized, that can range from: a) small museum artefacts; b) large museum artefacts like sculptures; c) buildings; d) urban areas or archaeological sites; e) portion of territory. This has a direct impact on some functional parameters that directly define the most suitable 3D technology needed. The most evident parameters include the capability to work indoor or outdoor, the maximum spatial resolution and the measurement uncertainty.</p><p>It is then important to consider what needs to be captured. In addition to the most strictly 3D features associated to the object's shape, it's accurate visual representation can be crucial, so that we should distinguish between: a) internal shape: b) external shape; c) colour texture; d) material reflectance. These features also influence the physical principle behind the 3D technology to be chosen.</p><p>In addition, the methods we are considering involve no physical contact between the 3D sensor and the heritage asset to be digitized. Therefore, every 3D technology uses a radiating form of energy that interacts with the surface to be measured, is somehow altered by such interaction and is then collected by a sensor that produces its measurement according to the amount of alteration originated by such interaction. In most cases, such radiated energy is light and the response of the 3D sensing method is affected by the nature of the material in terms of: a) reflectance (i.e. how much a material is shiny); b) transmittance (i.e. how much it is transparent); c) absorbance (i.e. how much it is dark). In addition, if the light used for gathering the 3D information is not generated by the 3D sensor itself, as happens in active 3D device, but it is a natural or non-coded artificial light typically used in passive 3D methods, also the presence of recognizable visual features on the surface to be digitized is something that heavily influences the 3D technology choice.</p><p>On top of all the 3D digitization constraints in terms of logistics, budget, timing, cost/benefit ratio, and, most important the final purpose of the 3D model originated by such digitization, is always the most important element driving the technological choices. Therefore, between a metric model representing an accurate virtual replica of the heritage object/scenario and a rough non-metric 3D model for an approximate visual representation of the object (e.g. on a website), there are several nuances that represent a crucial design choice in any 3D digitization project. Of course, the more accurate is the model, the more analysis on the heritage artefact/scenario can be done virtually in terms of geometric measurements and visual evaluation. But this increases the cost in terms of 3D acquisition and processing time.</p><p>On the "3D technologies" side, the available tools can be classified depending on their working principle. As mentioned above in any case a form of radiating energy is always used for gathering geometrical and visual information, so a first distinction can be done between penetrating radiation and non-penetrating ones.</p><p>In the penetrating category, methods based on the same X-Rays devices used in medicine, or, at higher energy, in the mechanical industry and in airport security, allow capture of the inaccessible internal surfaces of small heritage objects. On a larger size, recent developments based on the use of cosmic rays, are being experimented for attempting the 3D scanning of the interiors of Egyptian pyramids (www.scanpyramids.org). The typical opto-geometrical configuration in this case involves a source of radiation on one side on the object, and a sensing device on the opposite side.</p><p>For the non-penetrating 3D, the electromagnetic energy covers the visible and the InfraRed spectrum. The latter actually may allow a little penetration under the illuminated surface depending on the actual wavelength used, ranging from fractions of a millimetre for Near InfraRed (NIR), to several millimetres for the Far InfraRed (FIR), used in the so-called TeraHertz imaging. However, for 3D applications possible little penetrations inside the material are usually neglected, and this is the reason why light sources for 3D never go beyond NIR. Within non-penetrating devices a further distinction has to be done between active and passive 3D methods.</p><p>In a passive 3D method, light is used just for making the details of the scene clear. These details have to be clearly visible elements contrasting with the background and richly present on all the points of the surface of interest for capture. All 3D passive devices (e.g. theodolites) or methods (e.g. photogrammetry) use this feature since the measurement process requires, first of all, to recognize the same points in different views of a scene from different positions, and this is possible only if the measured object is provided with a contrasted texture, or -when the object is uniformly coloured with no salient points -if the operator has added reference targets over the surface of interest in a number of points sufficient for estimating its 3D shape. The most widely used passive method is Digital Photogrammetry (see Overview Box 2). Although in its early days this was based on a significant manual process of a specialized operator, and for this reason not particularly attractive for 3D digitizing of the complex shapes of Cultural Heritage assets, it has been extraordinarily improved over the last 10 years thanks to the automatization of feature recognition provided by Computer Vision algorithms <ref type="bibr">[4]</ref>. Although a manual intervention is always needed for scaling the 3D data according to one or more reference points to be set on the 3D digitized scene and measured with a different device, this highly automated version of the photogrammetric process allows largely improved 3D productivity with respect to the traditional approach.</p><p>In an active 3D method, a coded light is projected on the surface to be measured in such a way to represent a reference visible from a sensing device such as a camera or a photodetector <ref type="bibr">[1]</ref>. In this way, the 3D measurement results are feasible also for completely textureless surfaces. If the projected light intensity is not too high the environmental light may interfere with such coded light, making for example, the device unusable outdoor. In this domain a further distinction is made between: a) Devices based on triangulation, where the sensor is made by a light source and a camera set at a known distance, capable of measuring only small volumes but with a very small uncertainty (below 0.2 mm); b) Devices based on the direct measurement of distance, such as Time of Flight (TOF) and Phase Shift (PS) laser scanners where the sensor-to-surface distance is evaluated by the time needed by light to go from the sensor to the surface and back. Those are capable of working at distances from a few meters to few kilometres, suitable therefore for buildings, large artefacts, archaeological sites or territories. In this case, a much larger measurement uncertainty occurs, ranging from few millimetres to few decimetres. The same principle is used in Laser Radars (LR), where the method for evaluating the distance is based on modulated light and the measurement uncertainty can be reduced 20 times with respect of TOF laser scanners. Also interferometry works on the same concept, even if the method in this case is suitable for 3D digitization of the very small samples (e.g. coins) with measurement uncertainty in the order of few micrometres; c) Devices based on the laser-driven selective focusing of the imaged scene such as confocal microscopy, suitable for ultra-small CH samples or for the structure of their matter.</p><p>In any case, 3D active devices are the only ones capable of metrically acquiring the geometry of a surface in a totally automatic way, with no need to resize the final 3D results. The result they produce is a "range image" representing the 3D view of the device from the point of acquisition. Its structure can be a matrix of 3D coordinates, more common with triangulation-based 3D devices, or an unstructured cloud of 3D points, represented by a list of x,y,z coordinates, more common with the devices based on the direct measurement of distance.</p><p>After the 3D data acquisition, a post-processing phase is crucial for transforming a set of unrelated raw datasets in a reality-based 3D model. Here there is a clear distinction between active 3D devices and photogrammetry.</p><p>When the scene is imaged from different points of view with an active 3D device, each one provides a range image whose 3D coordinates are represented in a local reference system centred on the 3D device. Since all these coordinate systems are unrelated it is necessary to align all 3D data to the same coordinate system. Such a process can be achieved in three different ways: a) Measuring some reference targets on the scene with a different 3D device providing their coordinates in a common reference. This approach is used more frequently with laser scanners based on direct measurement of distance (TOF, PS, LR), thanks to their large region of interest <ref type="bibr">[5]</ref>; b) Using as references natural 3D features recognizable in more range images and finding the best possible match between them through the "Iterative Closest Point" (ICP) algorithm. This is the most used approach with triangulation-based devices, but it is often used also with the other active devices when no reference targets are available <ref type="bibr">[2]</ref>. c) Using a complementary equipment like GPS+IMU, CMMs, Laser Trackers or Motion Capture cameras, for measuring the range device position and orientation in a global reference when each range image is shot. The 3 coordinates and 3 rotations (6 degrees of freedom) of the 3D device can be used for calculating the transformation matrix of each range image from the range device coordinate system to the global one. This allows on-thefly provision of the 3D data gathered from different positions in a global reference. For this reason, this approach is at the basis of each mobile mapping device gathering 3D data from aerial vehicles, cars, robots, or handheld 3D devices <ref type="bibr">[6]</ref>.</p><p>Once the set of 3D data is available in the same reference system, a meshing process is used to transform them into a 3D mesh model whose precision, accuracy and resolution are determined by the quality of the initial raw data. This can be afterwards edited and textured with an additional process <ref type="bibr">[7]</ref>.</p><p>In the modern automatic photogrammetry techniques, the modelling process is far more straightforward, since the measuring phase with Structure from Motion and Image Matching (SfM/IM), provides 3D data all oriented in the same reference system, which makes the following modelling phase a mere generation of the polygonal mesh approximating the exterior surface of the Heritage object, where the only manual phase is the editing of the unavoidable holes and topological errors that might be originated by the automatic process. In addition, since the 3D data are originated by images, the texturing phase consists of the projection of the images on the geometry, which is straightforward for the end-user.</p><p>In conclusion, the production of 3D models for CH can be considered a solved problem with respect to the geometrical component, for many categories of scenarios that are optically cooperative, independently of their size. A significant difference does exist in terms of modelling time between steady active devices, that still need a significant manual effort for the post processing of the data, and mobile active devices or photogrammetry that allows the generation of reality-based 3D models with a minimal human effort. With the same types of materials, the generation of the texture component can also be considered a solved problem for all applications where the quality of a photographic image is considered accurate enough.</p><p>In particular, the experience with recent EU financed project like 3D-ICONS, the project CultLab3D by Fraunhofer Institute, or the IU-Uffizi project, whose goal is digitizing the whole patrimony of roman sculptures at the Uffizi Galleries, demonstrated how automatic photogrammetry based on SfM/IM is the key technology for massive digitization of CH, allowing production of a texturized model in a time 5 to 20 times less than that required by steady active 3D devices <ref type="bibr">[8]</ref>.</p><p>However, if the 3D digitization involves scenarios with non-cooperative materials (e.g. shiny or transparent), apart from penetrating radiation that may work in some cases, there are not yet efficient technological approaches for obtaining a mesh model.</p><p>Regarding the material reflectance, that is important for accurately rendering the visual aspect of a digitized heritage asset, the existing methods give good results only on specific categories of objects, typically small enough to fit in complex structures for generating sequences of images with various illumination geometries. Here the 3D technology needs to progress for extending reflectance estimation to a broader category of heritage objects, also reducing the time needed for estimating it.</p><p>Finally, what is still lacking on the humanity side of the process is a complete awareness of the metrological aspects related with 3D digitization. Any 3D capturing technology gives a limited resolution, accuracy and precision, and the full awareness of what is needed for a specific heritage application has direct impact on the whole 3D digitization pipeline, defining feasibility and costs.</p><p>Therefore, this should be completely clear to the end-users in the humanities for choosing the better trade-off between costs and benefits in any 3D digitization project.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Production -Expected features and issues</head><p>We discussed several themes, which are critical for the comprehension of the 3D production technologies and over their impact in concrete applications in the DH domain. Both technical and more general themes have been evoked: quality assessment, repeatability, guidance and feedback, non-linearity, geometry vs. colorimetry, multimodality, scalability, registration, reliability, interoperability, mass-digitization and preservation. They are detailed next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Quality assessment</head><p>First, a clear identification of critical quality indicators such as accuracy, resolution and uncertainty is needed. In some cases such indicators are domain-specific. One direction is to embed, either inside the 3D model or via a metadata-based convention, both qualitative and quantitative indicators of the data provenance in order to enable the retrieval of relevant information about unicity (is another version of this model available?), authenticity (is the model reliable regarding geometry, colorimetry, albedo, reflectance or BRDF?) and metrology (accuracy, uncertainty, signal to noise ratio). Obviously, the main challenge is to reach a universal and objective consensus for such a quality assessment, despite the very large number of hardware/software/algorithm combinations used by the CH community. Another challenge is to measure the degree of quality of a given model/representation, in a manner that is as objective as possible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Repeatability</head><p>A process is repeatable when it allows a project team to make efficient and stable use of technological and software tools that have been shown to be successful in the past, and reduce undesirable variance in the outputs that can tie up time and effort. Even though repeatability has slightly improved in the past few years from an algorithmic point of view, stability remains an issue mostly due to the fact that both the equipment used for acquisition and the pipeline used for data processing undergo an important and constant evolution. This fact substantially complicates the comparison among 3D models of a shared collection, emanating from different techniques, institutions and time-range. Different time-range herein refers to acquisition processes for the same scene or artefact that took place at different times or happened at different time intervals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Guidance and feedback</head><p>Controlling the results and steering the digitization process, especially for image-based techniques, is a major issue, mainly for structure-from-motion (SfM) and to a lesser extent for RTI methods. More specifically, most of the software tools do not provide sufficient user instructions on how to acquire the input images. In addition, they often do not give hints or explanations about the parameters required to reach the optimal way to process the acquired images. We thus observe an overshooting trend, which is maximizing the ease of use and the probability to obtain a result, but is often conducive to sub-optimal quality results. This motivates the following directions and recommendations:</p><p>A major effort is required to offer a didactic passive way to learn how to acquire data for specific purposes, through guideline, tutorial or e-learning. Some approaches have been devised to provide active feedback directly during the acquisition stage, via real-time assistance and processing or next best view planning. One direction is to integrate feedback as a feature within the acquisition software via a quantitative method enabling to assess the quality of the data acquisition in relation to the input data set.</p><p>In extension of the points above, we recommend devising novel tools/features to segment/classify automatically or manually the input data in terms of quality, in order to subsequently enable part of the input data to be discarded for improving the final quality.</p><p>The strong dichotomy between black box vs. flexible and parameterized solutions is a major issue concerning applications in CH studies. On the one hand, many of the user-friendly commercial solutions do not provide any explanation about the specific data processing pipeline required to scientifically evaluate the validity of the results. On the other hand, several solutions, mainly based upon open-source software, are more flexible and "transparent", offering more control of the data processing pipeline. However, they often require detailed knowledge and experience. As it will be hard to open the code of commercial solutions, the CH community should increase metrological software comparisons. In addition, the open-source developers should strive to make their solutions more accessible to non-expert CH oriented end-users.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Pamart, MAP Lab., CNRS, France</head><p>In the past few years, image-based modelling have been widely disseminated into the Digital Humanity community and beyond. Firstly, because of the accessibility and affordability of Digital Still Camera (DSCs) increasing at the same time the low-cost spectrum of this 3D survey method.</p><p>Secondly thanks to the great improvement of developers enhancing their algorithms in terms of velocity, robustness and automation. Hence, photogrammetry has nowadays the benefit of userfriendly techniques compared to lasergrammetry, which requires a higher degree of expertise in both the data acquisition and processing stages.</p><p>However, there remains an important gap between open-source solutions requiring knowledge of photogrammetry and programming over which users have complete control over and flexibility for data processing and the opaque alternatives of commercial black boxes. This transition from a selective expertise field to one of booming "end-users" has arisen due to the appearance of commercial solutions that bring necessary simplification, robustness and Graphical User Interface software. Nevertheless, among this diversity we have to highlight that no ideal and versatile solution exists nowadays, which is raising the question of our software dependency and also the data interoperability issue. One shall recognize the positive impact on SfM current approaches and practices even though this can also mislead non-initiated users into the black-box system without critical overview of the input and the output, even more on the processing stages, which remains silent for commercially valid reasons. But unlike other users interested in only visually correct results, the Digital Humanities community have to rely on the geometrical and dimensional characteristics and the extension to optical characterisation of material (reflectance) to perform further data analysis. This vulgarisation of image-based modelling methods reveals a lack of initiation of basics and principles of photogrammetry rules dedicated to CH oriented scientists or end-users' purposes. On one side, all pedagogical/educational experiences (summer school, e-learning, guidelines) have to be developed and promoted. On the other side, a more technocratic approach would be to improve development from the computer science aspects on real-time processing combined with Next-Best-View planning algorithms to obtain an in-situ data acquisition guidance system. Additionally, computing resources have to be scaled according to the overload of data resulting from the increasing megapixel capacities of current cameras, the number of pictures required to model complex or large objects and the amount of surveys performed. Even so, the state of the art in data acquisition automation is still not ready to reach the so-called big data in the field of 3D modelling. In the near future, the computation power of the current workstation may not be enough to encompass potential issues revealed by forthcoming technologies. In this context, our community shall have to discuss a large scale and shared cloud-based remote computing infrastructure for outperforming this issue.</p><p>Moreover, all the trends and issues mentioned above have to be seen under the light of the major evolution of image modelling, as most of time, photogrammetric practices no longer belong to a conventional and linear process. Indeed, SfM tends to become an incremental process with multiple actors, sensors, scales, and spectral dimensions and among several time ranges. Those multimodal perspectives directly question the need of a data uncertainty metric among multiplicity and complexity of interoperability and data provenance entangled issues correlated with the growing interdisciplinary framework of image-based modelling.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>References</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Non-linearity</head><p>We observe that 3D scanning has become an increasingly non-linear process, and we understand that it is no longer a one-shot pipeline from data acquisition to a single output 3D model. First, the increasing complexity of current acquisition processes requires a multi-temporal approach, sometimes combined with past data-acquisitions. Secondly, most of the time an acquisition requires collaborative processes (different techniques and/or institutions), making de facto the data processing incremental. This new trend of progressive acquisition and processing is likely to introduce some new challenges, both from the technical point of view and from the data authority management point of view.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Geometry vs. Colorimetry</head><p>An increasing requirement of the CH community relates to the fidelity of colours, ranging from the usual colour calibration within an image-based modelling pipeline, to more demanding reflectance measurements such as light-material interactions derived from RTI and BRDF approaches. Such a requirement is introducing a novel complexity gap for the entire 3D modelling pipeline, including the visualization step. In addition, there is still no universal consensus on the best format for rich colorimetry measurements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multimodality</head><p>Another complication of 3D scanning relates to the multiple and complementary techniques applied to the same case study, which requires multimodal approaches. While data fusion has been explored for a while in different fields such as remote-sensing or medical imaging, it is much more recent concerning 2D/3D scanning techniques applied to CH objects. It opens a new research area for the field, involving challenging projects with both pluri-and inter-disciplinary approaches. Multimodality promises to be a recurrent investigation field for the next few years as it embraces a wide range of approaches: multi-sensor, multiscale, and multi-spectral as well as multi-temporal considerations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Scalability</head><p>Scalability is often limited in terms of coverage and accuracy. The current solutions often suffer from insufficient scalability in memory, time or computational resources, making it difficult to acquire large-scale scenes with high accuracy. Having to trade coverage for accuracy is detrimental to the final quality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Registration</head><p>Registration is the process of transforming different sets of acquisition data into one coordinate system. The coordinate system may be either local to a site where different acquisitions happened, or global, i.e. in accordance to global positioning system coordinates. The data may come from different sensors, times or viewpoints. Registering the acquired models in manner that is reliable, automated and repeatable is a major issue. For cultural heritage sites, one direction is to resort to absolute spatial indexing on the earth, for reasons of consistency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reliability</head><p>We observe some level of stabilization of specific pipelines regardless of the great diversity of objects and purposes to fulfil requirements of CH experts using 3D model for studies and analysis. Nevertheless, a more global assessment of the diverse pipelines highlights an insufficient level of reliability of the data produced, as many of common practices resort to trial and error processes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Interoperability</head><p>In terms of interoperability, we are still far from a clear consensus for the best and ideal solutions, and fragmentation of the tools is a major issue for streamlining the process chains. In addition, we doubt that the quest for the ideal solutions is either realistic or useful for our community. To reduce fragmentation we thus recommend focusing on bringing together tools and data instead of aiming for the ideal process chain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mass-digitization</head><p>For several cross-analysis purposes, a valid option is to rely upon mass 3D digitization technologies. In order to reach a critical mass automation is needed, but automating the process usually reduces the flexibility, as each device must be dedicated to a specific acquisition task. Moreover, the CH domain is very wide in terms of characteristics of the artworks to be sampled. We follow, instead, the idea that this crucial challenge must be a common task shared by a wide consortium.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Preservation</head><p>Instead of storing and producing metadata only for the final result, one direction is preserve all data ranging from raw to final through intermediate processes and processed data. For more information about that topic, please refer to chapter 4 on "Objects' Description and Long Term Preservation".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusive guidelines on acquisition processes</head><p>Incorrect data acquisition processes can make it very hard or impossible for an effective use of 3D models.</p><p>Multiple technologies are available, and none of them is the solution for all the problems. Making a correct choice given a specific task is thus not an easy task for the users. More training and guidance are very much needed on the following topics:</p><p>• Guidance on how to address the critical issue of preparing the scene before digitization to make more evident the information we want to sample (archaeology case presented by Dell'Unto and others).</p><p>• Digitization is already an interpretation. It is thus critical to drive the digitization, ensuring that the digitization action focuses on the important areas. Note that evaluating the importance cannot be demanded of technologists, as the digitizing practitioner should understand the knowledge behind the sampled surface to sample it correctly. One way to ensure or enforce this is through training and devising guidelines on an improved planning protocol, where the digitization is first planned jointly on a graphical reference (a map or an image) where, e.g. the excavation people define which should be the focus of the digitization, i.e. the areas that should be given priority or more attention. Some sort of quick annotation performed on the field could drive the work of the digitization people. These annotations could also be projected back on the resulting 3D models (possible if annotation is done on registered images, following the approach proposed by MAP-CNRS). Panoramic images can play an important role in this process as they are now easy to acquire and offer a global view over the working area. Another more radical solution is to move digitization from the hands of the technologist, and have it driven instead by domain experts such as archaeologists or restorers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Annotation</head><p>Annotation refers to the process by which a user or computer system assigns metadata to acquired data in the form of captions, keywords, semantic classes or process description.</p><p>Thanks to the development of digitization and 3D-reconstruction techniques in the past few years, the generation of 3D models became a quite simple process. Digital 3D models are currently the preferred media for the representation of objects. They allow the monitoring of an object from its conception to its end of life, and even to provide support for maintenance monitoring. In the specific topic of Cultural Heritage, they also represent a useful media for the study and dissemination of information between experts and for general public.</p><p>In order to add additional information coming from analysis and documentation processes, it is often necessary to semantically enrich the object representation by means of annotations. The principle of semantic annotation relies on connecting a resource (partially or entirely) with supplementary information by using information structures (tags, attributes, relationships, ontologies, etc) for advanced research purposes.</p><p>The next Overview Box presents a review of the different systems and approaches for annotating visual models; the rest of the subsection highlights issues and limitations of current technologies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Overview Box 3 -Tools supporting annotation on 3D models.</head><p>A. Manuel, CNRS, MAP Lab, France; R. Scopigno, CNR, ISTI, Italy.</p><p>Currently, different tools are available to annotate 3D models in CH community. In these tools, annotations are attached to parts of the 3D model or to new objects inserted in the scene. In 3DSA (3D Semantic Annotation), annotations are structured by ontology and tied to points, surfaces, regions or segments of the 3D objects <ref type="bibr">[1]</ref>. ShapeAnnotator includes different segmentation algorithms that divide the 3D mesh into parts <ref type="bibr">[2]</ref>; the user then only needs to select parts of the provided segmentation. The Arrigo project is an interactive system allowing users to explore 3D models of a set of statues and to discover detailed information on these objects by using annotations linked with hotspots (rendered as small spheres) placed at specific locations on the 3D model surface <ref type="bibr">[3]</ref>. The 3D web viewer developed by Sketchfab includes the possibilities of adding point-based annotations on uploaded 3D models <ref type="bibr">[4]</ref>; annotations are represented by a circled number attached to the surface of the model. A similar feature is also available on the 3DHOP platform <ref type="bibr">[5]</ref>. The Agata system has the ability to insert vector shapes directly onto the surface of the polygonal model by making use of OWOL (Octree With Overlapping Leaves) encoding <ref type="bibr">[6]</ref>. The Nubes platform supports the connection between a structured 3D model and 2D mapped data, which are copied into the model textures <ref type="bibr">[7]</ref>.</p><p>One problem of using 3D models comes from the difficulty to manipulate them, especially when complex annotations have to be defined and stored. Annotating a 3D model is straightforward when each annotation is linked just to a geometric location (point-based), since we only need to pick the associated point and save its coordinates together with the annotation text. The work becomes more complex with more complex annotations, based on the selection of a polyline or a polygonal region over the object surface. Moreover, we should consider that high-resolution 3D models are a must for professional CH applications, such as CH restoration, and 3D digitization easily produces multi-million points models. In those cases, we usually endorse a multiresolution representation of the 3D model <ref type="bibr">[8]</ref>. Defining and clipping an annotation region over a complex multi-resolution model is not so straightforward, but it has been recently demonstrated to be feasible in the context of a web-based documentation systems designed to support a CH restoration project <ref type="bibr">[9]</ref>. However, all these different 3D annotation tools still don't integrate fully the use of images.</p><p>Managing multiple representation media in an integrated manner is considered a very promising approach. Images offer a different but very useful and easy-to-use media for annotation and can also record other information (e.g. diagnostic results produced with scientific imaging techniques).</p><p>The use of 2D and 3D representations in the same tool suppose that both representations have to be annotated in a common and interoperable way. The CHER-OB visualization and analysis platform <ref type="bibr">[10]</ref> allows management of annotations for 3D models and images in the same tool, but an annotation made on one media is not directly connected with (or translated) a corresponding annotation on the other media. Nubes Imago is a part of the Nubes platform that integrates 2D and 3D representations in the same space, but again it relies on an annotated 3D model around which images are registered and could be projected (reverberating the annotation performed over the 3D surface also over each image plane). Conversely, Aioli <ref type="bibr">[12]</ref> is the first system that includes an integrated management of annotation in 2D and 3D spaces. It relies on the idea of spatial referencing of images around a 3D representation (which in Aioli is a very dense point cloud obtained with photogrammetry/SfM). The starting point in Aioli is a dense set of images with predefined camera view that link each of them to the reconstructed 3D model (this is a standard byproduct of the photogrammetric reconstruction process). This allows the user to draw annotations directly on images (that is a simpler process than drawing a region over a 3D mesh); those regions are then projected back to the 3D representation and automatically propagated to all other relevant images. In this way, a single annotation action performed on a single image is automatically propagated to the 3D model and to all images that "see" that portion of surface region.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Linking different representations</head><p>Such links, through spatial correspondences, yields an information continuum between different media (3D, 2D), obtained through registering all media in 3D. This will offer a new paradigm, where annotations could be performed just on one media/item and then propagated to many other media/items. For datasets containing images and 3D objects such a correspondence can be generated through aligning images with point clouds.</p><p>Alignment is implicit when the 3D model is produced from photographs; conversely, automatic alignment solutions are needed when 3D is produced with active scanning technologies and the photographs must be registered to the 3D model. Collaborative processes implemented via crowdsourcing and/or cloud services poses major issues in terms of data authority, and validation as well as information integration: The diversity of actors and of the analysis approaches in the documentation process hampers direct merging of all data.</p><p>The main type of issue is to collect all these different data in a common system in order to develop collaborative processes between all actors. A collaborative system can offer new possibilities for crossanalysis, but such a system must be made easy-to-use and easy-to-access via web services. It requires managing various sources of data that can emanate from experts but also from non-expert people (especially in case of hard-to-access heritage). While the expert and non-expert can act via the same process, the challenge is to identify the reliability of each integrated data set according to the associated authors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Space and time</head><p>Historical objects and documents in the form of heterogeneous data such as archives require capturing time.</p><p>Beyond the geometric representations, a large amount of heterogeneous data is usually collected, organized and analysed for the study of heritage buildings. These data most often come from different areas (architecture, archaeology, history, conservation science, etc.) and are based on different supports (iconography, geographic maps, manuscripts, etc.). Moreover, the joint analysis of spatial and temporal data is clearly of particular importance for visualizing object histories, for conveying temporal distribution of categorized events, as well as for addressing spatiotemporal data distribution issues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Collections</head><p>Beyond annotating for a single object, one trend is to reason at the scale of a collection and multi-collections.</p><p>One challenge is to propagate annotations across objects of these collections, and to improve effectiveness by enabling the users to verify the outcome of such propagations, as verification is often faster than annotation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Provenance</head><p>Provenance in the context of digitized data refers to the record of evidence of creation, processing and altering of one or multiple CH data. Altering can take a wide range of electronic transactions such as compression, transmission, editing, referencing, plagiarism and distribution.</p><p>Providing provenance information is particularly important. We have looked into two themes: authority and paradata.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Authority</head><p>A key issue is the authority for data production, as well as documentation of the acquisition and processing processes. Currently the information related to the creation of reality-based 3D representation, as well as for the construction of iconographical-based models, is not present, incorporated or available to its users.</p><p>The professional community has a quite long tradition of explaining the issues and methods in written form, but not enough attention is given to the overall process, and only bits of information are available on certain specific phases. It is, thus, important to establish protocols that would register the acquisition and processing information, making them accessible by a wider public, and allowing the reuse of the 3D representation in other scenarios or by other users. The documentation and the preservation of the initial steps followed by the exact pipeline of production would certify, moreover, the scientific approach of the project (preserving the condition for ensuring its repeatability), laying down the foundation for a proper comparison mechanism between results. The community needs to grasp this theme and define on the basis of previously constructed approaches, an application profile that can have a wide application between diverse actors with different objectives. Furthermore, in the context of semantic web and open data, which are future driving forces of the discipline, the provenance information has a cardinal role because it allows us to understand the degree of reliability of a source.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Paradata</head><p>A key issue is to reduce the burden of annotating data for producing provenance, referred to as paradata. A means to reduce the cost for the user is to automate the integration of information through integrated format combining 3D and semantic, and auto-completion of metadata. It is paramount to develop tools with high interoperability with the current applications such as MicMac, PhotoScan and Sure. Such an approach would enable the automatic registration of the initial parameters and shooting information in a flexible data structure (XML or JSON) that could be easily ingested into a database. While some of the initial information must be extrapolated or inserted by hand, it is not the case for the EFIX data or the history of the processing, which, throughout the development of plugins, can be integrated into existing solutions. Storing this type of metadata can be implemented through an external or internal solution. The external solution would consist of a database carrying both the 3D model and the information connected to it. This would be a preferable solution in archiving because it splits the interpretation and the object itself. The internal solution would require the development of a new encoding able to preserve not only 3D information, but also the metadata associated with it. If incorporation would be the perfect solution for diverse problematics, it would, however, resolve the exchange and embedding problems, resulting in a smoother process for the professional working with 3D data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Impact on Parthenos</head><p>Incorrect data acquisition processes can make it very hard or impossible for the effective use of 3D models:</p><p>• Multiple technologies available, none of them is the solution for all the problems; making a correct choice given a specific task is not an easy task for the users. More training and guidelines?</p><p>• Comments on how critical it is to prepare the scene before digitization in order to make more evident the information we want to sample (archaeology case presented by Dell'Unto and others)</p><p>• Digitization is already an interpretation!! Comments on how critical it is to drive the digitization, being sure that the digitization action focuses on the important areas (thus cannot be demanded to technologist, the digitizer should understand the knowledge behind the sampled surface to sample it correctly) How to ensure/enforce the above issues? How could PARTHENOS contribute to improve ability of users in making a correct and qualified use of existing technologies?</p><p>• Planning and implementing training events?</p><p>• Producing Guidelines? Maybe define an improved planning protocol, where the digitization is first planned jointly on a graphical reference (a map or an image) where the excavation people define which should be the focus of the digitization, the areas that should be given priority or more attention… Some sort of quick annotation done on the field that could drive the work of the digitization people. These annotations could also be projected back on the resulting 3D models (possible if annotation is done on registered images, following the approach proposed by MAP-CNRS). Panoramic images can play an important role in this process (since they are now easy to acquire and give a global view over the working area).</p><p>• Move digitization from the hands of the technologist; have it driven by domain experts (archaeologist, restorers)?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Visualization and Analysis Issues Mission statement</head><p>The basic questions underlying the work of the WS session on "Visualization and Analysis" were as follows:</p><p>• Visualization and analysis is moving from desktop to the web. A first goal was to review the status of commercial and open source viewers online for 3D objects.</p><p>• Interlinking 3D objects to other media (RGB images, RTI, multi-spectral images, 3D models, video, sound, text, etc.): how could this be implemented? What are the needs of our community?</p><p>• Need of effective search and retrieval functionalities over archives of 3D shapes (tag-based or shape-based).</p><p>• How European 3D projects, teams, etc., contemplate the representation of time in their modelling? (How to represent visually and document the time span that is associated to a specific portion of the 3D model? How we could represent an architecture at different stage of its life? ).</p><p>The work of this session was organized consequently and we present here the results of the discussion and the insights gathered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Overview Box 4 -Web-based visualization of 3D models. B. Dutailly, CNRS, Archéovision Lab, France; M. Chayani, CNRS, Archéovision Lab, France; M. Dellepiane, CNR, ISTI, Italy</head><p>With the mass arrival of 3D digital technologies like photogrammetry or laser scanning, research teams produce many 3D models in the domain of the Cultural Heritage. Sharing this data over the internet was felt to be an unsolved need until very recently. Initially, solutions for the publication and visualization on the web of 3D models have been requested by applications oriented to the generalist public, following dissemination purposes (e.g. museums willing to offer also virtual shows of the artworks). More recently, similar needs are also arising from professional user community (e.g. to support the study of artworks or a comprehensive digital documentation of restoration projects).</p><p>Several approaches have been proposed for the publication of 3D material on the web these were mostly based on VRML and similar platforms and always required the installation of specific plugins on the remote users' PC. Unfortunately, those early experiences have been much below the expectations of users. More recently the introduction of HTML5 and of WebGL brought a complete revolution, making 3D content a standard component of any web page and providing visualization support directly inside all common web browsers. The installation of exotic plug-ins is not needed anymore; when 3D content is available on a web page, it is immediately rendered. This technological progress ignited the development of web sites and 3D data sharing platforms; therefore, many online 3D viewers are available nowadays to visualize and manipulate 3D models, either as commercial systems <ref type="bibr">[1,</ref><ref type="bibr">2,</ref><ref type="bibr">3,</ref><ref type="bibr">4,</ref><ref type="bibr">5,</ref><ref type="bibr">6,</ref><ref type="bibr">7]</ref> or academic/open source platforms <ref type="bibr">[8,</ref><ref type="bibr">9,</ref><ref type="bibr">10,</ref><ref type="bibr">11,</ref><ref type="bibr">12]</ref>.</p><p>Most of those browsers have been developed for commercial applications (in many cases, related to CAD or 3D printing). Only a few have been designed specifically for the purpose of CH/DH applications based on 3D sampled models <ref type="bibr">[8,</ref><ref type="bibr">9,</ref><ref type="bibr">11]</ref>.</p><p>These online 3D viewers present several advantages. The main one is that users should no longer need to pay attention to the file type and the availability of the related applications for opening and visualizing that 3D model. The browser is able to solve all these issues and data should not have to be downloaded explicitly by the user.</p><p>Moreover, web tools are going beyond the pure visualization functionalities. They can be enriched by second order features, like the ability to make measurements, link other content to the 3D model (annotations, documents…), and support more sophisticated visualization modes. Flexibility of the visualization context is another important aspect for CH/DH users: in a number of cases, a classical object-in-the-hand approach is satisfactory (using some sort of trackball, the system allows to rotate the digital object to see it from any side, as in most 3D browsers). But a more flexible approach could also be needed, for example to manage the visualization of a small collection of artworks or the navigation in a closed environment <ref type="bibr">[8,</ref><ref type="bibr">12]</ref>.</p><p>However, the existing online 3D viewers present some limitations (or perceived limitations), especially for CH/DH users. First, the 3D Data have to be stored on a web server. Not all CH/DH potential users might have the resources needed to setup and maintain a personal web server. This</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Web-based visualization technologies (plain viz) -Open issues</head><p>The primary scope of a 3D representation is to document the status of an artefact and to support remote and digital visual analysis. A number of tools have been designed and implemented to support interactive visualization features over digital 3D models, as well as more advanced and complex analysis features (supporting numerical / geometrical / topological analysis, i.e. processing shape and producing insight).</p><p>More recently, we are witnessing a process where 3D modelling and visual analysis features are migrating from desktop tools to web-based applications or tools (see the Overview Box 4). This follows two important trends:</p><p>• Users are used to searching for data over the web (as far concerns 2D visual data, huge quantity of images are nowadays already easily accessible on the web, with quite good search and retrieval interfaces; we are now in a more the pioneering status for 3D data);</p><p>• The old approach to data usage (based on file transfer and access to data on a local machine) is replaced by the quest for the immediate delivery and use of any visual media. Users want to be able to immediately open any visual resource, directly from the context used to discover its existence (therefore, from the web browser). Some issues emerged from the discussion over the state of the art of web-based tools for 3D data visualization and analysis. Several solutions exist, with a good level of consolidation (see the Overview Box 4) thanks to the introduction of the WebGL platform and its endorsement by all major web browsers. In some cases, the DH/CH community appears to be a bit behind the status of enabling technologies (e.g. even if repositories of 3D data already exist, scholars or DH experts still are reluctant to use those resources and to share data). What do we need to advance the adoption of cutting edge technology? There are several issues, related to:</p><p>• Need for more training (3D technologies are not straightforward as the existing basic 2D media, people requires some training to learn how to produce good quality 3D models or how to use them proficiently in research or study).</p><p>• Consulting could be needed to help some institutions less strong in ICT skills (small museums, humanities scholars) in endorsing new technologies.</p><p>• Need for some small and focused joint projects (linking better technology providers and users, setting up small bilateral teams); this could require a very small economic support, but could be highly beneficial in terms of momentum that could be ignited in practical activities and projects.</p><p>Could be seen as a follow up of training and consulting.</p><p>• From the technical side, visualization in CH/DH requires high quality models encoding not just geometry but also surface reflectance / texture characteristics (usually indicated with the jargon term "colour") <ref type="foot" target="#foot_1">2</ref> . Further research is, therefore, needed to advancing knowledge on progressive mesh compression with an improved management of multiplexed texture-geometry.</p><p>• Another technical issue is to advance representation and visualization technologies to provide more adaptive rendering solutions. Since we are using multiple computing platforms (desktops, portable PCs, tablets, smartphones), we should investigate new methods for the transparent interchange between geometry and texture/modulation maps, supporting a better adaptation to the wide range of portable devices (e.g. tablets are much faster at rendering low-poly models with texture maps than pure high-resolution geometry).</p><p>While current technology is sufficiently stable and consolidated, some issues have been raised concerning:</p><p>• The current concept of the ownership of the visual data is still a limiting factor, convincing the CH/DH community of the importance and added value of sharing good quality digital models is not an easy task. Production of high-fidelity visual models is usually a complex task (with costs and expertise invested in the effort). Moreover, in many cases we produce the digital model of objects under restoration or just recently discovered, therefore there are confidentiality constraints making open and free access a potential problem. How can we convince the community to endorse a more open approach? How can we push the community towards a more timely dissemination of the data produced?</p><p>• There are a number of perceived issues in data protection:</p><p>o De facto it is impossible or extremely hard to guarantee data protection! In some cases, it is very easy to steal 3D data <ref type="foot" target="#foot_3">3</ref> (just right-mouse-button select and copy…), while in some other case it is more complex (e.g. this is the case of digital models encoded adopting a multiresolution scheme -since the geometry is not encoded with a single file, but it is transmitted on demand to the remote rendering client following a view-dependent mode <ref type="foot" target="#foot_4">4</ref> , we never transmit the entire 3D model and this makes the production of fraudulent copies of the data more complex).</p><p>o Robust watermarking solutions have been proposed for 2D images (and to a lower extent to mark the geometry of 3D models 5</p><p>) as a solution for data protection. The association of a watermark to any digital assets would protect the ownership, since we will be able to check if a specific model is a copy or a derivation of a specific watermark model, property of a specific institution. Therefore, from a technological side, we have a possible solution. But from a practical side, this requires an institution not just to mark all assets, but also to run the search for fraudulent copies and unauthorized uses. This is part of the job of commercial companies 6</p><p>, but very hard to be endorsed by scientific or heritage related institutions (i.e.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>museums).</head><p>o Do we really have to bother with data protection? Why should we protect the data, avoiding that anyone can make a personal copy of the data file? Some data owners or institutions are endorsing a full open data approach. An example is ADS, with a wise policy for data archival and sharing 7 . One of the more cited reasons for protecting data (e.g. museums protecting digitized images) is the need to produce a revenue out of the digitized material.</p><p>But the current income of CH institutions produced from digitized material is so low (e.g. take into account the profit from selling digital images) that we could easily endorse a policy where this small financial loss is counterbalanced by the public gain is sharing knowledge to foster education and research.</p><p>o "Geometry" vs. "metadata": what is more critical in terms of availability and quality of the data? Is it acceptable to have good quality geometric data, which is totally (or mostly) lacking proper metadata? The term metadata in this context includes both data on the represented artwork, as well as data on who did the digitization and how it was accomplished (the latter are generally indicated as provenance data)</p><p>8</p><p>. The importance of pairing visual data with associated metadata probably depends on the specific application context. For example, availability of metadata is really mandatory in restoration of CH and for related visual data (the information linking the restoration decisions and the data which justify those decisions…). In archaeology, both visual data and metadata are important, however the definition of metadata in support of archaeological practice is probably more urgent.</p><p>• Is big model management a solved problem? CH/DH is a domain where visual media are usually required at very high resolution, thus huge digital models are usually produced 9</p><p>. Until very recently, the size of the data often was a strong deterrent for handy management. Given all the multiresolution schemes presented in literature (e.g. progressive meshes, progressive view-dependent data transmission and rendering) and related advances, from a scientific/technological prospective data complexity is a tractable problem. But for many practitioners in DH, size of the data could still present issues for visualization and sharing. Here again some effort on training and consulting could make a difference.</p><p>• WebGL and performances of JavaScript (an interpreted language) can reduce the performances of web applications. This is especially true in the case of web-based modelling, which could not sustain the same level of efficiency and performance of desktop applications, unless the web application is demanding processing from some cloud resource.</p><p>• Finally, we should not forget that when the browser is the context to run a programme or to process some data, then this model introduces some intrinsic limitations (no access to local file system; memory limitation). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3D browsers: supporting just plain Visualization vs. more structured Analysis</head><p>The current trend in visualization is to move from plain visualization (I have the object virtually in my hands, I can interactively manipulate it to see from any side) towards tools enabling more sophisticated inspection &amp; analysis 10 , thus adding the related functionalities. Some of these that have been suggested are:</p><p>• Access to full data resolution (removing the constraints related to data quality, do not force users to render simplified, low resolution models).</p><p>• Support dynamic lighting, the user should be able to easily modify the direction of light (grazing light inspection, in real time).</p><p>• Measuring features: the visualization tool should support measurement of point-to-point distances, angles, and sometime the area of surface portions.</p><p>• Non-photorealistic lighting and rendering should be supported, to allow the production of rendered images that resemble the manual drawings or the illustrations (so common in archaeology or restoration).</p><p>• Cut-through sections (also exporting the profile as an independent assets, a cut profile which then becomes part of the available documentation).</p><p>• Produce maps and sections from the 3D model, in formats ready to be used by other applications.</p><p>• Detect similarity, symmetry or orbits in a single model or between different models.</p><p>• Provide instruments to record/frieze the camera position of specific views (like a landmark) and the possibility of visualizing the model using different shaders or rendering parameters.</p><p>• Provide instruments to compute the volume between the different layers in the sampling of an archaeological excavation (for example, in order to analyse the distribution of the artefacts).</p><p>• Automatic and user-assisted partitioning of a model or a scene.</p><p>• Produce exploded views (this is useful in the case of complex objects, built over a number of components).</p><p>• Support space warping approaches for enhanced visibility and inspection (an example is the unrolling of vases or seals, to allow presentation in a single visual space the decoration or incision wrapped over a solid object).</p><p>• Automated discovery of correlations between different objects.</p><p>• Compliant transparent rendering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Local processing vs. CLOUD processing</head><p>The Culture3DCloud platform 11 has been demonstrated at the Workshop. It is a web-based resource supporting the production of 3D models on the cloud. The system adopts a modern automatic photogrammetric approach (thus, the 3D model is created from a set of 2D images using the SfM approach; see the Overview Box 2 for an introduction). This approach has been demonstrated to be very effective for approach? Some examples of the cloud-based approach that we can envision for the future in CH/DH are:</p><p>• A cloud-based platform for semantic enrichment and visual analysis of 3D models in archaeology?</p><p>The cloud might provide both the required graphic interface and the data archival/retrieval resources.</p><p>• A cloud-based platform for archival and consultation of restoration data? In this case, the platform should provide an infrastructure needed to upload the digital model of the artwork under restoration, as well as all the features needed to upload &amp; link the restoration data and documents to the 3D</p><p>clone.</p><p>What such a platform should offer? I. Tools for progressive 3D acquisition? In some cases, we have to repeat digitization, to take into account the evolving status of an artwork or site (an example is recording the archaeological discovery sequence, sampling the digging progress at different times).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II.</head><p>Tools for visual data analysis? (See subsection 3.3 above).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III.</head><p>Tools for data annotation? (Please note that annotation requires non-local approach to data management as mandatory, since usually multiple actors are involved in the annotation process;</p><p>this type of feature is required in the documentation of restoration actions / phases).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV.</head><p>Tools for metadata codification/enrichment/query?</p><p>V. Tools for search &amp; retrieval over archives of 3D data?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI.</head><p>Tools for the production of synthetic graphical results? It is important to underline that the final goal in many applications is still to produce graphical results for publications or presentations.</p><p>While interaction is the approach endorsed at study time, the production of frozen/static representations is still the preferred media for documentation or dissemination. Therefore, having features for the production of graphical results could be very handy (e.g. similar in spirit or better than Trimble "layout": mappings, selection of drawing scales, adding annotations, measurements, etc.).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII.</head><p>[Future goal] An architecture that should allow the possibility to define plug-ins for the inclusion of higher-order analysis or simulation codes (examples: visibility analysis, acoustic analysis, structural analysis).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Interlinking 3D objects to other media</head><p>In many applications or uses in DH/CH, we are faced with the multimodality aspect of the data (RGB images, RTI, multi-spectral images, 3D models, 3D tomography data, video, sound, etc.); we cannot restrict our activity to just the task of acquiring and showing a single media (e.g. a 3D model). Conversely, we should often manage quite large number of different representations related to the same artwork.</p><p>Therefore, we need technologies able to manage multimodality in a global and comprehensive manner:</p><p>• Multi-sensors: data can be produced by a large number of different instruments and devices.</p><p>• Data can be multi-temporal or multi-spectral.</p><p>• This introduces the need of performing a correct and accurate registration of data (either spatial or temporal).</p><p>• We need to manage different scales and resolutions.</p><p>There are a number of open issues, both at the data production scale and at the visualization/analysis scale, since for all the above needs we still do not have a common platform (data management functionalities are often inside the specific device management interface or part of the proprietary instruments of technical labs).</p><p>Which GUI for the visualization/analysis/management of multimodal data? Do we need a specific and common GUI for managing multimodal data?</p><p>Here are a few recent examples relating this topic:</p><p>• The Culture 3D Cloud project developed at CNRS/MAP lab. This is a cloud-computing platform for the fully automatic 3D reconstruction of heritage artefacts starting from the simple upload of photographs on the web.</p><p>• The Aioli platform developed at CNRS/MAP lab. This is a flexible and easy-to-use image-based modelling tool that allows the digitization and semantic annotation of cultural heritage artefacts. It refers to an innovative acquisition-to-processing protocol that includes on-site acquisition and remote (cloud-based) geometry processing phases.</p><p>The implementation follows a workflow based on a flexible camera calibration and orientation methodology that facilitates the production of 3D representations by non-experts. The user only has to acquire various images of a cultural heritage object following a basic acquisition protocol and upload these images through the web interface. The digitalization will then be realised automatically by the platform.</p><p>The fully automatic processing pipeline extracts the tie points from the images and computes the camera calibration and orientation, followed by the generation of dense and accurate 3D models from the set of uploaded photographs. An indexation of the photographs according to their geometric position to the point cloud is being calculated allowing the user to perform semantic annotations on the images for analysis and documentation purposes. The annotated region on one photograph gets propagated automatically to all the other photographs matching its exact spatial position.</p><p>Photographs are, thanks to this feature, an analytical support for visual and metric comparisons between different temporal states of the same object.</p><p>The project of Aïoli is a community project aiming to construct collaborative methods for </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Search and retrieval over DB/archives of 3D shapes (shape-based)</head><p>New technology has also been recently proposed for shape-based search and retrieval over archives of 3D models 14 .</p><p>The question here is how far we are from approaches able to detect the subtle shape similarity that CH experts often require?</p><p>• The specific requirements of the DH domain are not just providing the tools for classification among classes of objects (statue, amphora, bust, etc.), but tools able to help users in finding "similar" artworks for study purposes. Detection of similarity in DH is much more than understanding a digital model is a bust or a face, thus we need to go much beyond classification. Those more advanced approaches should enable unsupervised discovery of shape "correlations".</p><p>• Possibly this could be done by individuating shape-based characteristics (either material-or colourbased) which allow one to recognize, to some extent, similarity (but the work here seems to be very domain-dependent: criteria for architecture will be different than the ones for sculpture or pottery).</p><p>• We should include the possibility of producing several possible results and allow the expert to evaluate a small/wide possible result set and take an informed decision (which could also be used to improve the knowledge built in the recognition systems, with a feedback loop).</p><p>• Reasoning at the scale of entire collections or even between collections?</p><p>• Do scholars really need this tools, or is it just a technology-driven topic? (Producing further evidence on this issue will be useful). The understanding is it might be very useful in order to create new potential classifications of artefacts, to understand better the diffusion and the distribution of a specific typology in architecture, pottery, etc. (if the origin of the object(s) is indicated), and to make comparisons that help interpretation.</p><p>It would be useful to illustrate some examples where such tools/technologies could be used in support of CH, also to clarify their potential impact:</p><p>• Being able to identify similar features in fragments of pottery 15 , as for example the same motif, can help formulation of hypotheses about the origin and type of pottery shred, or on the movements of craftsmen, or about possible connections in different geographical areas.</p><p>• Recognising similar features in sculptures, for example, the same "hairstyle" in Roman statues, helps dating the work of art we are analysing 16 . Chisel marks have been sometimes mentioned as an important clue in investigating an attribution hypothesis; automatic shape characterization able to detect and characterize chisel marks can help in this analysis 17 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Encoding/including time</head><p>How we can encode the concept of time in our digital models is still a largely open issue. The concept of time is a metadata issue, but it also has an impact on visualization and GUI of our visualization platforms.</p><p>Probably defining this information as a metadata could be sufficient to develop a tool to visualize 3D models according with a time frame.</p><p>Time is often not just a single axis, but at least two different axes: e.g. in archaeology we have the excavation time and the attribution time (the period associated to a specific parcel of land, e.g. bronze age)</p><p>Historical time can be visualized in four ways (following K. Pomian, 1984):</p><p>• Chronology (order of facts),</p><p>• Chronography (cumulation of events),</p><p>• Chronometry (repetition of cycles),</p><p>• Chronosophy (meaning of periods).</p><p>These different perceptions of duration have to be taken into account in dynamic modelling: in reverse engineering, in static restitutions/renderings, in retro-simulations (in motion) and in retro-conception (system).</p><p>Another vision is that 3D graphics can be conceived as a time machine, bringing us back to lost architectures or human processes/workshops/manual production expertise (e.g. following the examples presented in the historical Renault factory reconstruction which was presented at the workshop by Alain P.</p><p>Michel). In this process, 3D instruments could be intended as:</p><p>• 3D as an instrument for producing insight (while modelling in 3D a structure, I understand it better since I am forced to specify in unambiguous manner a number of parameters and relations between components) and for disseminating results.</p><p>• 3D as an instrument for collecting many data sets and linking them to a final model (metadata and representation of the analysis and process) and finally presenting to the public.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Impact on PARTHENOS</head><p>The impact of the themes treated in this section over the PARTHENOS community and work programme are listed in the following section. We list the sub-domains discussed and for each of them we define the possible outcomes or actions that could be activated in PARTHENOS. Those actions could be related to dissemination of knowledge (training) or to research/technological transfer efforts (development).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Web-based visualization technologies and related issues</head><p>• Training actions (remember the usual need of building a common language linking technologists and DH people; we should plan training actions at two levels: beginning/advanced).</p><p>• Production of Recommendations / How to guides, to disseminate and consolidate best practices.</p><p>• Devise proof of concepts for visualization tools managing diverse types of datasets or for collections of datasets?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3D browsers: plain Visualization vs. Analysis approaches</head><p>• Tools development: move from web tools implementing generalist visualization functionalities, to more specific analysis tools, fulfilling the needs of the DH community.</p><p>• Training actions: enabling our community to use and deploy existing web based resources.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Local processing vs. CLOUD processing</head><p>• Tools development (or setting up initiatives for sharing available resources).</p><p>• Training actions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Interlinking 3D objects to other media</head><p>• Managing multimodal data with integrated tools or repositories is quite a new approach in DH. We have some tools available (even in the open source domain) for which training should be invested in.</p><p>For some other cases, we could envision some development effort of new tools.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Search and retrieval over DB/Archives of 3D shapes</head><p>• On this subject we need further study and research, both at the technology and humanities level: to find a clear justification and research objectives according to DH user requirements, to find proper use cases, to considerably improve current technologies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Encoding/including time</head><p>On this subject we need further study, to find a clear justification according to user requirements, to verify if a common way to manage time could be shared between different stakeholders (should we develop a model customized towards the requirements of the archaeology domain, or following a set of requirements common to several sub-domains?).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">3D Objects' Description with metadata and their Long Term Preservation</head><p>The basic questions that emerged while planning the Workshop session on "3D Objects' Description and</p><p>Long Term Preservation" are as follows:</p><p>• Metadata formats for 3D objects. Use of Europeana CARARE model as a template?</p><p>• Quality and characterisation of metadata for 3D objects. E.g.: what about integrating "historical metadata" in 3D modelling/3D models (with linked extra data)?</p><p>• Need of platforms/tools providing file type conversion features (ensuring preservation of old file types) and verification tools.</p><p>• Description of linked data.</p><p>The work of the session was organized consequently and this section presents the results of the discussion and the insights gathered from it.</p><p>The session, therefore, discussed the state-of-the-art in generating and managing metadata in order to support retrieval and reuse of 3D objects across scientific domains. Central to the discussion was the uniqueness of PARTHENOS as a research infrastructure supporting generation and reuse of data across scientific domains from cultural heritage, to linguistics, to history, archaeology and more. For this reason, the challenge of considering the required metadata for 3D data generated in these networks is multiplied by the varied kinds of interest that are brought to bear by different disciplines and practitioners. The task of recommending one or more target schemata for capturing metadata requires a comprehensive analysis of the cross-disciplinary needs, identifying the discipline independent requirements, and yet at the same time should not limit possible expressivity or new research directions which might suggest other/additional metadata requirements.</p><p>It was noted that this discussion fits clearly within the mandate of PARTHENOS WP4 on standards.</p><p>Therefore, it was decided that the outcome of the workshop should be collated and the issues raised summarized in the coming months, in order to provide a contribution/recommendation as part of the deliverable scheduled for April, 2017. The target would be to create a recommendation for the reference schema or schemata that are suggested for use.</p><p>In order to address the metadata challenge for 3D objects in an interdisciplinary environment, it was argued that we should consider: a) a mission statement, b) the necessary elements of proposed schema / strategy, c) past work / known schemas and the d) the resources available in the PARTHENOS network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mission Statement</head><p>It was noted that the guiding reason for addressing the metadata issue for 3D objects must be clearly stated in order to have a clear direction in moving forward in researching the available sources on this question and proposing new solutions.</p><p>The team came to the following statement: cross-disciplinary discovery of and access to 3D objects, improve interoperability and promote reuse of these objects for scientific and educational purposes."</p><p>This statement makes reference to three founding principles:</p><formula xml:id="formula_0">1) Discovery / Access 2) Reproducibility / Comparison 3) Debatable / Semantic</formula><p>That is to say, while elaborating a schema or strategy for metadata generation and management for 3D objects it is necessary to bear in mind how to facilitate the principles of enabling discovery/access to 3D (e.g.</p><p>Google style finding or structured registry), reproducibility (e.g. the ability to reuse or reproduce a model because of transparency of its provenance provided in metadata) and debatable (e.g. metadata should potentially enable the critical scientific use of the object either to understand the object which it represents or to question the accuracy of the representation).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sarah Tournon-Valiente, Archeovision Lab., CNRS, France</head><p>Working on creating 3D metadata schema for long-term preservation, Archeovision CNRS worked on a very minimalist schema endeavouring to include the necessary elements for this purpose. The task of identifying and representing these necessary elements is challenging and on-going.</p><p>Nevertheless, for conceptualizing the first step of such a schema, we concentrated on:</p><p>• Describing the archaeological project that produced the 3D object, providing practical information on the identity of the project such as:</p><p>o Name of the project/archive;</p><p>o Goal (scientific and technical goal, research project);</p><p>o Actors (producer, partner, team);</p><p>o Date (archaeological, project).</p><p>• Describing the archive package (how many 3D objects in how many files, how many sources).</p><p>• Describing each virtual object:</p><p>o How it stands (digitized description) (maillage);</p><p>o How it has been produced (technically) (3D geometry, texture);</p><p>o From which scientific sources it has been elaborated (group Source).</p><p>The main strategy in supporting long-term preservation through a minimal schema was to stay realistic and pragmatic according to the recommendations of the CINES <ref type="bibr">[1]</ref>. The information selected for documentation was kept to a minimum of vital information in the archive so to be able to understand the archived 3D objects in the long run.</p><p>That being said, our schema is flexible enough and left open, so as to be able to contain as much information as the actor completing the metadata wants to include <ref type="bibr">[2]</ref>.</p><p>This strategy is elaborated in full knowledge of other potentials schemas <ref type="bibr">[3,</ref><ref type="bibr">5]</ref>. These, however, focus on the interoperability and/or the connection to CH resources themselves, to be able to connect 3D objects between each other or to other kind of web resources, such as museum collections. Currently, our schema is proposed in order to provide a focus on preservation rather than communication.</p><p>This strategy can be supplemented by mapping this schema to as many known metadata schemas as possible <ref type="bibr">[3]</ref>. The implemented preservation schema already uses aspects of Dublin Core. But a complete mapping has not yet been made and it would be the focus of the forthcoming 3D-SHS Consortium<ref type="foot" target="#foot_13">18</ref> of French TGIR Huma-Num.</p><p>Our complete schema, its description and its implementation will be published by 3D Consortium edition, by the end of the year (2017). Before its publication, we are actually focusing on testing its implementation based upon some 3D objects produced by 3D Consortium's members as part of a</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Necessary Elements of Proposed Schema / Strategy</head><p>Based on the mission statement, the group outlined the basic elements that should be addressed by the proposed schema / strategy. These should include:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Actors</head><p>The agents involved in the creation, modification, maintenance, enrichment and critique of 3D models play a crucial role in the understanding of a 3D object as they provide the original knowledge of its creation and may hold valuable additional data for the interpretation and reuse of the model.</p><p>Objects Aside from the digital object itself, the objects of which the 3D object is a model and their aspects are of key importance in order to be able to understand and evaluate the information delivered by a 3D model Goals 3D models are elaborated towards some end. They do not form and cannot be seen as digital replacements of the actual objects of which they are models. Rather a 3D model plays a functional purpose in a scientific process to understand some aspect of an object. Explicitly documenting such goals of creation/modification/use of models is crucial to their scientific evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Tools</head><p>Playing an effective causal role in the produced model are the sampling devices and the digital tools adopted for the digitization, as well as their use at certain moments in certain environments using specific variables. Linking 3D models to the causal processes that created them is crucial in supporting their interpretation and reuse.</p><p>It was noted that inspiration and data could be taken from Dublin Core profiles in order to try to flesh out the factors of relevance to specify in declaring a set of descriptors for these different aspects. Additionally, it was noted that protocols like OAI-PMH, which enable access to such profiles and/or similar initiatives should be considered such that metadata is not simply generated but exposed and made available. This led to a discussion of how to best reuse past work and known schemata.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Past Work / Known Schemas</head><p>The key point made in discussing the possibility of articulating a new or adapting/adopting a past schema, was that the work in PARTHENOS does not take place in a vacuum but can already pick up and benefit from existing efforts taken at project, national and European levels. The basic argument was made that elaborating a new standard that will stand as yet another standard amongst standards will not have the desired effect of creating general accessibility and reusability. The key to understanding the best strategy for metadata in a multi and interdisciplinary network such as PARTHENOS is to understand the existing standards and schemata and how they might be brought to bear or together in order to serve the purposes of our network. The following list of past projects and proposed schema was thus elaborated.</p><p>Six key metadata schemas for 3D models have been identified. They have been elaborated within the scope of previous projects that have especially important bearing on PARTHENOS:</p><p>1. ARCO  Reference: http://3dicons-project.eu/eng/Resources/Documentation/CARARE-2.0-schema</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CRMdig</head><p>CRMdig is an ontology and RDF Schema to encode metadata about the steps and methods of production ("provenance") of digitization products and synthetic digital representations such as 2D, 3D or even animated models created by various technologies. Its distinct features compared to competitive models are the complete inclusion of the initial physical measurement processes and their parameters.</p><p>Reference: http://www.ics.forth.gr/isl/index_main.php?l=e&amp;c=656</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LIDO</head><p>The schema is intended for delivering metadata, for use in a variety of online services, from an organization's online collections database to portals of aggregated resources, as well as exposing, sharing and connecting data on the web. The strength of LIDO lies in its ability to support the full range of descriptive information about museum objects. It can be used for all kinds of object, e.g. art, architecture, cultural history, history of technology, and natural history. LIDO supports multilingual portal environments. It does this by having a language attribute that can be associated with each element, or more generally, with the group of descriptive elements for fully multilingual resources.</p><p>Reference: http://network.icom.museum/cidoc/working-groups/lido/what-is-lido/</p><p>The METS schema is a standard for encoding descriptive, administrative, and structural metadata regarding objects within a digital library, expressed using the XML schema language of the World Wide Web Consortium. The standard is maintained in the Network Development and MARC Standards Office of the Library of Congress, and is being developed as an initiative of the Digital Library Federation.</p><p>Reference: http://www.loc.gov/standards/mets/</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>STARC Metadata Schema</head><p>The metadata schema developed by the STARC team has the goal to enable data interoperability and access to the digital resources stored in the local repository. Its structure allows retrieving models, activities, decision and answers the research question on how data can be used for data interpretation and re-used to perform further analysis and post-processing of raw data. The datasets stored in STARC repository refer to 2D and 3D archaeological data including archaeological sites, museum objects and architectonic elements.</p><p>The schema was created after an assessment <ref type="bibr">[5]</ref> of the most common metadata schemas that highlighted what was missing from the standards used by most cultural heritage institutions.</p><p>Reference: Ronzino, P., Hermon, S., Niccolucci, F., A metadata schema for cultural heritage documentation, V. Cappellini (ed.), Electronic Imaging &amp; the Visual Arts: EVA, 2012.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Resources available in Network</head><p>We noted that the work to determine the best recommendations for standards for 3D object metadata in an interdisciplinary framework such as PARTHENOS would require live, agile testing of hypotheses and conclusions. Therefore, the discussion turned towards what resources were available in PARTHENOS to be used as initial test data. It was pointed out that the data to be worked with would need to be open and available to the public, or to be reasonably foreseen to be open to the public within the near future, so that the results obtained could be demonstrated in an open and transparent way.</p><p>We agreed that we should identify those 3D model repositories existing within the network. Those would also include peculiar but important datasets such as:</p><p>• Stereoscopic Images on Isidore<ref type="foot" target="#foot_14">19</ref> (this is a series of old pairs of stereoscopic images digitized, a sort of ancestor of 3D models).</p><p>The list of visual resources was left to be further elaborated by the responsible WP (see section 4.5). It was underlined that the reuse of PARTHENOS resources that are already open data is important not only to bring results within the network but also in order to not run into problems of IPR.</p><p>This initial list is envisioned to be enriched by outreach to the PARTHENOS network and by research into available repositories outside the network that it would be necessary and relevant to cover in formulating our recommendations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Impact on PARTHENOS</head><p>PARTHENOS as an inter-disciplinary network of Research Infrastructures has the possibility to take a new, wider view of the question of metadata for 3D models by building from the multi-disciplinary base it provides to set up a generic perspective on the needs for describing 3D models in their full provenance context.</p><p>The decision of which schema or schemas to recommend falls within the remit of WP4. The work undertaken during this session and followed up by the research of relevant previous projects and existing schema should be combined with an analysis of their use/usefulness as discovered empirically by analysis against existing repositories of 3D model data within and outside of the PARTHENOS network. This list remains to be compiled and used.</p><p>Another important resource to keep in the loop with regards to the progress of this task are the WP6 implementers of PARTHENOS who could provide search and display functions based off these metadata recommendations.</p><p>On basis of the above, a first draft recommendation on schema/ strategy for 3D object metadata could be</p><p>articulated. An open discussion was whether a tool for generating/managing such metadata could be within the scope of PARTHENOS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">3D, Cultural Heritage and Museology Mission Statement</head><p>The questions that emerged during the Workshop session on "3D, Cultural heritage and museology" share a common denominator, which is the issue of reusability of 3D objects in broader contexts than research.</p><p>More precisely, the critical role of museology in structuring and extending the 3D objects' lifecycle was pointed out.</p><p>To facilitate this reusability, some work is needed in several domains: the accessibility of 3D objects in the dedicated repositories (Sketchfab, to make a single example) should be adapted to serve the community needs. Different approaches coexist, based on tags, on metadata, or on shape-based criteria, and a review of current status and museums requirements is probably a necessary.</p><p>A related problem is the preservation of the content produced for (interactive) exhibitions (e.g. http://archives35verso.artefacto.fr/) and how we could search, retrieve and reuse components produced for previous installations/projects.</p><p>Finally, there are a number of issues related to ethics and intellectual property rights at European level for 3D objects that have to be analysed and discussed.</p><p>The work of the session was organized consequently and this section presents the results of the discussion and the insights gathered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Define explicit rules around 3D developments, uses and reuses</head><p>A starting key point is to define good practices (rules / guide for users and re-users of 3D historic developments). The importance of building bridges between different communities (e.g. cultural institutions / social sciences scholars / 3D scientific producers) is also highlighted.</p><p>Three aims and tasks emerged from the discussion:</p><p>1.</p><p>Discuss on common values in sharing knowledge &amp; practices.</p><p>The aim is to share best practices but to avoid imposing a one best way. Define which are the potential positive effects of moving from a private/proprietary model concerning digital 3D assets (each scholar produces the 3D models needed for the research planned) to a shared model (scholars could search and retrieve the required models from the web, possibly with a controlled authentication of the producer, provenance data and some quality lab). How can we foster this radical change of model? Could we envision rewarding policies that could speed up the adoption of the shared model?</p><p>2. Do our best to build a programme adapted to different disciplinary rules.</p><p>What kind of common rules and charters can we write and what practices can be implemented? Big players can provide a lead and an EU institution (PARTHENOS?) the management.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.</head><p>Take into account the market economy vs. public service (authors and artists producers of images or 3D models).</p><p>We should not be naive and exclude this market; conversely, we should define rules and best practices to participate in this economy. Behind the data reusing approach are some issues and policies that have to be modified or created by scratch, such as: how do we add references to provenance of the data used in research (in the case it has been shared by third parties), how do we provide proper citations to the authors of 3D models, how these data could be communicated to the authors (for authors of shared material it is quite complicated to gather info on reuse of their data if this is only provided in reference lists or acknowledgement sections of published papers). Some ideas for different policies emerged in the discussion:</p><p>• Investigate different types of sharing -share low-res, keep hi-res.</p><p>• A 3D asset could be produced as a "model" of the original artwork (a digital clone of the real) or as a "maquette" (mock-ups, i.e. a derived artefact, which might imply not only a technical work but also a creative contribution). There are things that can be shared and others that can't.</p><p>Finally, museums or heritage curators and institutions are important partners in the development of digital 3D objects (and related digitization and reusing processes). In this perspective, the notion of "valorization" is crucial both in the renewal/enrichment of conservation practices, or in objects of museology mediation.</p><p>It seems there are four types of partners to be considered in the process:</p><p>• 3D scientific developers and producers,</p><p>• Social sciences scholar (direct) users of digital humanity technologies to produce knowledge (social and human sciences),</p><p>• Cultural institutions (e.g. museums or restoration laboratories),</p><p>• Other end users (e.g. applications in education).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Use and reuse of 3D objects in restoration, conservation and exhibition: museology as a part of 3D objects life cycle?</head><p>3D models should be considered as research instruments for Cultural Heritage scholars, and professionals as well as end of the line digital mediation products served to a larger public. However, tensions may occur when 3D models appear as substitutes of the heritage objects (which they are not) or when the demand for 3D models is justified by the production of a (one shot) museum animation. For instance, 3D objects are increasingly used in the context of exhibitions, like the 3D mockup of the city of Nantes in 1900 (see below).</p><p>But 3D technologies are also very powerful practices in museum preservation and study, as presented by Clotilde Boust (C2RMF, France). Unfortunately, most of the time, the 3D objects are still used in an empirical case-by-case way, with no systematic procedures. Moreover, very often the museum staff is only the "commissioner" of the work, that is then commissioned either to a scientific lab (when the financial resources are coming from an EU or national project) or to a commercial company. In both cases, the result is that technical choices are done by third parties, often the CH institution may lose memory of the modelling choices made and does not maintain a coherent best practice approach common to all projects developed in a time span by a single institution.</p><p>54 Therefore, it is recommended that museum, as "clients", and research labs or commercial companies, as "3D models creators", should sign some sort of Memorandums of Understanding, where the modelling protocol, the tools and methods used are clearly explained, in order to ensure the sustainability of the use of the 3D models for the Cultural Heritage institutions themselves and to support future reuse of the results of the digitization actions.</p><p>Overview Box 6 -3D digitalisation of Nantes historic harbour. At that time, only very little information about the object and the Nantes harbour's history was displayed. The scale model could provide visitors with an interesting historical feedback about itself and some key notions about harbour history and industrial heritage. Indeed, Nantes harbour has a great historical potential thanks to its rich heritage: national heritage cranes, one of the first water mill in concrete, shipyards, vessels and many companies dedicated to shipbuilding processes (chemicals, wood industry, assembly…).</p><p>Starting from some research activity on reverse engineering and knowledge management for technical heritage, historians, curators and engineers worked together to design a framework dedicated to this historical scale model's digitization and promotion. This framework was built upon three main principles:</p><p>• Separation between technologies used for promotion and the historical material for reusability,</p><p>• Long-term documentation of the object with further research results,</p><p>• Collaboration between historians, engineers, curators, visitors.</p><p>Finally, a dedicated knowledge database has been designed to capture historical material and historians' knowledge. The city harbour points of interest are connected to related historical documents and pieces of information provided by historians and curators. One of the specific features of the system is the connections made between those pieces of information. Based on similarities of interest between objects, the different points of interest of the history of the harbour are connected providing serendipity during the exploration.</p><p>This part was done partially in collaboration with experts, but also thanks to algorithms thus opening new fields of research in information processing.</p><p>This system also allows a participatory experience for the different types of users. Museum visitors can help contribute to the project by providing material related to any harbour's heritage topics (photographs, stamps, postcards, testimonies). These contributions, after being digitized can be uploaded to the database and keep the project going. Museum curators can use the material to create new interfaces like geolocated applications, bringing knowledge out of the classic museum tour.</p><p>As far as a museum collection object is concerned, a museographic system has been designed [See picture </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Enhancing 3D models repositories &amp; searching indexation functionalities</head><p>Users within the Arts and Humanities research communities routinely access information available on the Web. Thus, finding and visualising 3D representations of heritage artefacts should be a natural extension of this process. In order to support this, there is need to provide effective search and retrieval functionalities for user to find and access the 3D content which fulfils their specific needs. The use of 3D technologies for scientific documentation and analysis views the scholar as the main user of 3D technologies. However, this is a restricted view. Instead, a greater variety of users might benefit from access to these resources.</p><p>It is important to understand the applications and solutions which 3D modelling of heritage artefacts can provide these diverse users. At this point, it is useful to distinguish between browsing and searching for information. Browsing is the process of skimming or seeing what is available, while searching is the process of finding a piece of information that answers a specific question. Certainly some users might be more interested to browse for information rather than to search with a specific question in mind. Hence, the requirements for searching technologies are much more complex as they involve an extra step of specifying the "question" (language, visual or shape queries) in the user's mind.</p><p>Arts and Humanities users also have specific requirements for tools that enable to visualise and analyse the 3D models. These requirements bring additional challenges for 3D web publishing solutions that should provide basic functionalities, such as plain visualisation, or also more advanced features (e.g. supporting data analysis and data fusion).</p><p>Overview Box 7 -Repositories for 3D models and searching features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>K. Rodriguez, Univ. Brighton, UK</head><p>One of the current challenges to the wider use of 3D content remains the issues of access.</p><p>Although a great amount of content is being generated by a diversity of technologies, very little content is easily accessible for use and reuse. To solve this issue, there is a need to improve the searching and browsing capabilities of repositories where the content is stored.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">State of the art in searching and browsing technologies</head><p>Existing user interface solutions for searching and browsing are limited in the Cultural Heritage (CH) domain. Currently, the service requires of content providers of which there are currently only two: an Italian ethnomusicology and a furniture archive.</p><p>Moreover, Pena Serna (2011) et al. present results of the 3D-COFORM project, which developed an interface for browsing and searching 3D content in museum's repositories. The interface enables building complex queries through a user interface, which uses categories, relationships, and keywords that the user want to search for. The search space is restricted to the data ingested in specific repositories to which the interface connects to.</p><p>Other relevant searching and browsing systems include systems that search 3D repositories given a 3D model as a query. <ref type="bibr" target="#b40">Pascoal et al (2012)</ref> and Hildrebrand and Alexa (2013) report search systems which allow 3D object retrieval given a 3D model as a query.</p><p>Most of the systems described rely on having access to a large amount of multimedia content, including 3D content. But most importantly these systems only work with specific datasets, as it is a previous requirement for the content to be associated to a richer set of semantic metadata. It is also a requirement that this metadata is in a format which is understandable to the search engine.</p><p>Currently, the content available on the web, such as images and 3D models are not associated to this semantic information. The following subsection will deal with the state of the art for the semantic enrichment of 3D data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Semantic enrichment of 3D data to support browsing and searching</head><p>More often than not, 3D models are stored without being associated to very much related information. Hence, the semantic enrichment of 3D content is the process of associating (either manually or automatically) information to 3D models to support its discovery. Automatically extracting semantic information from a 3D model is a complex process as visual assets can be 1. Perceptual descriptors: describe the attributes of an object which can often be measured. These include visual elements (e.g. shape geometry and topology), sound, smell as well as physical and chemical material properties.</p><p>2. Interpretive descriptors: describe the attributes that are more subjective and are the opinion of a particular user. These include the content or story depicted in the object, the provenance of the object, value, principles of design and style.</p><p>3. Reactive descriptors: describe the attributes that reflect an emotional or intellectual reaction of a user when interacting with the 3D model. These include abstract concepts and descriptors, such as something representing particular feelings, events or cultures.</p><p>Furthermore, information regarding the digitisation and post-processing steps also needs to be recorded. Once all the relevant information to describe an artefact has been identified, the next step is to associate this information to a 3D representation of the object. This related information might be documented:</p><p>• In a structured format in an existing Collection Management System, database or semantic network; or</p><p>• In an unstructured format such as text and images extracted from relevant documents and publications.</p><p>Existing manual solutions for semantically enriching a 3D model allow users to annotate a 3D model with relevant information. Automatic or semi-automatic solutions often rely on computer vision and graphic techniques which aim to understand the semantics of 3D content by analysing its shape. These techniques include shape segmentation, labelling, classification, matching and retrieval methods. Of particular interest are the techniques for shape classification, which can support browsing and the techniques for 3D shape retrieval with can support searching. 3D shape retrieval techniques can be classified according to the type of query they use. For instance, the query can be text-based or content based, where a sample 3D shape is given and the goal is to retrieve similar ones. These techniques for classification and retrieval often rely on descriptors which encode the features in the shape for comparison. <ref type="bibr" target="#b43">Kazmi et al. (2013)</ref> presents a suitable review on 2D and 3D shape descriptors.</p><p>Related research in the area of cultural heritage focus mainly on supporting semantic enrichment as well as searching and browsing techniques. For instance, Lo Buglio et al (2016) proposes an approach that rely on data accumulation to understand high level semantic structures from the comparative analysis of common low-level geometric features of 3D models. Rodriguez Echavarria and Song (2016) propose the use shape similarity between decorative patterns to understand how the 3D model can be described in terms of its design style. In addition, Sfikas (2014) proposes a method for partial matching and retrieval of 3D models of archaeological objects based on image queries.</p><p>On the other hand, 3D is also an excellent mean of popularization and valorisation of scientific results which are thus made accessible to a larger audience. It can meet both the political mission of research funding and the deontology of restitution, and serve as an "edutainment" tool. The bottom-up client-server mechanism is not relevant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Impact on PARTHENOS</head><p>The issues raised by the reuse of 3D objects relate closely to the use of appropriate standards and methods able to guarantee their long-term usability. This need has been stressed in all the previous sections.</p><p>However, the participants of the session "3D, Cultural Heritage and Museology" agreed that some efforts should be put to develop best practices related to use and reuse policies of 3D objects. These best practices could take the form of a guide, helping researchers in defining the access and reuse policy of the material they produce. PARTHENOS is currently developing such a guide within WP3, as an interactive Common Policies Wizard. In this broad context, 3D specialists should establish a more specific best practices guide regarding the access and the reuse of the objects they produce. These guidelines could be, in a second phase, integrated in the Common Policies Wizard. The solicitation of interdisciplinary research programs, which associate technological, conceptual and knowledge challenges, may be a way to consolidate and disseminate these best practices.</p><p>About the level of the dissemination of 3D objects to a wider public, it is stated that scientific 3D imaging should be presented in a specific visual language, and be inserted in public usage scenarios precisely designed. Sketching these design methods is still a pending task, which should be based on the necessity to render properly the scientific reasoning rigour and the subtle points expressed by the hypotheses. A crucial question is the responsibility of this task. Should it be carried out by the scientific labs, considering it as a significant part of the research project, or by other (private) structures, with all the risks this entails. This question is highly decisive for Archaeology and Cultural Heritage, as they face a high demand from the society (education, tourism, local development, etc.). The multifaceted nature of 3D models offers new possibilities in this domain, allowing for new ways of knowledge sharing.</p><p>Finally, the Data Reuse Charter, a service developed by PARTHENOS, amongst other partners, could be a real added value to the reuse of 3D objects. Its aim is to develop an environment to set out the conditions of collaboration between Cultural Heritage Institutions and scholars. It simplifies information retrieval and transactions related to the scholarly use of cultural heritage data. The Charter does not express constraints regarding data reuse conditions, but rather reflects the actors' policies. It does encourage good practices by offering guidelines based on recognized standards. In other words, scholars that produce 3D objects could use the Charter to declare the technical and legal requirements to abide by in order to reuse such pieces of work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Concluding remarks</head><p>The White Paper on 3D objects for Humanities embraces the whole lifecycle of such objects, from the production to the reuse, including processing, description and visualization.</p><p>This lifecycle involves many highly technical steps and the use of a wide range of technologies, methods and tools, which evolve quickly. For each step, if professionals are interested in long-term solutions, this diversity of practices and protocols is a hindrance to agreement on a unique standardized solution that could fit all the needs and solve all the raised problems.</p><p>Consequently, all contributors agree on the crucial importance of producing guidelines and documenting their own research practices. This has been pointed out by all the contributors, in particular at both ends of the 3D objects' lifecycle: the digitization/modelling phase, where these objects are created and thus have to be documented properly, and the data reuse phase, where the availability of proper metadata and accessible archives is a pre-condition for further reuse of digital assets. PARTHENOS, in particular with the development of the Standardization Survival Kit, aims at being the place where these good practices can be recorded and presented, by means of specific research scenarios where the handling of 3D objects is the core activity, and that would be presented together with documentation, literature and technical resources.</p><p>On one particular aspect, the 3D object metadata format, 3D specialists and data modelling specialists are asked to build, together within the PARTHENOS infrastructure, a standardization proposal based on the outcomes and the questions raised in the White Paper, considering that solid projects already exists and the related expertise could be used as baseline.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>[ 1 ]</head><label>1</label><figDesc>Photogrammetric Acquisition and Processing Methodology for Monitoring Conservation andRestoration Studies.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>[ 4 ]</head><label>4</label><figDesc>Boochs, F., Bentkowska-Kafel, A., Degrigny, C., Karaszewski, M., Karmacharya, A., Kato, Z., ... &amp; Tamas, L. (2014, November). Colour and space in cultural heritage: Key questions in 3D optical documentation of material culture for conservation, study and preservation. In Euro-Mediterranean Conference (pp. 11-24). Springer International Publishing.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>10 R. Scopigno, M. Callieri, P. Cignoni, M. Corsini, M.Dellepiane, F. Ponchio and G. Ranzuglia, "3D models for Cultural Heritage: beyond plain visualization", IEEE Computer, July 2011, vol. 44 no. 7, pp. 48-55. 11 http://c3dc.fr/ (accessed on April 21st 2017) CH/DH, since the users could demand the (heavy) processing of the 2D images from a remote cloud-based computing resource, without having to bother with the requirements in terms of data size and processing resources. Do we need similar cloud-based platforms supporting also the further use of the data? Or should we keep the consolidated "all data and related processing resources managed by means of my laptop"</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>13 .A</head><label>13</label><figDesc>documenting and analysing cultural heritage artefacts. A large-scale-scenario is being imagined, making it even possible to use mobile devices such as tablets for on-site acquisitions and annotations by non-experts in order to contribute to the collaborative semantic-aware geometric data acquisition and processing framework. The development of Aïoli is based on the TAPEnADe (Tools and Acquisition Protocols for Enhancing Artefact Documentation) project and the C3DC cloud-computing platform for the fully automatic 3D reconstruction of heritage artefacts starting from the simple upload of photographs on the web. Furthermore, open source code, algorithms and applications like MicMac, Potree and Potrace are implemented in the workflow for the automatic processing pipelines for the on-site image-based modelling and semantic annotation propagation of Aïoli. • The CHER-Ob platform developed at Univ. Yale, Computer Graphics Group 12 . This is an opensource platform to simplify the visualization and analysis of visual data, providing a unified GUI and common visualization features -see the CHER-Ob platform at: http://graphics.cs.yale.edu/site/cherob-open-source-platform-shared-analysis-cultural-heritage-research. The following figure shows a visual analysis session over different media. A snapshot from the GUI of the CHER.Ob platform (Yale Univ.) Moreover, having different data modalities means also that multiple media can be used to present or to tell the story of an artwork. In this context, we need tools enabling the construction of multimedia presentations, where different media could be inter-linked in the context of an interactive presentation. Some experiences in this direction have been presented in the Ruthwell Cross project snapshot from the Ruthwell Cross project, where a web-based tool supports navigation over the 3D representation of an artwork and interlinks interactive visualization with a more classical textual description.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>CARARE 2 .</head><label>2</label><figDesc>0 (3D ICONS)Version 2.0 of the CARARE schema was prepared in the framework of the 3D-ICONS project. The schema is intended to support the delivery of metadata to the 3D-ICONS service environment. The strength of the schema lies with its ability to support the full range of descriptive information about monuments, building, landscape areas and their representations in both 2D and 3D. The CARARE schema is an application profile of the Europeana Data Model (EDM). The 3D-ICONS project extended the "activity" class to include</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>F</head><label></label><figDesc>. Laroche, Ecole Centrale de Nantes, LS2N, France Among the hundreds of thousands of objects hosted by the Musée d'histoire de Nantes -urban history museum located at the Château des ducs de Bretagne, there is one scale model of the city harbour as it was at the beginning of the twentieth century. This scale model, designed by Pierre-Auguste Duchesne in 1899 for the 1900 World's Fair in Paris, is 9.20 meters long and 1.85 meters wide, modelling the city at a 1/500 scale. Such an object is quite uncommon and makes the object significant among the museum collections.Back in 2007, the museum started collaboration with the city's University and an engineering school (Ecole Centrale de Nantes) to set up a research project around this object and related industrial heritage. The question was: would it be possible to use this object as a reference witness of urban history with museographic techniques and novel interdisciplinary research methods?</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>and video-projectors. Historical material is accessible through touch screens by selecting areas of interest on a high-resolution scrollable photograph of the scale model. Video projection makes the link between virtual actions on the screen and the real object selected on the scale model.One of the emblematic technical systems in the history of Nantes harbour is the transporter bridge built in 1903 and dismantled in 1958. It is modelled on the scale model and historical information is available about this object of Nantes industrial heritage. Based on historical sources like original technical drawings and notes, we designed a 3D mock-up of the bridge. This virtual artefact can be added to the existing documentation in the knowledge database about Nantes harbour industrial heritage. Moreover, it can be used for augmented reality applications. In addition to displayed information through the museum interactive application, one can virtually contemplate this technical object on the actual area it was located, get access to more detailed information, and operate it virtually.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="40,81.50,198.26,431.84,260.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="41,95.05,76.85,404.88,268.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="58,56.70,76.85,478.35,222.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Steiner et al. (2012) reports the result of the I-SEARCH project, which developed a framework for search and retrieval of rich media content from large-scale databases. The i-search portal (http://vcl.iti.gr/is/) offers a user interface which can handle different types of multimedia content, including text, 2D image, sketch, video, 3D objects and audio. Multimedia data types use low-level descriptors represented in a formal description called Rich Unified Content Description (RUCoD).</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>See: http://www.parthenos-project.eu/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>M. Callieri, M. Dellepiane, P. Cignoni, R. Scopigno, "Processing sampled</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2"><p>3D data: reconstruction and visualization technologies", Chapter in "Digital Imaging for Cultural Heritage Preservation", F. Stanco, S. Battiato, G. Gallo (Ed.s), Taylor and Francis, page 103--132 -2011.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_3"><p>D. Koller, M. Turitzin, M. Levoy, M. Tarini, G. Croccia, P. Cignoni, R. Scopigno "Protected Interactive 3D Graphics Via Remote Rendering", ACM Trans. on Graphics, vol. 23(3), 2004, pp. 695-703.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_4"><p>F. Ponchio, M. Dellepiane, Multiresolution and fast decompression for optimal web-based rendering , Graphical Models, Volume 88, page 1-11 -November 2016.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_5"><p>F. Uccheddu, M. Corsini, and M. Barni. "Wavelet-based blind watermarking of 3D models." Proceedings of the 2004 workshop on Multimedia and security. ACM, 2004.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_6"><p>An example of company who is following this policy is Fratelli Alinari (http://corporate.alinari.it/it/); they have marked all items in their catalogue of historical photographs and actively persecute any unallowed (commercial) use.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12" xml:id="foot_7"><p><ref type="bibr" target="#b16">Shi, Weiqi. et al. 2016</ref>. "CHER-Ob: A Tool for Shared Analysis in Cultural Heritage," proceedings of EUROGRAPHICS Workshop on Graphics and Cultural Heritage (2016), http://graphics.cs.yale.edu/site/publications/cher-ob-tool-shared-analysis-cultural-heritage?destination=node%2F197 (accessed on April 21st 2017)</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13" xml:id="foot_8"><p>Leoni C., Callieri M., Dellepiane M., O'Donnell D., Rosselli Del Turco R., Scopigno R. "The dream and the cross: a 3D Scanning project to bring 3D content in a digital edition". In: ACM Journal on Computing and Cultural Heritage (JOCCH), vol. 8 (5) article n. 5. ACM, 2015.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="14" xml:id="foot_9"><p>D. Koller, B. Frischer, G. Humphreys. "Research challenges for digital archives of 3D cultural heritage models." journal on computing and cultural heritage (JOCCH) 2.3 (2009): 7.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="15" xml:id="foot_10"><p>A. Koutsoudis, C. Chamzas, "3D pottery shape matching using depth map images", Journal of Cultural Heritage, Volume 12, Issue 2, April-June 2011, Pages 128-133</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="16" xml:id="foot_11"><p>Zhang, Y., et al. "Classical sculpture analysis via shape comparison." Culture and Computing (Culture Computing), 2013 International Conference on. IEEE, 2013.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="17" xml:id="foot_12"><p>Pietroni N., Corsini M., Cignoni P., Scopigno R., "An interactive local flattening operator to support digital investigations on artwork surfaces". IEEE Trans. on Visualization and Computer Graphics. 2011. Vol.17(12):1989-96.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="18" xml:id="foot_13"><p>See: https://shs3d.hypotheses.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="19" xml:id="foot_14"><p>Archéovision : les collections stéréoscopiques de la CLEM https://www.rechercheisidore.fr/search/?source_tree=10670/3.mq7wsv%7C10670/2.iot15b (accessed on April 21st</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_15"><p>2017)   </p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>validation process of the schema.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Executive Summary</head><p>With this White Paper, which gathers contributions from more than 25 experts of 3D imaging, modelling and processing, as well as professionals concerned with the interoperability and sustainability of research data, the PARTHENOS project aims at laying the foundations of a comprehensive environment centred on the researchers' practices concerning 3D digital objects.</p><p>The topics addressed in the document are meant to help to ensure the development of standardized good practices relating to the production, the handling, the long-term conservation and the reuse of 3D objects.</p><p>Therefore, even if the focus is put on technical questions (formats, processing, and annotation), the White Paper also identifies the need to clarify the legal status of 3D objects, in order to facilitate their reuse(s) in non-research contexts, in particular in Museums.</p><p>service could be demanded of external institutions, either commercial <ref type="bibr">[1]</ref> or public <ref type="bibr" target="#b26">[13]</ref>, and the related service can be provided by a tier under specific conditions of use, or also under specific costs. The conditions of use may not guarantee the protection of data in terms of property and copy, and this may have a strong impact on the publication of data from the Digital Humanities community. Another constraint are the intrinsic browser limitations: the viewer will be memory and file access limited, making the implementation of processing filters and complex annotation quite difficult. Obviously, the 3D model must be downloaded to be available in the viewer, so the bandwidth availability of the server and of the client may strongly impact on the performances of the available systems (but efficient data management based on compression, streaming and multiresolution encoding do exist to mitigate this issue). Finally, several viewers are optimized for specific types of data (i.e. manually modelled meshes, point clouds, models with animations), so the best solution can vary when different types of models are available.</p><p>Hence, the choice of the 3D viewer has to be guided by the typology of data that have to be published. If the data are in some way "sensitive", a service that allows you to host them in your own web server is preferable. Additionally, if the 3D model is a high resolution one, a viewer able to provide multi-resolution visualization is crucial.  • 3D digitization for the humanities: an overview, Gabriele Guidi, Politecnico Milano, Italy.</p><p>• A short review on issues and trends in the field of photogrammetric acquisition and processing, Anthony Pamart, MAP, France.</p><p>• Digital Pompei: Where computer vision meets archaeology, Jean Ponce, INRIA, France. Subtheme 2: Annotation over 3D models: is it a major missing feature?</p><p>• Aioli: reality-based 3D annotation cloud service, Adeline Manuel, MAP, Marseille, France.</p><p>• Subtheme 3: Checking consistency of 3D file formats from syntaxic toward semantic check?</p><p>• The french scientific national project ReSeed : Semantic reverse-engineering of digital heritage objects, Florent Laroche, Ecole Centrale de Nantes, France.</p><p>• Data Provenance in Photogrammetry Through Documentation Protocols, Nicola Carboni, MAP, Marseille, France.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>14:00 -16:30 2nd Session: Visualization and Analysis Issues</head><p>Moderator: Roberto Scopigno, CNR, Italy.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Subtheme 1:Use and reuse of 3D objects in restoration, conservation and exhibition : museology as a part of 3D objects life cycle?</head><p>• Conservation of art works with 3D technologies, Clotilde Boust, C2RMF, France.</p><p>• Toward virtual life of museological artefact: the use of 3D and heritage knowledge, Florent Laroche, Ecole Centrale, Nantes, France. The audience will first split in 4 groups, ach one resuming and advancing the work done in previous days on each major topic; and a final common session where the preliminary results will be presented.</p><p>General wrap up for the definition of the topics which will be included in a white paper in order to formalise the conclusions and recommendations of each workshop session. We will finalize an agreement on the structure of this white paper and will subdivide the work among the ones willing to contribute.</p><p>One guideline could be the way for researchers and engineers to share 3D models in an interoperable way at European level.</p><p>From this white paper, different kind of output can be considered: a standard publication, recommendations for WP4 on 3D standards and for WP6 on tools around 3D objects.</p><p>12:00 -12:15 Closing words Stéphane Pouyllau, TGIR Huma-Num (Technical deputy-director)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Biography of participants</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pierre ALLIEZ</head><p>Senior Researcher at Inria (Sophia-Antipolis, France), Team leader, TITANE; ERC grantee. Computer scientist, International expert on geometry processing (geometry compression, surface approximation, mesh parameterization, surface remeshing, mesh generation and surface reconstruction) and 3D digitization. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Laurent BERGEROT</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mehdi CHAYANI</head><p>Chayani Mehdi is an engineer in the lab Archeovision (UMS3657, CNRS/Université Bordeaux/Université Bordeaux-Montaigne). He is responsible for coordinating the work of the 3D consortium labeled by Huma-Num (TGIR), which gathers ten French labs that already have a practical production of 3D models in the scientific context of social and human science and with the aim to create deliverables for the SHS community. He has also several experiments in 3D data acquisition (photogrammetry) and object reconstruction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bruno DUTAILLY</head><p>Bruno Dutailly is a Computer Science Engineer in software development, specialized in 3D and Imagery. He works in two labs: PACEA (UMR5199, CNRS/Université Bordeaux/Ministère de la Culture) especially in CT (computed tomography) imagery and mesh extraction, and in Archeovision (UMS3657, CNRS/Université Bordeaux/Université Bordeaux-Montaigne) in point cloud and meshes tools, and stereovision. He is the author of TIVMI®, a software designed for precise measurements on CT scans and meshes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Matteo DELLEPIANE</head><p>CNR-ISTI, Pisa, Italy. Engineer, PhD, researcher at CNR-ISTI. He has a vast experience with digitization technologies, interactive visualization, web-based tools and application to CH. Participated to more than 10 EC projects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Nicolo DELL'UNTO</head><p>Univ. Lund, Sweden. An archaeologist, with a very solid experience with ICT technologies, GIS and 3D digitization. Participated to several scanning campaigns, including extensive work at Pompei as part of the Swedish Pompei Project.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Gabriele GUIDI</head><p>Politecnico Milano, Italy Engineer, PhD, expert in 3D digitization technologies, partner of EC "3D-ICONS" project and of the Indiana University digitization project in the Uffizi Museum, Florence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Anaïs GUILLEM</head><p>Both architect and archaeologist, Anaïs Guillem was previously involved in ITN-DCH project as Marie-Curie fellow. Her research work focuses on the digital documentation and modeling to document Built Cultural Heritage: from the different techniques and tools for surveying, to the processing, the modeling, and the analysing that lead to the interpretation the data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Florent LAROCHE</head><p>Florent Laroche is a "doctor-engineer" working as an assistant professor at Ecole Centrale de Nantes (France) and as a researcher in the laboratory IRCCyN (Research Institute for Communication and Cybernetics of Nantes, France, UMR CNRS 6597). He works on the translation of knowledge of the past in contemporary knowledge, readable and understandable in the present socio-technical system. His research topics are KM, PLM, information system modeling, interoperability, enterprise modeling, virtual engineering, reverse engineering. He is expert for Museums and ICOMOS. For more information:  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Review of 20 years of range sensor development</title>
		<author>
			<persName><forename type="first">F</forename><surname>Blais</surname></persName>
		</author>
		<idno type="DOI">10.1117/1.1631921</idno>
	</analytic>
	<monogr>
		<title level="j">J. Electron. Imaging</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">231</biblScope>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The 3D Model Acquisition Pipeline</title>
		<author>
			<persName><forename type="first">F</forename><surname>Bernardini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Rushmeier</surname></persName>
		</author>
		<idno type="DOI">10.1111/1467-8659.00574</idno>
	</analytic>
	<monogr>
		<title level="j">Comput. Graph. Forum</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="149" to="172" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Pulli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Curless</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rusinkiewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ginzton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ginsberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fulk</surname></persName>
		</author>
		<idno type="DOI">10.1145/344779.344849</idno>
		<title level="m">Proceedings of the 27th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH &apos;00</title>
		<meeting>the 27th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH &apos;00<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press/Addison-Wesley Publishing Co</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="131" to="144" />
		</imprint>
	</monogr>
	<note>The Digital Michelangelo Project: 3D Scanning of Large Statues</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Distinctive Image Features from Scale-Invariant Keypoints</title>
		<author>
			<persName><forename type="first">S</forename><surname>Keypoints</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
		<idno type="DOI">10.1023/B:VISI.0000029664.99615.94</idno>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Toth</surname></persName>
		</author>
		<title level="m">Topographic Laser Ranging and Scanning: Principles and Processing</title>
		<imprint>
			<publisher>CRC Press</publisher>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><surname>Guidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Remondino</surname></persName>
		</author>
		<title level="m">D Modelling from Real Data, in: Modeling and Simulation in Engineering</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="69" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">MeshLab as a complete tool for the integration of photos and color with high resolution 3D geometry data</title>
		<author>
			<persName><forename type="first">G</forename><surname>Ranzuglia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Callieri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dellepiane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cignoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Scopigno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CAA 2012 Conference Proceedings</title>
		<imprint>
			<publisher>Pallas Publications -Amsterdam University Press</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="406" to="416" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Best Practices and Metrological Issues in Massive 3D Digitization of Sculptures</title>
		<author>
			<persName><forename type="first">G</forename><surname>Guidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">S</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CAA</title>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
			<pubPlace>Atlanta (GA), USA. References</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Hunter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yu</surname></persName>
		</author>
		<title level="m">Assessing the Value of Semantic Annotation Services for 3D Museum Artefacts</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Attene</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Robbiano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Spagnuolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Falcidieno</surname></persName>
		</author>
		<title level="m">Part-based Annotation of Virtual 3D Shapes</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Havemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Settgast</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Berndt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Eide</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Fellner</surname></persName>
		</author>
		<title level="m">The Arrigo Showcase Reloaded -Towards a sustainable link between 3D and semantics</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">DHOP: 3D Heritage Online Presenter</title>
		<author>
			<persName><forename type="first">M</forename><surname>Potenziani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Callieri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dellepiane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Corsini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ponchio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Scopigno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer &amp; Graphics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="129" to="141" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A complete 3D information system for cultural heritage documentation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Soler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Melero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">V</forename><surname>Luzón</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Cultural Heritage</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="49" to="57" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Developing a toolkit for mapping and display stone alteration on a web-based documentation platform</title>
		<author>
			<persName><forename type="first">C</forename><surname>Stefani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Brunetaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Janvier-Badosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>De Luca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Al-Mukhtar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Cult. Heritage</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Multiresolution and fast decompression for optimal web-based rendering</title>
		<author>
			<persName><forename type="first">F</forename><surname>Ponchio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dellepiane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Graphical Models</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">A 3D-centered Information System for the documentation of a complex restoration intervention</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">I</forename><surname>Apollonio</surname></persName>
		</author>
		<ptr target="http://vcg.isti.cnr.it/activities/nettuno/" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>Submitted paper</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">Weiqi</forename><surname>Shi</surname></persName>
		</author>
		<title level="m">CHER-Ob: A Tool for Shared Analysis in Cultural Heritage, proceedings of EUROGRAPHICS Workshop on Graphics and Cultural Heritage</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A semantic-based platform for the digital analysis of architectural heritage</title>
		<author>
			<persName><forename type="first">L</forename><surname>De Luca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Busayarat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Stefani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Véron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Florenzano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Graphics</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="227" to="241" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Manuel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Véron</surname></persName>
		</author>
		<title level="m">De Luca L., 2D/3D Semantic Annotation of Spatialized Images for the Documentation and Analysis of Cultural Heritage, proceedings of EUROGRAPHICS Workshop on Graphics and Cultural Heritage</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>References</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<ptr target="https://sketchfab.com/" />
		<title level="m">Sketchfab</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title/>
		<ptr target="https://a360.autodesk.com/viewer/" />
	</analytic>
	<monogr>
		<title level="j">Autodesk A</title>
		<imprint>
			<biblScope unit="volume">360</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<ptr target="http://www.viewstl.com/" />
		<title level="m">STL Viewer</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<ptr target="https://grabcad.com/" />
		<title level="m">GrabCAD</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">DHOP: 3D Heritage Online Presenter</title>
		<author>
			<persName><forename type="first">M</forename><surname>Potenziani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Callieri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dellepiane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Corsini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ponchio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Scopigno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer &amp; Graphics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="129" to="141" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title/>
		<ptr target="https://3d.si.edu/" />
	</analytic>
	<monogr>
		<title level="j">Smithsonian X</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">webVis/instant3DHub: visual computing as a service infrastructure to deliver adaptive, secure and scalable user centric data visualisation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Behr</surname></persName>
		</author>
		<ptr target="https://www.x3dom.org" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th International Conference on 3D Web Technology</title>
		<meeting>the 20th International Conference on 3D Web Technology<address><addrLine>X3DOM</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="39" to="47" />
		</imprint>
	</monogr>
	<note>Web3D &apos;15</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<ptr target="http://visual.ariadne-infrastructure.eu/References" />
		<title level="m">ARIADNE&apos;s Visual Media Service</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<ptr target="https://www.cines.fr/archivage/un-concept-des-problematiques/le-concept-darchivage-numerique-perenne/" />
		<title level="m">Le concept d&apos;archivage numérique pérenne</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>CINES 2014a. last update 22/04/2014</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A New Introduction to the London Charter</title>
		<author>
			<persName><forename type="first">Hugh</forename><surname>Denard</surname></persName>
		</author>
		<ptr target="http://www.londoncharter.org/" />
	</analytic>
	<monogr>
		<title level="m">Paradata and Transparency in Virtual Heritage Digital Research in the Arts and Humanities Series</title>
		<editor>
			<persName><forename type="first">Ina</forename><surname>Bentkowska-Kafel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Baker</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Denard</surname></persName>
		</editor>
		<imprint>
			<publisher>Ashgate</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="57" to="71" />
		</imprint>
	</monogr>
	<note>site accessed on 07/04/2017</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Fernie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gavrilis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Angelis</surname></persName>
		</author>
		<title level="m">The CARARE metadata schema</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">3D-centered media linking and semantic enrichment through integrated searching, browsing, viewing and annotating</title>
		<author>
			<persName><forename type="first">Peña</forename><surname>Serna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Scopigno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Doerr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Theodoridou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Georgis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ch</forename><surname>Ponchio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Stork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of VAST11: The 12th International Symposium on Virtual Reality, Archaeology and Intelligent Cultural Heritage</title>
		<meeting>VAST11: The 12th International Symposium on Virtual Reality, Archaeology and Intelligent Cultural Heritage<address><addrLine>Prato, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-10-18">2011. October 18-21, 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Digitisation to presentation: Building virtual museum exhibitions</title>
		<author>
			<persName><forename type="first">P</forename><surname>Ronzino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hermon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Niccolucci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Walczak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sayd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Vision, Video and Graphics</title>
		<editor>
			<persName><forename type="first">V</forename><surname>Capellini</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2003">2012. 2003</date>
		</imprint>
	</monogr>
	<note>A metadata schema for cultural heritage documentation</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Framework for historical knowledge management in museology</title>
		<author>
			<persName><forename type="first">B</forename><surname>Hervy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Laroche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bernard</surname></persName>
		</author>
		<idno type="DOI">10.1504/IJPLM.2017.083001</idno>
		<ptr target="http://dx.doi.org/10.1504/IJPLM.2017.083001" />
	</analytic>
	<monogr>
		<title level="j">Int. J. Product Lifecycle Management</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="44" to="68" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>Inderscience</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Museum augmented interface for historical scale models: towards a new way for cultural heritage promotion</title>
		<author>
			<persName><forename type="first">B</forename><surname>Hervy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Laroche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-L</forename><surname>Kerouanton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bernard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Courtin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>D'haene</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Guillet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Waels</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Virtual Reality</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1081" to="1451" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Guillet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Courtin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Laroche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-L</forename><surname>Kerouanton</surname></persName>
		</author>
		<title level="m">Nantes 1900 -la maquette du port, ouvrage collectif, Musée d&apos;histoire de Nantes</title>
		<meeting><address><addrLine>France</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page" from="88" to="978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Virtual conservation and interaction with our cultural heritage: Framework for multi-dimension model based interface</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Laroche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hervy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-L</forename><surname>Kerouanton</surname></persName>
		</author>
		<idno type="DOI">10.1109/DigitalHeritage.2013.6743756</idno>
		<imprint>
			<publisher>Digital Heritage International Congress</publisher>
			<biblScope unit="page" from="323" to="330" />
			<pubPlace>Marseille</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Renault-Billancourt</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kilouchi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1922">1922</date>
		</imprint>
	</monogr>
	<note>C5 Workshop in the Digital Age: a New Story of the</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Assembly</forename><surname>Line</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Actes du Symposium, L&apos;histoire contemporaine à l&apos;ère numérique</title>
		<imprint>
			<biblScope unit="page" from="207" to="221" />
			<date type="published" when="2013">2013</date>
			<pubPlace>Bruxelles, PIE-Peter Lang</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">I-SEARCH -a multimodal search engine based on rich unified content description (RUCoD)</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lorenzo</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sabine</forename><surname>Spiller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marinella</forename><surname>Lazzaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Nucci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW 2012 Companion -21st international conference companion on World Wide Web</title>
		<meeting><address><addrLine>Lyon, France</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012-04">Apr 2012. 2012</date>
			<biblScope unit="page" from="291" to="294" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">3D-centered Media Linking and Semantic Enrichment through Integrated Searching, Browsing, Viewing and Annotating</title>
		<author>
			<persName><forename type="first">Pena</forename><surname>Serna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Scopigno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roberto</forename><surname>Doerr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Theodoridou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><surname>Georgis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christos</forename><surname>Ponchio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Federico</forename><surname>Stork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andre</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VAST: International Symposium on Virtual Reality, Archaeology and Intelligent Cultural Heritage</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<author>
			<persName><forename type="first">Pedro</forename><surname>Pascoal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alfredo</forename><surname>Ferreira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jorge</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Joaquim</forename></persName>
		</author>
		<title level="m">Towards an Immersive Interface for 3D Object Retrieval. Eurographics Workshop on 3D Object Retrieval. The Eurographics Association</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Sketch-based pipeline for mass customization</title>
		<author>
			<persName><forename type="first">Kristian</forename><surname>Hildebrand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Alexa</surname></persName>
		</author>
		<idno type="DOI">10.1145/2504459.2504506</idno>
		<ptr target="DOI=http://dx.doi.org/10.1145/2504459.2504506" />
	</analytic>
	<monogr>
		<title level="m">ACM SIGGRAPH 2013 Talks (SIGGRAPH &apos;13)</title>
		<meeting><address><addrLine>New York, NY, USA, , Article</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">37</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Subject matter categorization of tags applied to digital images from art museums</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Klavans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Laplante</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Golbeck</surname></persName>
		</author>
		<idno type="DOI">10.1002/asi.22950</idno>
	</analytic>
	<monogr>
		<title level="j">J Assn Inf Sci Tec</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="3" to="12" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A Survey of 2D and 3D Shape Descriptors</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">K</forename><surname>Kazmi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1109/CGIV.2013.11</idno>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics, Imaging and Visualization (CGIV), 2013 10th International Conference</title>
		<meeting><address><addrLine>Macau</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A Survey on Partial Retrieval of 3D Shapes</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11390-013-1382-9</idno>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Sci. Technol</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page">836</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">What Do Thirty-One Columns Say about a &quot;Theoretical&quot; Thirty-Second?</title>
		<author>
			<persName><forename type="first">David</forename><surname>Lo Buglio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vanessa</forename><surname>Lardinois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Livio</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luca</forename></persName>
		</author>
		<idno type="DOI">10.1145/2700425</idno>
		<ptr target="DOI=http://dx.doi.org/10.1145/2700425" />
	</analytic>
	<monogr>
		<title level="j">J. Comput. Cult. Herit</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2015-02">2015. February 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Analyzing the Decorative Style of 3D Heritage Collections Based on Shape Saliency</title>
		<author>
			<persName><forename type="first">Karina</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Echavarria</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Ran</forename><surname>Song</surname></persName>
		</author>
		<idno type="DOI">10.1145/2943778</idno>
		<ptr target="https://doi.org/10.1145/2943778" />
	</analytic>
	<monogr>
		<title level="j">J. Comput. Cult. Herit</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">17</biblScope>
			<date type="published" when="2016-12">2016. December 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Laurent ROMARY Senior Research at Inria, France and director general of DARIAH. He carries out research on the modeling of semi-structured documents, with a specific emphasis on texts and linguistic resources. He has also been active in standardization activities within the TEI consortium and ISO and is now chairing ISO committee TC 37 on terminology and language resources. He is also contributing to the definition of the scientific information policy of Inria. Roberto SCOPIGNO Roberto Scopigno is Research Director at CNR-ISTI with 30 years of experience on 3D graphics (3D digitization, visualization, geometry processing) and its application to the Cultural Heritage domain. He is author of more than 200 international papers, with Google Scholar h-index 45 and more than 9500 citations. He participated with several EU and national research projects concerned with ICT and Cultural Heritage</title>
		<author>
			<persName><forename type="first">K</forename><surname>Sfikas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Pratikakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Koutsoudis</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11042-014-2069-0</idno>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum and ACM Journal of Computing and Cultural Heritage)</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="page">3693</biblScope>
			<date type="published" when="2016">2016</date>
			<publisher>Multimed Tools Appl</publisher>
		</imprint>
	</monogr>
	<note>Journal in Computing and Cultural Heritage. and was the organizer of several international events (Eurographics&apos;99, Eurographics2008, Digital Heritage2015, CAA2015</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Archeovision UMS3657, CNRS. Formerly specialized in databases administration and migration for private telecom firms</title>
		<author>
			<persName><forename type="first">Tournon-Valiente Software</forename><surname>Sarah</surname></persName>
		</author>
		<author>
			<persName><surname>Engineer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Now acting in research databases, specialized in database management, software development and interoperability</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
