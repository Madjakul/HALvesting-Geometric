<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="fr">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">HTR-United : Mutualisons la vérité de terrain !</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>ALMAnaCH, Inria</roleName><forename type="first">Alix</forename><surname>Chagué</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Thibault Clérice</orgName>
								<orgName type="institution" key="instit2">Centre Jean Mabillon</orgName>
								<address>
									<settlement>École nationale des chartes</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>ALMAnaCH, Inria</roleName><forename type="first">Laurent</forename><surname>Romary</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Thibault Clérice</orgName>
								<orgName type="institution" key="instit2">Centre Jean Mabillon</orgName>
								<address>
									<settlement>École nationale des chartes</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">HTR-United : Mutualisons la vérité de terrain !</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">41627F3BAF52C1DC7DEB5268CE01B20C</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-08-24T14:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="fr">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Depuis quelques années, les projets en humanités numériques intègrent des tâches de transcription automatique d'écritures manuscrites pour l'acquisition des corpus, confirmant le transfert de cette technologie du domaine expérimental de la vision par ordinateur vers le grand public. En témoigne le développement de logiciels conviviaux, libres ou propriétaires, proposant des solutions quasi clefs-en-main, tels que Transkribus <ref type="bibr" target="#b15">[Kahle et al., 2017]</ref>, eScriptorium <ref type="bibr">[Stökl Ben Ezra, 2021]</ref> ou encore Arkindex <ref type="bibr" target="#b28">[Teklia, 2021]</ref>. Parmi les projets ayant eu recours à ces logiciels, on peut citer HIMANIS <ref type="bibr" target="#b27">[Stutzmann et al., 2017]</ref>, Ffl <ref type="bibr" target="#b18">[Massot et al., 2019]</ref>, HORAE <ref type="bibr" target="#b2">[Boillet et al., 2019]</ref>, TIME US <ref type="bibr" target="#b4">[Chagué et al., 2019]</ref>, MaRITEM <ref type="bibr" target="#b17">[Mariotti, 2020]</ref>, LECTAUREP <ref type="bibr">[Chagué et al., 2020]</ref>. On pourrait en déduire que n'importe qui peut désormais se lancer dans un projet de reconnaissance automatique d'écritures manuscrites, mais il reste en réalité de nombreux points de blocage. Ainsi, quoique disponibles, les plateformes techniques implémentant des solutions de transcription automatique nécessitent encore de grandes quantités de données. Produire ces données a un coût que la mutualisation des efforts peut atténuer. Nous présentons dans ce papier une solution nommée HTR-United facilitant la mise en commun de la vérité de terrain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Principes de la transcription automatique</head><p>La reconnaissance des écritures manuscrites (REM), que l'on appelle aussi HTR (Handwritten Text Recognition), est un procédé informatique qui vise à obtenir un équivalent de texte numérique à partir de l'image d'un document physique comportant du texte manuscrit. Ce traitement est décomposé en trois tâches (Figure <ref type="figure">1</ref>) dont deux (1, 3) sont indispensables :</p><p>1. localiser l'emplacement du texte sur l'image de manière à produire en ensemble de coordonnées (segmentation) ; 2. déterminer l'organisation logique de chaque segment par rapport aux autres et par rapport à la page (analyse de la mise en page) ; 3. à partir des coordonnées de chaque segment, reconnaître les lettres et les mots tracés dans la portion de l'image (transcription).</p><p>Ces tâches relèvent du domaine de l'apprentissage profond, il est donc nécessaire d'entraîner, pour chacune d'entre elles, des modèles à partir de données d'exemple. Ce sont ces exemples que l'on appelle la vérité de terrain : des ensembles de données annotées et corrigées de manière à fournir au modèle des paires composées d'une part d'une image ou d'une portion d'image (entrée) et d'autre part de l'annotation attendue (sortie), qui peut être des coordonnées dans le cas de la segmentation ou un ensemble de caractères pour la transcription. Les performances des modèles dépendent certes de l'architecture neuronale mise en place, mais aussi de la qualité et de la quantité de vérité de terrain fournies lors de l'apprentissage.</p><p>Figure <ref type="figure">1</ref> : Schématisation des étapes de traitement impliquées dans la REM, image produite par les auteur⋅rices.</p><p>De nombreux facteurs font que la tâche de transcription constitue encore un défi dans le domaine <ref type="bibr" target="#b24">[Stokes et al., 2021]</ref>. On peut citer par exemple : la très grande variation dans la formation des lettres ; la forte présence de bruit et d'accidents sur les pages manuscrites ; l'impossibilité de s'appuyer sur une segmentation à l'échelle des caractères ; ou encore la présence de graphèmes et de systèmes d'abréviations propres à chaque personne (Figure <ref type="figure">2</ref>). A cela s'ajoute la difficulté pour les annotateurs et annotatrices de se mettre d'accord sur les pratiques de transcription, notamment la manière de traiter les variations graphétiques <ref type="bibr" target="#b26">[Stutzmann, 2011]</ref> ou les abréviations. En dépit de cela, il est possible à l'heure actuelle d'obtenir des modèles produisant des transcriptions réussites à 95% <ref type="bibr" target="#b19">[Pinche 2021</ref>].</p><p>Figure <ref type="figure">2</ref> : Exemples illustrant les principales difficultés rencontrées pour le traitement de textes manuscrits, image produite par les auteur⋅rices.</p><p>Pour produire de tels modèles, on peut considérer qu'il existe deux approches (Figure <ref type="figure">3</ref>) :</p><p>-une configuration qui s'apparente à un démarrage à froid : on part de zéro en générant un modèle à partir d'un jeu de vérité de terrain et d'une architecture neuronale ; -ou au contraire, une configuration qui s'appuie sur l'affinage d'un modèle pré-entraîné : on ré-entraîne un modèle sur une architecture neuronale identique en ajoutant des données qui sont plus ou moins similaires à celles qui ont permis d'entraîner le modèle de départ. La deuxième approche présente de nombreux avantages, parmi lesquels un important gain d'efficacité : en s'appuyant sur les acquis préalables d'un modèle, on a besoin d'une moindre quantité de vérité de terrain pour obtenir de bonnes, voire de meilleures performances. Au lieu de devoir transcrire une centaine de pages d'un corpus nouveau, on peut ainsi obtenir la même performance avec seulement 30 pages, si on affine un modèle <ref type="bibr" target="#b22">[Reul et al., 2021]</ref>.</p><p>Dans les deux cas toutefois, en matière de transcription automatique pour les écritures manuscrites, l'état de l'art est tel qu'on échappe rarement à la nécessité de produire sa propre vérité de terrain, à l'inverse de la transcription automatique de l'imprimé ou bien de la segmentation, où les modèles disponibles sont déjà suffisamment performants.</p><p>Figure <ref type="figure">3</ref> : Les deux configurations principales pour l'entraînement de modèles de REM ne demandent pas la même quantité de données, image produite par les auteur⋅rices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Décloisonner les ressources, partager les données</head><p>Produire de la vérité de terrain de qualité suppose de posséder une connaissance minimale des environnements de transcription automatique, de mettre à plat l'ensemble des règles de transcription permettant d'obtenir une sortie de texte correspondant aux attentes, et surtout de posséder les moyens en temps et financiers de produire cette vérité de terrain. Il faut alors s'assurer de la disponibilité de personnes capables de lire les écrits du corpus, qu'elles disposent d'une compréhension suffisante des documents et des enjeux du projet, et qu'elles soient capables de contrôler la qualité de la transcription par rapport aux règles fixées en amont. Il est rare qu'un projet en humanités numériques souhaitant recourir à la REM possède toutes ces ressources.</p><p>Un écueil guette ces projets, celui d'échouer à obtenir un modèle de transcription efficace et d'abandonner l'ambition initiale d'automatiser cette tâche. On risque de dédier un temps considérable à produire une transcription qui, d'échantillon de vérité de terrain, finit par devenir le corpus final. Si on prend un peu de hauteur, c'est aussi une perte de ressources pour la communauté des sciences humaines car la vérité de terrain n'est souvent produite que pour servir les finalités d'un projet précis. S'opère en effet un cloisonnement des ressources où chaque projet part de zéro et doit produire, ou tenter de produire, sa propre vérité de terrain comme si rien n'avait été transcrit avant.</p><p>Plusieurs facteurs expliquent le cloisonnement de ces données. En tout premier lieu le manque d'attention portée à la vérité de terrain elle-même par rapport à celle portée aux modèles. Les logiciels permettent aux utilisateurs et utilisatrices de partager des modèles, qui ont l'avantage d'être immédiatement capables de produire une transcription en plus de fournir des informations sur leurs performances théoriques. A l'inverse, il est plus difficile de partager la vérité de terrain : outre parfois l'absence de fonctionnalités adéquates dans les logiciels, se posent des problèmes de droits sur les images, d'embargo sur les transcriptions, et de compétences et capacités de calcul pour entraîner de nouveaux modèles sur ces données.</p><p>Autre difficulté découlant de la première : trouver, en ligne, des jeux de vérité de terrain déjà constitués. En passant par des moteurs de recherche ou des plateformes de dépôt comme Zenodo, on peut trouver ce type de données, mais on n'a jamais la certitude que le jeu est complet, à jour, dans un format standard, ou compatible avec notre projet. Par exemple, même un corpus, pour l'imprimé, aussi récent et bien documenté que OCR17 <ref type="bibr" target="#b12">[Gabay et al., 2020]</ref>, recense des données dans un format appauvri incompatible avec la version actuelle de Kraken (3.0.5) <ref type="bibr" target="#b16">[Kiessling, 2015</ref><ref type="bibr" target="#b16">[Kiessling, /2021] ]</ref> </p><formula xml:id="formula_0">1 .</formula><p>Pourtant s'appuyer sur la vérité de terrain plutôt que sur un modèle a du sens. Alors qu'il est impossible de transposer un modèle d'un moteur de transcription à un autre, les données s'avèrent plus souples. La raison en est simple : il n'y pas de pratique standardisée pour l'enregistrement des modèles de transcription puisque les architectures neuronales varient d'un système à l'autre et certains logiciels ne permettent tout simplement pas de télécharger les modèles. En revanche, il existe des standards pour la représentation des données et la plupart des logiciels de transcription les intègrent : XML ALTO [ALTO 4.2, 2020] et XML PAGE <ref type="bibr" target="#b21">[Pletschacher &amp; Antonacopoulos, 2010]</ref>.</p><p>Dans le cadre de la Science Ouverte, l'enjeu de la publication des transcriptions finales est certes compris, de même que celui de publier les modèles lorsque cela est possible, mais il manque un réflexe de publier la vérité de terrain en tant que vérité de terrain et non pas en tant que transcription. En fait, c'est d'autant plus dommageable que le fait de pouvoir accéder à la vérité de terrain permet de comprendre quelles ont été les pratiques de transcription conduisant à un modèle, d'en comprendre les résultats et même de reproduire l'entraînement du modèle 2 .</p><p>En premier lieu, le signalement, la documentation et les métadonnées. Parmi les métadonnées qui nous semblent devoir accompagner un dépôt de vérité de terrain, outre celles qui permettent de l'identifier et de le citer 3 , nous avons recensé les suivantes : la licence ; la langue ; le système d'écriture (ou alphabet) ; le nombre de mains ou de polices et leur proportion 4 ; la période couverte ; ou encore, l'importance matérielle (le volume). Ces éléments de description sont cruciaux pour faciliter le filtrage, par une personne porteuse d'un projet, entre plusieurs jeux de données. Ce filtrage se fait alors en fonction de critères permettant de composer une vérité de terrain nouvelle, susceptible de compléter les données que le projet possède déjà ou d'aboutir à un modèle idoine.</p><p>Outre la question de savoir quelles informations doivent être fournies, se pose également celle de savoir comment les renseigner. Si certains champs posent peu de problèmes, d'autres qui semblent au premier abord aller de soi s'avèrent difficiles à évaluer. Par exemple : le nombre de mains. Lorsque quantifier le nombre de mains représentées dans un corpus disparate s'avère impossible, on doit se contenter d'en donner au mieux une estimation. Il est en fait préférable d'exprimer cette information en suivant deux modalités : soit une quantification précise lorsque l'on connaît l'identité des scripteurs, soit des mot-clefs comme "few" ou "many" pour exprimer un ordre de grandeur pertinent<ref type="foot" target="#foot_1">5</ref> . En effet, ce qui importe vraiment ce n'est pas le nombre exact, mais de savoir si un jeu de vérité de terrain ne contient qu'une seule main, s'il existe un peu de variation dans ce lot ou bien si au contraire les écritures y sont très disparates, en grand nombre et parfois difficiles à distinguer.</p><p>Parmi les autres aspects méthodologiques à considérer : les standards. On a mentionné PAGE et ALTO. Il en existe donc au moins deux, mais qui se déclinent chacun en plusieurs versions. Faut-il s'en tenir à un standard et une version uniques, et si oui lesquels ? Est-il seulement possible de répondre à cette question alors que les logiciels continuent d'évoluer ? Par exemple, jusqu'à la publication de la version 1.5.0 de Transkribus en mars 2021, l'application desktop proposait d'exporter des données au format XML ALTO 2 et au format XML PAGE. Soudainement, le logiciel est passé à la version 4.2 d'ALTO, pour l'export puis pour l'import, sans rétrocompatibilité. Cela rend-il caduque les nombreux jeux de données déposés et publiés sur Zenodo avant mars 2021 ? On pourrait arguer que les modèles sont de ce point de vue plus robustes que les données mais il n'en est rien. En janvier 2020, lorsque Kraken est passé à sa version 3, permettant l'entraînement de modèles de segmentation, ce qui n'était pas possible avant, tous les modèles produits avec des versions antérieures du logiciel ont cessé d'être compatibles avec les versions ultérieures.</p><p>Enfin, troisième aspect méthodologique important : le contrôle de la qualité d'un jeu de données. Ce qui définit la qualité d'une vérité de terrain dépend des objectifs de la personne par rapport au modèle qu'elle en tire. On peut toutefois s'accorder à prendre en compte plusieurs critères :</p><p>-l'homogénéité des règles de transcription suivies pour produire ces données, -la fidélité de la transcription par rapport à l'image -et sa capacité à s'adapter aux objectifs d'un autre projet.</p><p>Dans un corpus de transcription comme celui créé à l'occasion de l'édition des journaux d'Eugène Wilhelm <ref type="bibr" target="#b23">[Schlagdenhauffen, 2020]</ref> des passages rédigés en alphabet grec ont été transcrits en alphabet latin. Cela est justifié par l'auteur de l'article qui rend compte de ce travail, mais constitue de fait une transcription qui diffère de ce que l'image originale contient et peut ne pas être adaptée à d'autres projets où le modèle doit distinguer alphabet grec et alphabet latin. Pour autant, cette vérité de terrain potentielle est-elle de mauvaise qualité ? Ce qui importe en fait, c'est qu'a minima l'information concernant la pratique suivie soit documentée afin qu'elle puisse être prise en compte par une personne ré-utilisant de telles données. Idéalement, ce genre de problématique est pris en charge dans le cadre d'un Plan de Gestion des Données (PGD).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Un projet adossé à Github</head><p>Le projet HTR-United s'est mis en place sous la forme d'une organisation Github en octobre 2020. Il s'agit d'une entité propre à la plateforme permettant à plusieurs utilisateurs et utilisatrices de se rassembler autour d'un projet commun se déployant sur différents répertoires de travail. L'organisation Github HTR-United est donc composée de plusieurs répertoires (Figure <ref type="figure" target="#fig_0">4</ref>) dont les principaux sont :</p><p>-un répertoire central <ref type="bibr" target="#b3">[Chagué et al., 2021]</ref> contenant :</p><p>-un catalogue sous la forme d'un fichier YAML unique et généré automatiquement grâce au moissonnage des métadonnées fournies par chaque sous-projet ; -un sous-dossier de signalement nommé "catalog" rassemblant les métadonnées de projets hébergés en dehors de Github<ref type="foot" target="#foot_2">6</ref> , par exemple sur Zenodo, mais signalés dans HTR-United ; -une série de répertoires satellites permettant le dépôt des jeux de données directement sur Github s'ils n'ont pas été déposés ailleurs.</p><p>Pour être complet, un dépôt de données devrait comporter :</p><p>-des transcriptions alignées avec des images, dans un format standard comme XML PAGE ou XML ALTO ; -des images soit directement dans le dépôt, soit sous la forme de liens vers des ressources hébergées ailleurs, par exemple sur un serveur IIIF ; -un fichier de présentation du corpus et de son contexte de production sous la forme d'un fichier README, donnant autant d'informations que possible, y compris sur l'architecture du dossier de dépôt, à la manière d'un data paper ; -et enfin un fichier YAML de métadonnées correspondant aux champs identifiés plus haut et requis par HTR-United. Ce fichier se nomme "htr-united.yml" dans les dépôts réalisés directement sous l'organisation Github, ou bien porte le nom du corpus lorsqu'il se situe dans le sous-dossier "catalog". On peut ainsi automatiser le calcul des valeurs des champs liés à l'importance matérielle. C'est l'ambition de HTR-United Metadata Generator (HUM) <ref type="bibr">[Clérice &amp; Chagué, 2021]</ref>, un processus qui analyse les fichiers XML déposés afin de relever le nombre de pages, de lignes et de caractères constituant un lot de vérité de terrain. Ces métriques sont importantes car lorsqu'elles sont exprimées individuellement, elles ont peu de signification.</p><p>Pour renseigner sur la taille réelle d'un lot de vérité de terrain, il faut les croiser, le nombre de caractères dans une ligne et le nombre de lignes dans un page étant extrêmement variables en fonction des types de document.</p><p>Le fait de s'appuyer sur une plateforme comme Github présente plusieurs avantages, dont la facilité d'y mettre en place un travail collaboratif dépassant les limites d'un projet de recherche donné ; la gestion fine des versions ; et la possibilité d'en faire coexister plusieurs simultanément 8 .</p><p>Cela signifie que lorsqu'une personne publie sa vérité de terrain et la signale dans le catalogue HTR-United, sous réserve qu'elle soit libre de droit, une autre personne peut l'utiliser pour son projet, la mettre à jour ou la convertir pour la rendre compatible avec son logiciel et la re-publier comme un fork du jeu de données initial. A l'échelle d'un dépôt, cela veut aussi dire qu'une personne déposant un lot de vérités de terrain peut, plus tard, augmenter ce lot, mettre à jour la documentation et ainsi en publier une nouvelle version.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Un soutien au contrôle qualité</head><p>La production de vérité de terrain en HTR repose sur trois piliers : une production d'annotations -le texte, la segmentation-, sa formalisation -en XML, avec différents jeux de caractères-, et son intégration dans un réseau de production -à travers des ontologies de segmentation, des schémas et des choix d'encodage (cf. Figure <ref type="figure" target="#fig_1">5</ref>). Si la première section relève principalement de données à vérification qualitative, l'ensemble des autres informations correspond à des éléments dont la validation peut être prise en charge par la machine. Dans ce cadre, afin d'assurer à la fois la qualité des données et de réduire le temps passé à leur vérification formelle, HTR-United et le projet CREMMA travaillent à la mise à disposition de divers outils dits "d'intégration continue".</p><p>L'intégration continue consiste au lancement automatisé et externalisé 9 de tests voire de compilations 10 au moment de la synchronisation d'un dépôt tel que ceux de Github<ref type="foot" target="#foot_4">11</ref> : elle permet par son caractère décentralisé de produire une vérification publique de la qualité des données et du code à chaque modification. Cette pratique reste encore assez rare dans le domaine des données en humanités numériques, mais connaît une progression sur les dernières années <ref type="bibr" target="#b0">[Almas &amp; Clérice, 2017;</ref><ref type="bibr" target="#b10">Ferger &amp; Hedeland, 2020]</ref>.</p><p>HTR-United propose l'utilisation de trois outils ayant chacun des objectifs partagés :</p><p>-ChocoMufin <ref type="bibr" target="#b8">[Clérice &amp; Pinche, 2021b]</ref>,</p><p>-HTRVX <ref type="bibr" target="#b7">[Clérice &amp; Pinche, 2021a]</ref> -et HTR United Metadata Generator (HUM Generator) présenté plus haut (cf. Figure <ref type="figure" target="#fig_2">6</ref>).   Ainsi, les annotateur⋅rices et gestionnaires de corpus de vérité de terrain réduisent le temps de maintenance et de recherche d'erreurs, en ne se concentrant que sur les logiques globales du corpus (normes de transcriptions, transcriptions) et en s'appuyant sur ces outils. Par ailleurs, les détails statistiques fournis par HUM Generator permettent de suivre la progression de la production de contenus voire de fournir des badges publics informant les personnes découvrant les corpus de l'état de ceux-ci au moment de leur visite (cf. Figure <ref type="figure" target="#fig_3">7</ref>). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>Mettre en commun la vérité de terrain est crucial pour permettre à la recherche d'avancer vers une meilleure intégration de la reconnaissance des écritures manuscrites dans les projets en humanités numériques. Outre la disponibilité de données de qualité, correctement documentées et recensées, cette mutualisation des ressources peut pousser l'ensemble des utilisateur⋅rices à établir progressivement des pratiques homogènes. Cela concerne autant les règles de transcription que les métadonnées permettant ce partage. On peut noter des initiatives comme SegmOnto, dont l'objectif est de produire des modèles de segmentation et d'analyse de mise en page basés sur des données très diversifiées mais suivant les mêmes règles d'annotation sémantique. L'objectif d'un tel projet est double : produire des modèles prêts à l'emploi et adaptés aux documents patrimoniaux manuscrits et imprimés, et partager des données permettant d'aboutir à ces modèles.</p><p>Un pot commun s'appuyant sur une plateforme initialement orientée vers le versionnage telle que Github présente de nombreux avantages, mais l'on peut envisager que des institutions patrimoniales s'emparent progressivement de la tâche de recensement et de collecte de la vérité de terrain afin d'en pérenniser l'enregistrement.</p><p>Il est temps d'encourager la publication de ces données pour ce qu'elles sont. Cela peut passer par la mise en place de chartes incitant au dépôt de la vérité de terrain en contrepartie de l'utilisation de ressources librement mises à disposition, comme ce sera par exemple le cas du serveur CREMMA, financé par le DIM MAP <ref type="bibr">[DIM MAP, 2021]</ref>. En cherchant à garantir une simplicité d'utilisation, HTR-United peut également être intégré dans les cursus universitaires qui forment à la transcription ou aux outils de versionnage. En effet, en réalisant une simple tâche d'alignement entre transcription et image, ou en mettant à jour un corpus, n'importe qui peut contribuer à cette initiative.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4 : Schématisation des répertoires rassemblés dans l'organisation HTR-United, image produite par les auteur⋅rices.</figDesc><graphic coords="8,78.75,79.50,440.25,351.75" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5 : Typologie des informations et leurs relations dans le cadre de vérité de terrain, image produite par les auteur⋅rices.</figDesc><graphic coords="10,78.75,79.50,440.25,132.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6 : Informations, outils de contrôle et résultat de ces contrôles, image produite par les auteur⋅rices.</figDesc><graphic coords="11,78.75,79.50,440.25,159.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7 : Badges statistiques automatiquement mis à jour pour un corpus HTR United, image produite par les auteur⋅rices.</figDesc><graphic coords="11,78.75,421.79,440.25,129.75" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Le deuxième outil est un simple outil de vérification des schémas, au format XSD. HTRVX s'appuie sur un schéma -nous fournissons uniquement un schéma pour l'ontologie SegmOnto<ref type="bibr" target="#b11">[Gabay et al., 2021]</ref> et la spécification ALTO pour le moment -et permet alors la vérification de la validité du fichier en fonction des catégories de segmentation proposées par SegmOnto. Nos schémas incluent aussi une vérification d'absence de lignes vides, qui auraient pu échapper à l'oeil des annotateur⋅rices, soit parce que la ligne était difficile à percevoir et à l'origine d'une erreur de segmentation, soit parce qu'elle a tout simplement été oubliée. Chaque fichier fait alors l'objet d'un rapport individualisé avec un regroupement lisible de l'ensemble des erreurs rencontrées.</figDesc><table /><note><p>table de valeurs autorisées propre à chaque dépôt. Cette vérification s'accompagne d'une table des nouveaux caractères apparus, qui peuvent alors être inclus à la table des caractères validés ou au contraire corrigés. Par ailleurs, cette table des caractères contient aussi une valeur de remplacement, permettant aux utilisateur-rice-s de proposer des "simplifications" de leurs transcriptions, afin d'uniformiser les pratiques entre dépôts et projets.</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Outre ces aspects de portabilité des données, il nous faut mentionner la plasticité de la vérité de terrain : il est impossible de fusionner des modèles de transcription, alors qu'on peut assembler, diviser, croiser différents jeux de vérité de terrain pour en recomposer un nouveau. De même, on peut modifier les exemples de transcription qu'ils contiennent de manière à rendre des jeux compatibles entre eux, ou pour obtenir un modèle dont la sortie correspond à nos besoins.On comprend alors qu'accéder à la vérité de terrain d'autres projets présente de nombreux avantages et permet à coup sûr d'éviter un démarrage à froid : grâce à ces données, on peut créer son propre modèle pré-entraîné pour basculer dans un scénario d'affinage, ou bien augmenter rapidement l'importance matérielle de sa vérité de terrain de manière à réduire le temps passé à transcrire manuellement son corpus pour entraîner un premier modèle.HTR-United : questions méthodologiquesLe projet HTR-United est né de ce constat. Il faut mettre en commun la vérité de terrain pour permettre à chacun d'en bénéficier. Pourtant cela pose de nombreuses questions méthodologiques que nous pouvons rappeler.2 A condition que l'ensemble des paramètres de l'entraînement ait été documenté.1 Le dataset OCR17+[Jahan &amp; Gabay, 2021]  résout cela en proposant désormais des paires d'images et de fichiers XML ALTO.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_1"><p>HTR-United propose d'ajuster la quantification du nombre de mains à l'échelle des fichiers ou des dossiers avec des valeurs comme "one-per-file" (une main par fichier) ou "one-per-folder" (une main par dossier).4 HTR-United propose plusieurs valeurs telles que "only-manuscript", "only-typed", "mainly-manuscript", "mainly-typed" ou encore "evenly-mixed".3 Nous proposons pour cela de fournir les informations (nom, prénom, rôle) permettant de citer l'ensemble des personnes ayant contribué à la création d'un jeu de vérité de terrain, notamment à travers les rôles "transcriber", "aligner", "project-manager" et "support".</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_2"><p>Ainsi HTR-United n'impose pas qu'images et transcriptions soient déposées sur Github.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_3"><p>Le formulaire est accissible via l'URL suivante : https://htr-united.github.io/document-your-data.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_4"><p>Github propose son propre service d'Intégration Continue, Github Actions, mais d'autres existent : TravisCI, CircleCI, etc.10 Dans notre cas, la phase compilation peut prendre la forme d'une normalisation automatisée ou de versionnage automatique du corpus.9  Ces tests sont nécessairement lancés sur des machines vierges, permettant ainsi un test "objectif" des données : le même code est lancé indépendamment de toute particularité de paramétrage des ordinateurs de chacun-e des contributeurs-ices.8  Pour comprendre le fonctionnement des forks dans Github : https://docs.github.com/en/get-started/quickstart/fork-a-repo[Github Inc., 2021]   </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12" xml:id="foot_5"><p>Ce problème dépasse la période médiévale : d'une part, il est encore commun de trouver des abréviations à la période moderne dans les documents manuscrits, mais on trouve encore après cette période des variations graphiques tels S Long / S ou des ligatures (les éditions de la Pléïade présentent encore des st en ligature). Les abréviations type numéro, les guillemets, etc. peuvent aussi faire l'objet de variations d'un annotateur à une autre.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Continuous Integration and Unit Testing of Digital Editions</title>
		<author>
			<persName><forename type="first">B</forename><surname>Almas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Clérice</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Digital Humanities Quarterly</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<ptr target="https://www.loc.gov/standards/alto/news.html#4-2-released" />
		<title level="m">Analyzed Layout and Text Object (ALTO)</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>Computer software</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">HORAE : An annotated dataset of books of hours</title>
		<author>
			<persName><forename type="first">M</forename><surname>Boillet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-L</forename><surname>Bonhomme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Stutzmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kermorvant</surname></persName>
		</author>
		<idno type="DOI">10.1145/3352631.3352633</idno>
		<ptr target="https://doi.org/10.1145/3352631.3352633" />
	</analytic>
	<monogr>
		<title level="m">th International Workshop on Historical Document Imaging and Processing</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="7" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">HTR United, a centralization effort of HTR and OCR ground-truth repositories for French languages</title>
		<author>
			<persName><forename type="first">A</forename><surname>Chagué</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Clérice</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Chiffoleau</surname></persName>
		</author>
		<ptr target="https://github.com/HTR-United/htr-united" />
		<imprint>
			<date type="published" when="2020">2021. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Deux siècles de sources disparates sur l&apos;industrie textile en France : Comment automatiser les traitements d&apos;un corpus non-uniforme ? Colloque DHNord</title>
		<author>
			<persName><forename type="first">A</forename><surname>Chagué</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Le Fourner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Martini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">É</forename><surname>De La Clergerie</surname></persName>
		</author>
		<ptr target="https://hal.inria.fr/hal-02448921" />
	</analytic>
	<monogr>
		<title level="m">Corpus et archives numériques</title>
		<imprint>
			<date type="published" when="2019">2019, octobre 16. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Chagué</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Terriel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Romary</surname></persName>
		</author>
		<ptr target="https://hal.archives-ouvertes.fr/hal-03008579" />
		<title level="m">Des images au texte : LECTAUREP, un projet de reconnaissance automatique d&apos;écriture</title>
		<imprint>
			<date type="published" when="2020-11">2020, novembre</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">HUM Generator, the HTR United Metadata Generator</title>
		<author>
			<persName><forename type="first">T</forename><surname>Clérice</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chagué</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.5363307</idno>
		<ptr target="https://doi.org/10.5281/zenodo.5363307" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>v0.0.1) [Python</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">) [Computer software]</title>
		<author>
			<persName><forename type="first">T</forename><surname>Clérice</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pinche</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.5359963</idno>
		<idno>HTR-United/HTRVX : 0. (v0.0.1</idno>
		<ptr target="https://doi.org/10.5281/zenodo.5359963" />
	</analytic>
	<monogr>
		<title level="j">Zenodo</title>
		<imprint>
			<date type="published" when="2021">2021a</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">T</forename><surname>Clérice</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pinche</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.5356154</idno>
		<idno>PonteIneptique/choco-mufin : 0.0.4 (v0.0.4</idno>
		<ptr target="https://doi.org/10.5281/zenodo.5356154" />
		<imprint>
			<date type="published" when="2021">2021b</date>
		</imprint>
	</monogr>
	<note>Computer software</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">Patrimoniaux -Ppsm (</forename><surname>Dim Matériaux Anciens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ens</forename><surname>Cnrs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paris</forename><forename type="middle">-</forename><surname>Saclay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">)</forename></persName>
		</author>
		<ptr target="https://www.dim-map.fr/projets-soutenus/cremma/" />
		<title level="m">Projets soutenus/CREMMA. DIM MAP</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Towards Continuous Quality Control for Spoken Language Corpora</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ferger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hedeland</surname></persName>
		</author>
		<idno type="DOI">10.2218/ijdc.v15i1.601</idno>
		<ptr target="https://doi.org/10.2218/ijdc.v15i1.601" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Digital Curation</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">SegmOnto : Common vocabulary and practices for analysing the layout of manuscripts (and more)</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gabay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-B</forename><surname>Camps</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pinche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Jahan</surname></persName>
		</author>
		<ptr target="https://hal.archives-ouvertes.fr/hal-03336528" />
	</analytic>
	<monogr>
		<title level="m">16th International Conference on Document Analysis and Recognition (ICDAR 2021)</title>
		<meeting><address><addrLine>Lausanne, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021-09">2021, septembre</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">OCR17 : Ground Truth and Models for 17th c. French Prints (and hopefully more</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gabay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Clérice</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Reul</surname></persName>
		</author>
		<ptr target="https://hal.archives-ouvertes.fr/hal-02577236" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<ptr target="https://docs.github.com/en/get-started/quickstart/fork-a-repo" />
		<title level="m">Fork a repo</title>
		<imprint>
			<publisher>Github Inc</publisher>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>GitHub Docs</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">C</forename><surname>Jahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gabay</surname></persName>
		</author>
		<idno>OCR17 + (1.0</idno>
		<ptr target="https://doi.org/none" />
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Transkribus-A Service Platform for Transcription, Recognition and Retrieval of Historical Documents</title>
		<author>
			<persName><forename type="first">P</forename><surname>Kahle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Colutto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hackl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mühlberger</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICDAR.2017.307</idno>
		<ptr target="https://doi.org/10.1109/ICDAR.2017.307" />
	</analytic>
	<monogr>
		<title level="m">14th IAPR International Conference on Document Analysis and Recognition (ICDAR)</title>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="volume">04</biblScope>
			<biblScope unit="page" from="19" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">B</forename><surname>Kiessling</surname></persName>
		</author>
		<ptr target="https://github.com/mittagessen/kraken" />
		<imprint>
			<date type="published" when="2015">2021. 2015</date>
		</imprint>
	</monogr>
	<note>mittagessen/kraken : 3.0.5 (v3.0.5) [Python</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<author>
			<persName><forename type="first">V</forename><surname>Mariotti</surname></persName>
		</author>
		<ptr target="https://maritem.hypotheses.org/193" />
	</analytic>
	<monogr>
		<title level="m">Transcription automatique des feuillets du Manuscrit du Roi</title>
		<imprint>
			<date type="published" when="2020">2020, octobre 19</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Transcribing Foucault&apos;s handwriting with Transkribus</title>
		<author>
			<persName><forename type="first">M.-L</forename><surname>Massot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sforzini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ventresque</surname></persName>
		</author>
		<ptr target="https://hal.archives-ouvertes.fr/hal-01913435" />
	</analytic>
	<monogr>
		<title level="j">Journal of Data Mining and Digital Humanities</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>Atelier Digit_Hum</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">CREMMA Medieval, an Old French dataset for HTR and segmentation (1.0.1 Bicerin (DOI)) [XSLT</title>
		<author>
			<persName><forename type="first">A</forename><surname>Pinche</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.5235186</idno>
		<ptr target="https://doi.org/10.5281/zenodo.5235186" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">HTR-United/cremma-medieval : 1.0.1 Bicerin (DOI) (1.0.1) [Computer software]</title>
		<author>
			<persName><forename type="first">A</forename><surname>Pinche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Clérice</surname></persName>
		</author>
		<idno type="DOI">10.5281/ZENODO.5235186</idno>
		<ptr target="https://doi.org/10.5281/ZENODO.5235186" />
	</analytic>
	<monogr>
		<title level="j">Zenodo</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Pletschacher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Antonacopoulos</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICPR.2010.72</idno>
		<ptr target="https://doi.org/10.1109/ICPR.2010.72" />
		<title level="m">The PAGE (Page Analysis and Ground-Truth Elements) Format Framework. 2010 20th International Conference on Pattern Recognition</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="257" to="260" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Mixed Model OCR Training on Historical Latin Script for Out-of-the-Box Recognition and Finetuning</title>
		<author>
			<persName><forename type="first">C</forename><surname>Reul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nöth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Büttner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wehner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Springmann</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/2106.07881" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM Conference (HIP&apos;21</title>
		<meeting>ACM Conference (HIP&apos;21</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
	<note>submitted to</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Optical Recognition Assisted Transcription with Transkribus : The Experiment concerning Eugène Wilhelm&apos;s Personal Diary (1885-1951)</title>
		<author>
			<persName><forename type="first">R</forename><surname>Schlagdenhauffen</surname></persName>
		</author>
		<ptr target="https://hal.archives-ouvertes.fr/hal-02520508" />
	</analytic>
	<monogr>
		<title level="j">Journal of Data Mining and Digital Humanities</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>Atelier Digit_Hum</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The eScriptorium VRE for Manuscript Cultures</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Stokes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kiessling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Stökl Ben Ezra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tissot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Gargem</surname></persName>
		</author>
		<ptr target="https://classics-at.chs.harvard.edu/classics18-stokes-kiessling-stokl-ben-ezra-tissot-gargem/" />
	</analytic>
	<monogr>
		<title level="j">Classics@ Journal</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">L&apos;infrastructure eScriptorium de reconnaissance automatique d&apos;écriture manuscrite (HTR)</title>
		<author>
			<persName><forename type="first">Stökl</forename><surname>Ben</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ezra</forename></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename></persName>
		</author>
		<ptr target="https://projet.biblissima.fr/fr/infrastructure-escriptorium-reconnaissance-automatique-ecriture-manuscrite-htr" />
	</analytic>
	<monogr>
		<title level="m">Rendez-vous IIIF360</title>
		<imprint>
			<date type="published" when="2021">2021, mars 24</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Paléographie statistique pour décrire, identifier, dater</title>
		<author>
			<persName><forename type="first">D</forename><surname>Stutzmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Normaliser pour coopérer et aller plus loin ? 247</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">La recherche en plein texte dans les sources manuscrites médiévales : Enjeux et perspectives du projet HIMANIS pour l&apos;édition électronique</title>
		<author>
			<persName><forename type="first">D</forename><surname>Stutzmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-F</forename><surname>Moufflet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hamel</surname></persName>
		</author>
		<idno type="DOI">10.4000/medievales.8198</idno>
		<ptr target="https://doi.org/10.4000/medievales.8198" />
	</analytic>
	<monogr>
		<title level="j">Médiévales. Langues, Textes, Histoire</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">73</biblScope>
			<biblScope unit="page" from="67" to="96" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><surname>Teklia</surname></persName>
		</author>
		<ptr target="https://teklia.com/solutions/arkindex/releases/0-15-4/" />
		<title level="m">Teklia/Arkindex : 0</title>
		<imprint>
			<date type="published" when="2004">2021. v0.15.4</date>
			<biblScope unit="volume">15</biblScope>
		</imprint>
	</monogr>
	<note>Computer software</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
