<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Leveraging Concepts in Open Access Publications</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Andrea</forename><surname>Bertino</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Luca</forename><surname>Foppiano</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Laurent</forename><surname>Romary</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Pierre</forename><surname>Mounier</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Göttingen State and University Library</orgName>
								<address>
									<settlement>Göttingen, Inria, Paris</settlement>
									<region>ALMAnaCH, OpenEdition</region>
									<country>Germany, France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">EHESS</orgName>
								<address>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Leveraging Concepts in Open Access Publications</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">1DB17AE0BACC6E321895A92102AB380A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-08-24T15:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Named Entity Recognition and Disambiguation (NERD)</term>
					<term>Entity-Fishing</term>
					<term>Open Access</term>
					<term>Monographs</term>
					<term>Digital Publishing Platforms</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Aim: This paper addresses the integration of a Named Entity Recognition and Disambiguation (NERD) service within a group of open access (OA) publishing digital platforms and considers its potential impact on both research and scholarly publishing. This application, called entityfishing, was initially developed by Inria in the context of the EU FP7 project CENDARI <ref type="bibr" target="#b0">(Lopez et al., 2014)</ref> and provides automatic entity recognition and disambiguation against Wikipedia and Wikidata. Distributed with an open-source licence, it was deployed as a web service in the DARIAH infrastructure hosted at the French HumaNum. Methods: In this paper, we focus on the specific issues related to its integration on five OA platforms specialized in the publication of scholarly monographs in social sciences and humanities as part of the work carried out within the EU H2020 project HIRMEOS (High Integration of Research Monographs in the European Open Science infrastructure). Results and Discussion: In the following sections, we give a brief overview of the current status and evolution of OA publications and how HIRMEOS aims to contribute to this. We then give a comprehensive description of the entity-fishing service, focusing on its concrete applications in real use cases together with some further possible ideas on how to exploit the generated annotations. Conclusions: We show that entity-fishing annotations can improve both research and publishing process. Entity-fishing annotations can be used to achieve a better and quicker understanding of the specific and disciplinary language of certain monographs and so encourage non-specialists to use them. In addition, a systematic implementation of the entity-fishing service can be used by publishers to generate thematic indexes within book collections to allow better cross-linking and query functions.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"> <ref type="bibr">(OPERAS Consortium, 2017)</ref><p>. The current uncoordinated situation represents a major obstacle to the optimal dissemination of research results of the SSH disciplines and their impact on the structures of open science.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The H2020 HIRMEOS Project</head><p>The HIRMEOS project focuses on the monograph as a significant mode of scholarly communication in SSH and tackles the main obstacles to the full integration of five large-scale platforms supporting open access content. The main objective of HIRMEOS is to optimise five OA digital platforms for the publication of monographs from the SSH and to ensure their interoperability. An integrated publishing system would support scientific work by fostering basic research activities -the so-called scholarly primitives -i.e. writing, finding, annotating, referencing, assessing, exemplifying, presenting, as well as elementary activities in the digital field such as searching in browsers, connecting digital texts, collecting data, scanning and creating standards of data handling (data practices) <ref type="bibr" target="#b3">(Palmer et al., 2009)</ref>. HIRMEOS intends to transform collections of passive documents into corpora of enriched texts. More specifically, the participating platforms will be enhanced with services that enable identification, authentication and interoperability (via DOI, ORCID, FundRef), the annotation of monographs, the gathering of usage and alternative metric data, as well as using tools -like entity-fishingthat enrich the text with linked data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Entity Resolution Service</head><p>With the digital information explosion, over the last few decades the extraction and resolution of entities has been studied extensively <ref type="bibr" target="#b4">(Milne et al., 2007;</ref><ref type="bibr" target="#b5">Cucerzan, 2007)</ref> and has become a crucial task in large-scale text mining activities. Entity extraction and resolution is the task of determining the identity of entities mentioned in a text against a knowledge base representing the reality of the domain under consideration. This could be the recognition of generic Named Entities suitable in general purpose subjects, like person name, location, organisation name and so on, but also the resolution of specialist entities in different domains. Entity-fishing addresses these needs and provides a generic service for entity extraction and disambiguation (NERD) against Wikidata, supporting possible further adaptations for applications to specialist domains. This allows it to be independent of a particular framework and usage scenario for maximum reuse. Entity-fishing API allows the processing of different input (raw or partially annotated texts, PDF, search query), different languages and different formats. Entity-fishing employs supervised Machine Learning algorithms for both the recognition and the disambiguation tasks using training data generated from Wikipedia article structures <ref type="bibr" target="#b6">(Milne and Witten, 2008)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Entity-fishing Integration: Applications, Use Cases and beyond</head><p>The integration of the service during the HIRMEOS project was supervised and measured by different levels of increasing complexity (from the access to the API to the creation of new services using the generated data). After having successfully completed the basic integration to the API, each partner could choose to use the annotations based on their own needs and practices. The results have been summarised as a set of use cases, providing an initial feedback on common needs among publishing platforms. One of the most implemented use cases was the enhanced facet search based on entities extracted from the library content. Targeting Named Entity of Person and Location, the users were able to further restrict their search to some content-based information. This functionality required processing the entire collection and indexing all the generated annotations. A variant of this idea was the automatic generation of a word cloud at the repository level; in this way the users were able to access the most important concepts present in the monographs hosted at the digital library. An interesting evolution which could improve the search quality would be the generation of the word cloud at the search or book level, the cloud being updated at each query as the user narrows down the number of results. The annotations could in this way help to achieve better and quicker understanding of the specific and disciplinary language of certain monographs and so encourage non-specialists to use them. In this way, exploiting NERD annotations would foster interdisciplinary research. Other partners worked on a different approach, more focused on enhancing the visualisation of the monograph, by supporting annotation generated by entity-fishing to the monographs' landing page in order to automatically annotate content and seamlessly visualise it to the users. This visualisation could be further enhanced by having a slider at the side of the page that allows users to reduce or increase the detail of the annotations based on occurrence or type of entity. Finally, another interesting aspect pursued was the possibility to group books by their content extracted entities. Linking related books is one of the keys to boosting dissemination. Classic recommendation systems attempt to suggest additional articles or products the user might be interested in by exploiting the user's purchase history or the navigation. This could have a big impact on the dissemination in open access monograph catalogues. A simpler approach (which would not require collecting any user data) would be to process the generated annotations with clustering techniques. This would enable more cluster configurations, exploiting different aspects (domains, similarity, frequency, etc) of the collection annotations. There are indeed many more ideas that could be implemented to improve the user experience in terms of navigation or search. The search box could be improved by adding an additional layer dealing with disambiguation in the query in order to expand it to match the correct concept among several ambiguous possibilities. Entity-fishing could be also integrated in the process of feature generation as recommended by the CORE (https://core.ac.uk/), extracting concepts to be used as keywords for linking research outputs together. Another challenging idea is the possibility to extract all events and temporal expressions in order to build a timeline visualisation graph at the collection or book level. These use cases are applicable not only to other publishing platforms in SSH but potentially to any open access repository.</p></div>			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>bertino@sub.uni-goettingen.de</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Romary</surname></persName>
		</author>
		<title level="m">CENDARI Virtual Research Environment &amp; Named Entity Recognition techniques. Grenzen überschreiten -Digitale Geisteswissenschaft heute und morgen</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Open access publishing and scholarly communications in non-scientific disciplines</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Eve</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Online Information Review</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="717" to="732" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m">OPERAS Consortium. Operas design study</title>
		<imprint>
			<date type="published" when="2017-10">October 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Pirmann CM: Scholarly information practices in the online environment: Themes from the literature and implications for library service development</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">C</forename><surname>Teffeau</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Extracting corpus specific knowledge bases from wikipedia</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">N</forename><surname>Milne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nichols</forename><surname>Dn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Large-scale named entity disambiguation based on wikipedia data</title>
		<author>
			<persName><forename type="first">S</forename><surname>Cucerzan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning to link with wikipedia</title>
		<author>
			<persName><forename type="first">D</forename><surname>Milne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th ACM conference on Information and knowledge management</title>
		<meeting>the 17th ACM conference on Information and knowledge management</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="509" to="518" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
