<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Constraints on the Use of Language, Gesture and Speech for Multimodal Dialogues</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Bertrand</forename><surname>Gaiffe</surname></persName>
							<email>gaiffe@loria@fr</email>
							<affiliation key="aff0">
								<orgName type="institution">CRIN-CNRS &amp; INRIA Loraine</orgName>
								<address>
									<postBox>B.P. 239</postBox>
									<postCode>54506</postCode>
									<settlement>B~timent Loria, Vandceuvre L~s Nancy</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Laurent</forename><surname>Romary</surname></persName>
							<email>romary@loria@fr</email>
							<affiliation key="aff1">
								<orgName type="institution">CRIN-CNRS &amp; INRIA Loraine</orgName>
								<address>
									<postBox>B.P. 239</postBox>
									<postCode>54506</postCode>
									<settlement>B~timent Loria, Vandceuvre L~s Nancy</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Constraints on the Use of Language, Gesture and Speech for Multimodal Dialogues</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">61D63313D45F4D60EE97672093FA5198</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-08-24T14:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In the domain of natural language understanding and more precisely manmachine dialogue design, there are usually two trends of research which seem to be rather differentiated. On the one hand, many studies have tackled the problem of interpreting spatial references expressed in verbal utterances, focusing in particular on the different geometric or functionnal constraints which are bound to the existance of a "source" (or site) element in relation to which a 'target" is being situated. Such studies are usually based upon fine grained linguistic descriptions for different languages <ref type="bibr">(Vandeloise, 1986)</ref>. On the other hand, the problem raised by the integration of a gestural mode within classical NL interfaces has yielded some specific research about the association of demonstrative or deictic Nps together with designations, as initited by Bolt some two decades ago (cf. <ref type="bibr">Thorisson et alii, 1992;</ref><ref type="bibr">Bellalem and Romary, 1995)</ref>. Our aim in this paper is to show that the different phenomena described in the context of spatial reference or multimodal interaction should not necessarily be considered as two independant issues, but should rather be analysed in a unified way to account for the fact that they are both based on linguistic and perceptual data. As a matter of fact, if we consider a situation of man-machine dialogue where the user is presented with a graphical representation of his task, it is clear that, given a certain informational content he wants to convey, h e will essentially choose a referring mode which seems most relevant in the current communicative situation. For example, if we consider a graphical situation such as that described in figure <ref type="figure">1</ref>.1, he may either use the black triangle, this triangle (+ pointing gesture), the leftmost triangle to refer to the left most object, and it would be quite annoying to consider these different expressions as corresponding to uncomparable referring modes 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Â© Figure 1.1</head><p>In this context, we will try to show how language, gesture and perception can be seen in a uniform way from the perspective of referential analysis, even if doing so we will have to look at the specific constraints which underly the speaker's choice of a given expression. To this end, we will first quickly situate the relative importance of speech and gesture in man-machine communication. Then, we will concentrate upc~ the specific effects resulting from the combination of verbal, gestural and perceptual information, showing that on the one hand the three provide structural constraints to the objects which are being referred to and on the other hand that any referring operation, whatever its origin, has to be interpreted within a localized frame, with some consequences upon dialogue management.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Several means to make a referring act</head><p>When designating a given object within a visual environment, it seem at first sight that Natural Language provides uncomparable means to do so as opposed to gesture. Beyond the different determiners which are present in most natural languages either explicitely or implicitely (indefinite, definite or demonstrative), nominal categories allows one to set the proper level of granularity corresponding to the intended object. Indeed, in a situation where a gesture would be ambiguous and point to the overall scene (a set of geometrical shapes), a specific i In particular, gricean maxims as well as relevance theory (Sperber and Wilson, 1986) would tend towards an analysis which compare the different referring expressions in terms of cognitive cost. object (a triangle) or any of its part (a segment, a point etc.), the sole phrase the triangle may directly designate what is being intended. Another important aspect is that pointing gestures 2, when used in the general framework of an oral dialogue, can seldom appear in isolation, wheras a definite description such as the blue triangle can clearly be expressed independantly of any gesture. The reason for this is, as we said, that the intrisic ambiguity of gesture implies that it should be complemented with a categorizing expression, but also because a gesture cannot express very easily an action to be performed upon the by means of formulae (at step b) such as:  designated _,object and has thus to be also complemented by a predicative utterance. In this latter case, it is hard to imagine that any combination will be possible between linguistic chunks and gestural acts. In particular, gesture can hardly fill a role which is mandatory for a given predicate, since it would lead to odd utterances such as ?give me the color of <ref type="bibr">[pointing]</ref>.</p><formula xml:id="formula_0">* triangle(R) &amp; (card(R) &gt;= 2) &amp; R included R' &amp; R</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Reference and contrast</head><p>The schematic algorithm used in most dialogue systems in order to deal with referential NPs (in the case they get their reference within a context which is visually presented) can be expressed as: a) get all the indices from the expression; b) deduce from these indices some constraints which must be true in the visual representation; c) filter the referent(s) thanks to these constraints. In such a framework, what would be expected as the system's perceptuel abilities boils down to an ability to build the set of objects appearing on the screen. Such an approach would compute the "correct" referents in such examples as:  probably prefer an expression such as the two leftmost triangles or these triangles together with a "peripheral" designation as we will describe it latter. Our claim about the necessity of a perceivable discrimination seems in accordance with what Robert Dale (Reiter and Dale 1992, Dale 1995) observes about referential expression generation. Just as we do, he argues that the relevance of a refering expression does not only rely on its ability to filter a unique referent but also cn its ability to establish a contrast in a contextual set of objects.  If a dialogue system has to understand such expressions as those we mentioned so far, h e therefore should perceive its environment on a more "user compatible" basis. We suggest at least that perceptual contrasts should be taken into account in order to structure the set of visible objects. When no contrast pre-exists which would directly support an intended reference, we mentioned the possibility to build a group on the basis of individuals by such an explicit expression as "the two leftmost triangles". A corresponding solution in terms of demonstrative use would be something like this triangle and this one (or these two triangles) together with two pointing gestures. Another solution consists in building the contrast by means of a "peripheral designation" which justifies our claim about considering perception and designation on a unified constrastive basis. In order to argue that claim, we will now re-consider gestures almost independantly from the referential expressions they accompany.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Gesture and contrast</head><p>Our analysis of demonstrative and definite NPs (when referring within a perceptual environment) relies on perceptually founded contrasts. The required precision of a designation gesture therefore depends upon these perceptive constrasts. In such an example as: relies on the same kind of horizontal discrimination: the only difference with the preceeding example is that we refer to a cohesive group. The horizontal discrimination identifies here two groups from which gesture only has to select one. However, such situations as: do not provide any perceptual grouping of something which would correspond to "the upper and the righmost triangles in the left group of three". If the user intends to refer to these two triangles, he has to build a discrimination into the group. A possible gesture to do that is depicted bellow: Such "peripheral" designations take up for the absence of a shared perceptual feature (such colour), as it both gather up the two objects and put them into focus. The analysis of the whole intervention (the gesture plus the NP "these triangles") is then of the same kind as its equivalent in 2.3.b. As such, we clearly see here that gesture, instead of just being another mtxte of communication, [] pertains to the same domain as perceptual information.</p><p>[] Our analysis so far can thus be summarized as " follows: a contrast based on the category has to match a perceptive contrast in the case of simple definite Nps, thus meaning that perceivable triangles should be considered when analyzing the triangle(s)</p><p>a contrast based on saliance has to match a perceptive contrast in the case of demonstrative Nps. As we only considered in this paper demonstrative plus gestures, the required saliance is yielded by gesture itself a spatial contrast has to match a perceptive contrast (not necesserally spatial) in the case of spatial definite NPs. The remaining problem is now to limit the context in which we consider these contrasts. There are expressions in dialogue corpora that cannot be properly understood if we do not take into account focusing phenomena as well as attentional contexts and visual capabilities. Moreover, as we will justify, in such reduced contexts, functionality associated to the objects considered may introduce specific orientations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Localizing spatial references</head><p>Having shown that any spatial --in the broad sense we want to advocate --reference is based upon a structural organisation of a set of elements, we will now see how this very set plays a real role of contextualizing the referring process, with some consequences upon dialogue management. Indeed, all our examples so far were simple enough to imply that there was only one context in which to find the intended referent. On the contrary, i f we consider a more complex situation taken from a Wizard of Oz simulation in the domain of interior furnishing <ref type="bibr">(Dauchy et alii, 1993;</ref><ref type="bibr">Mignot et alii 1993)</ref>, we will see that our analysis should actually be drawn a step further. Figure <ref type="figure" target="#fig_7">4</ref>.1 examplifies a typical situation that was presented to the user during the experiment, with an empty drawing room to be furnished using the presented elements. speaker and the hearer for a spatial reference to be understood, we can quickly see that this structure can only be inferred within a localized context which first limits its extension, but also subsumes its general characteristics such as the categories of objects, their perceptual or functional properties etc. Paradoxically, we could say that it is difficult to contrast objects having little or nothing in common as there would be no reason for a speaker to compare them in any way. Besides, such contexts seem to have a certain amount of stability during a dialogue, as can be seen in the following example associated with figure 4.2: U1 : turn the sofa round U2 : move up a bit the armchair on the right I1.</p><p>, f'  Following the observation that there should be a prior structure shared by both the</p><p>Here, it appears that the spatial reference in the second utterance is not computed globally on the visualized scene but upon a sub-space resulting from the interpretation of the first utterance and thus centered on the sofa. Such a sub-space is characterized by its spatial inclusion within that of the drawing room, hut also by the different characteristics (especially functionnal ones) of the objects i t contains. At this stage we can thus caracterize a spatial referring operation as a double system of vertical and horizontal relationships within a context which encompasses the object which is being referred to, but also the set of alternatives which being stated either explicitaly or implicitaly during the current referring act or the rest of the dialogue. Figure <ref type="figure" target="#fig_7">4</ref>.3 summarizes these different constraints for a reference to object O1 within a context C, the alternatives being reduced here to a single object 02. about the actual contrasting relation and thus makes the presence of alternatives all the more obvious. For the two other cases, it is usually through the following utterances that, as we have seen, we can justify the presence of the set of alternatives. As a matter of fact, one consequence of constraining a referential operation to a localized frame is that these have a certain amount of stability from utterance to utterance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>In this paper, we argue on the one hand for a unified account of gesture and perception, and on the other hand for a matching between contrastive conditions required by referential 4 There can be of course many different contexts projected upon a ~iven object, as this depends upon the intention that the speaker wants to convey about it.</p><p>expressions and a pre-existing perceptual contrast. We show that such a contrast has to be localized and to exhibit traces of these contexts through dialogue structures as well as specific orientation properties related to such perceptual contexts. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2</head><label>2</label><figDesc>Figure 2.1.b: the leflmost triangles and</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2</head><label>2</label><figDesc>Figure 2.1.a: the leflmost triangles</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2</head><label>2</label><figDesc>Figure 2.2.b: these triangles What seems to lack in examples 2.1.a and 2.2.a is a visual contrast that pre-exists to the refering expression. The refering expression itself is not sufficient to establish such a contrast. If the user intends to refer to the first two triangles of figure 2.1.a, he would</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Examples 2.1.b and 2.2.b rely on an already accessible discrimination based upon spatial cohesion. In such a case, the definite referring expression (the leftmo~t triangle) directly maps the spatial discrimination. Such examples as:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 2</head><label>2</label><figDesc>Figure 2.3.a: the leftmost triangles and</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>the gesture only has to separate the two triangles along the horizontal, since the perceptive contrast relies upon a separation of the objec~ on that direction. No strict inclusion of the pointing into the left triangle is required. The situation depicted below 3 In some cases, the speaker has the possibility to elicit the contrasfive feature. E.g. The l~lack triangles (fig.2.3.b)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 . 2 :</head><label>42</label><figDesc>Figure 4.2: Referential contextualisation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 4</head><label>4</label><figDesc>Figure 4.1 : Initial scene for the interior furnishing scenario.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 4</head><label>4</label><figDesc>Figure 4.3: localizing links</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>at the left as compared to (R'-R)</figDesc><table><row><cell>in what concerns 2.1.a and</cell></row><row><cell>e triangleR) &amp; (card(R) &gt;= 2) &amp; (made</cell></row><row><cell>sallient (by gesture) R) in what concerns</cell></row><row><cell>2.2.a.</cell></row><row><cell>Although these two referential expressions, if</cell></row><row><cell>ever used, are unambiguous, we would</cell></row><row><cell>certainly prefer such examples as:</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Basil Blackwell, Oxford. Thorisson K., D. Koons et R. Bolt 1992, Multimodal natural dialogue, Acres CHF92, USA, p. 653-654. (Annelies).</figDesc><table><row><cell cols="2">7. References</cell><cell></cell><cell></cell></row><row><cell cols="5">Alien James F. and Raymond C. Perrault 1980,</cell></row><row><cell cols="2">Analyzing</cell><cell>intention</cell><cell>in</cell><cell>utterances,</cell></row><row><cell cols="5">Artificial Intelligence, 15, p. 143-178.</cell></row><row><cell cols="5">Bellalem Nadia and Laurent Romary 1995,</cell></row><row><cell cols="5">Reference interpretation in a multimodal</cell></row><row><cell cols="5">environment combining speech and gesture,</cell></row><row><cell cols="5">Actes First IMMI Workshop, Edinburgh.</cell></row><row><cell cols="5">Cadoz Claude 1992, Le geste canal de</cell></row><row><cell cols="5">communication hormne/machine</cell><cell>-1 a</cell></row><row><cell cols="5">communication instrumentale, Technique e t</cell></row><row><cell cols="5">Science Informatique, 13, 1, p. 31-61.</cell></row><row><cell>Dale</cell><cell cols="4">Robert and Ahud Reiter</cell><cell>1992,</cell></row><row><cell cols="5">Computational Interpretations of Gricean</cell></row><row><cell cols="5">Maxims in the Generation of Referring</cell></row><row><cell cols="4">Expressions, Actes Coling-92.</cell></row><row><cell cols="5">Dale Robert 1995, Generating One-Anaphoric</cell></row><row><cell cols="5">Expressions: Where Does the Decision</cell></row><row><cell cols="5">Lie?, Actes Working Papers of PACLING-</cell></row><row><cell cols="5">II, Brisbane, Australia, p. 49-58.</cell></row><row><cell cols="5">Dauchy P., C. Mignot and C. Valot 1993, Joint</cell></row><row><cell cols="5">speech and gesture analysis : some</cell></row><row><cell cols="5">experimental results, Actes Eurospeech 93,</cell></row><row><cell cols="2">p. 1315-1318.</cell><cell></cell><cell></cell></row><row><cell cols="5">Mignot C., C. Valot et N. Carbonell 1993, An</cell></row><row><cell cols="5">Experimental Study of Future "'Natural"</cell></row><row><cell cols="5">Multimodal Human-Computer Interaction,</cell></row><row><cell cols="5">Actes INTERCHI'93 1993 Conference on</cell></row><row><cell cols="5">Human Factors in Computing Science</cell></row><row><cell cols="5">INTERACT'93 and CHI'93, Amsterdam</cell></row><row><cell cols="3">(The Netherlands).</cell><cell></cell></row><row><cell cols="5">Schang D. et L. Romary 1994, Framing the</cell></row><row><cell cols="5">world, towards a locahsed</cell><cell>spatial</cell></row><row><cell cols="2">reasoning,</cell><cell>Acres</cell><cell>3rd</cell><cell>International</cell></row><row><cell cols="5">Conference on the Cognitive Science of</cell></row><row><cell cols="5">Natural Language Processing (CSNLP-94),</cell></row><row><cell cols="2">Dublin.</cell><cell></cell><cell></cell></row><row><cell cols="5">Sperber Dan et Deidre Wilson 1986,</cell></row><row><cell cols="5">Relevance, communication and cognition,</cell></row></table><note><p>Vandeloise Claude 1986, L'espace enfran~ais, Editions du Seuil, Paris.</p></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl/>
			</div>
		</back>
	</text>
</TEI>
