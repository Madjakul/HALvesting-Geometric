<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Collaborative Machine Translation Service for Scientific texts</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Patrik</forename><surname>Lambert</surname></persName>
							<email>patrik.lambert@lium.univ-lemans.fr</email>
						</author>
						<author>
							<persName><forename type="first">Jean</forename><surname>Senellart</surname></persName>
							<email>senellart@systran.fr</email>
						</author>
						<author>
							<persName><forename type="first">Laurent</forename><surname>Romary</surname></persName>
							<email>laurent.romary@inria.fr</email>
						</author>
						<author>
							<persName><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
							<email>holger.schwenk@lium.univ-lemans.fr</email>
						</author>
						<author>
							<persName><forename type="first">Florian</forename><surname>Zipser</surname></persName>
							<email>f.zipser@gmx.de</email>
						</author>
						<author>
							<persName><forename type="first">Patrice</forename><surname>Lopez</surname></persName>
							<email>patrice.lopez@inria.fr</email>
						</author>
						<author>
							<persName><forename type="first">Frédéric</forename><surname>Blain</surname></persName>
							<email>frederic.blain@lium.univ-lemans.fr</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University of Le Mans</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Humboldt Universität Berlin</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">INRIA Saclay -Ile de France</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">University of Le Mans</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">Humboldt Universität Berlin</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="institution">Humboldt Universität Berlin</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="institution">INRIA Saclay -Ile de France</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff7">
								<orgName type="institution">Systran SA</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff8">
								<orgName type="institution">University of Le Mans</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Collaborative Machine Translation Service for Scientific texts</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">98B897BB26161FD4578279E732BEC39A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-08-24T15:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>French researchers are required to frequently translate into French the description of their work published in English. At the same time, the need for French people to access articles in English, or to international researchers to access theses or papers in French, is incorrectly resolved via the use of generic translation tools. We propose the demonstration of an end-to-end tool integrated in the HAL open archive for enabling efficient translation for scientific texts. This tool can give translation suggestions adapted to the scientific domain, improving by more than 10 points the BLEU score of a generic system. It also provides a post-edition service which captures user post-editing data that can be used to incrementally improve the translations engines. Thus it is helpful for users which need to translate or to access scientific texts.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Due to the globalisation of research, the English language is today the universal language of scientific communication. In France, regulations require the use of the French language in progress reports, academic dissertations, manuscripts, and French is the official educational language of the country. This situation forces researchers to frequently translate their own articles, lectures, presentations, reports, and abstracts between English and French. In addition, students and the general public are also challenged by language, when it comes to find published articles in English or to understand these articles. Finally, international scientists not even consider to look for French publications (for instance PhD theses) because they are not available in their native languages. This problem, incorrectly resolved through the use of generic translation tools, actually reveals an interesting generic problem where a community of specialists are regularly performing translations tasks on a very limited domain. At the same time, other communities of users seek translations for the same type of documents. Without appropriate tools, the expertise and time spent for translation activity by the first community is lost and do not benefit to translation requests of the other communities.</p><p>We propose the demonstration of an end-to-end tool for enabling efficient translation for scientific texts. This system, developed for the COSMAT ANR project, 1 is closely integrated into the HAL open archive, 2 a multidisciplinary open-access archive which was created in 2006 to archive publications from all the French scientific community. The tool deals with handling of source document format, generally a pdf file, specialised translation of the content, and user-friendly userinterface allowing to post-edit the output. Behind the scene, the post-editing tool captures user postediting data which are used to incrementally improve the translations engines. The only equipment required by this demonstration is a computer with an Internet browser installed and an Internet connection.</p><p>In this paper, we first describe the complete work-flow from data acquisition to final postediting. Then we focus on the text extraction procedure. In Section 4, we give details about the translation system. Then in section 5, we present the translation and post-editing interface. We finally give some concluding remarks.</p><p>The system will be demonstrated at EACL in his tight integration with the HAL paper deposit system. If the organizers agree, we would like to offer the use of our system during the EACL conference. It would automatically translate all the abstracts of the accepted papers and also offers the possibility to correct the outputs. This resulting data would be made freely available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Complete Processing Work-flow</head><p>The entry point for the system are "ready to publish" scientific papers. The goal of our system was to extract content keeping as many metainformation as possible from the document, to translate the content, to allow the user to perform post-editing, and to render the result in a format as close as possible to the source format. To train our system, we collected from the HAL archive more than 40 000 documents in physics and computer science, including articles, PhD theses or research reports (see Section 4). This material was used to train the translation engines and to extract domain bilingual terminology.</p><p>The user scenario is the following:</p><p>• A user uploads an article in PDF format 3 on the system.</p><p>• The document is processed by the opensource Grobid tool (see section 3) to extract 3 The commonly used publishing format is PDF files while authoring format is principally a mix of Microsoft Word file and LaTeX documents using a variety of styles. The originality of our approach is to work on the PDF file and not on these source formats. The rationale being that 1/ the source format is almost never available, 2/ even if we had access to the source format, we would need to implement a filter specific to each individual template required by such or such conference for a good quality content extraction the content. The extracted paper is structured in the TEI format where title, authors, references, footnotes, figure captions are identified with a very high accuracy.</p><p>• An entity recognition process is performed for markup of domain entities such as: chemical compounds for chemical papers, mathematical formulas, pseudo-code and object references in computer science papers, but also miscellaneous acronyms commonly used in scientific communication.</p><p>• Specialised terminology is then recognised using the Termsciences<ref type="foot" target="#foot_2">4</ref> reference terminology database, completed with terminology automatically extracted from the training corpus. The actual translation of the paper is performed using adapted translation as described in Section 4.</p><p>• The translation process generates a bilingual TEI format preserving the source structure and integrating the entity annotation, multiple terminology choices when available, and the token alignment between source and target sentences.</p><p>• The translation is proposed to the user for post-editing through a rich interactive interface described in Section 5.</p><p>• The final version of the document is then archived in TEI format and available for display in HTML using dedicated XSLT style sheets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The Grobid System</head><p>Based on state-of-the-art machine learning techniques, Grobid <ref type="bibr" target="#b2">(Lopez, 2009)</ref> performs reliable bibliographic data extraction from scholar articles combined with multi-level term extraction. These two types of extraction present synergies and correspond to complementary descriptions of an article. This tool parses and converts scientific articles in PDF format into a structured TEI document<ref type="foot" target="#foot_3">5</ref> compliant with the good practices developed within the European PEER project <ref type="bibr" target="#b0">(Bretel et al., 2010)</ref>. Grobid is trained on a set of annotated scientific article and can be re-trained to fit templates used for a specific conference or to extract additional fields.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Translation of Scientific Texts</head><p>The translation system used is a Hybrid Machine Translation (HMT) system from French to English and from English to French, adapted to translate scientific texts in several domains (so far physics and computer science). This system is composed of a statistical engine, coupled with rule-based modules to translate special parts of the text such as mathematical formulas, chemical compounds, pseudo-code, and enriched with domain bilingual terminology (see Section 2). Large amounts of monolingual and parallel data are available to train a SMT system between French and English, but not in the scientific domain. In order to improve the performance of our translation system in this task, we extracted in-domain monolingual and parallel data from the HAL archive. All the PDF files deposited in HAL in computer science and physics were made available to us. These files were then converted to plain text using the Grobid tool, as described in the previous section. We extracted text from all the documents from HAL that were made available to us to train our language model. We built a small parallel corpus from the abstracts of the PhD theses from French universities, which must include both an abstract in French and in English. Table <ref type="table" target="#tab_0">1</ref> presents statistics of these in-domain data.</p><p>The data extracted from HAL were used to adapt a generic system to the scientific literature domain. The generic system was mostly trained on data provided for the shared task of Sixth Workshop on Statistical Machine Translation<ref type="foot" target="#foot_4">6</ref> (WMT 2011), described in Table <ref type="table" target="#tab_3">2</ref>.</p><p>Table <ref type="table">3</ref> presents results showing, in the English-French direction, the impact on the statistical engine of introducing the resources extracted from HAL, as well as the impact of domain adaptation techniques. The baseline statistical engine is a standard PBSMT system based on Moses <ref type="bibr" target="#b1">(Koehn et al., 2007)</ref> and the SRILM tookit <ref type="bibr" target="#b4">(Stolcke, 2002)</ref>. Is was trained and tuned only on WMT11 data (out-of-domain). Incorporating the HAL data into the language model and tuning the system on the HAL development set, tracted from all documents in HAL, in computer science (cs) and physics (phys). The following statistics are given for the English (En) and French (Fr) sides (Lg) of the corpus: the number of sentences, the number of running words (after tokenisation) and the number of words in the vocabulary (M and k stand for millions and thousands, respectively).</p><p>yielded a gain of more than 7 BLEU points, in both domains (computer science and physics). Including the theses abstracts in the parallel training corpus, a further gain of 2.3 BLEU points is observed for computer science, and 3.1 points for physics. The last experiment performed aims at increasing the amount of in-domain parallel texts by translating automatically in-domain monolingual data, as suggested by <ref type="bibr" target="#b3">Schwenk (2008)</ref>. The synthesised bitext does not bring new words into the system, but increases the probability of indomain bilingual phrases. By adding a synthetic bitext of 12 million words to the parallel training data, we observed a gain of 0.5 BLEU point for computer science, and 0.7 points for physics.</p><p>Although not shown here, similar results were obtained in the French-English direction. The French-English system is actually slightly better than the English-French one as it is an easier translation direction.     </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Post-editing Interface</head><p>The collaborative aspect of the demonstrated machine translation service is based on a post-editing tool, whose interface is shown in Figure <ref type="figure" target="#fig_1">1</ref>. This tool provides the following features:</p><p>• WYSIWYG display of the source and target texts (Zones 1+2)</p><p>• Alignment at the sentence level (Zone 3)</p><p>• Zone to review the translation with alignment of source and target terms (Zone 4) and terminology reference (Zone 5)</p><p>• Alternative translations (Zone 6)</p><p>The tool allows the user to perform sentence level post-editing and records details of postediting activity, such as keystrokes, terminology selection, actual edits and time log for the complete action.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions and Perspectives</head><p>We proposed the demonstration of an end-to-end tool integrated into the HAL archive and enabling efficient translation for scientific texts. This tool consists of a high-accuracy PDF extractor, a hybrid machine translation engine adapted to the scientific domain and a post-edition tool. Thanks to in-domain data collected from HAL, the statistical engine was improved by more than 10 BLEU points with respect to a generic system trained on WMT11 data.</p><p>Our system was deployed for a physic conference organised in Paris in Sept 2011. All accepted abstracts were translated into author's native languages (around 70% of them) and proposed for post-editing. The experience was promoted by the organisation committee and 50 scientists volunteered (34 finally performed their post-editing). The same experience will be proposed for authors of the LREC conference. We would like to offer a complete demonstration of the system at EACL. The goal of these experiences is to collect and distribute detailed "post-editing" data for enabling research on this activity.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Table 3 :</head><label>3</label><figDesc>Results (BLEU score) for the English-French systems. The type of parallel data used to train the translation model or language model are indicated, as well as the set (in-domain or out-of-domain) used to tune the models. Finally, the number of words in the parallel corpus and the BLEU score on the in-domain test set are indicated for each domain: computer science and physics.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Translation and post-editing interface.</figDesc><graphic coords="4,72.14,219.22,446.41,240.17" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Statistics for the parallel training, development, and test data sets extracted from thesis abstracts contained in HAL, as well as monolingual data ex-</figDesc><table><row><cell>Parallel data</cell><cell></cell><cell></cell></row><row><cell cols="4">Train cs+phys En 55.9 k 1.41 M 43.3 k</cell></row><row><cell></cell><cell cols="3">Fr 55.9 k 1.63 M 47.9 k</cell></row><row><cell>Dev cs</cell><cell cols="3">En 1100 25.8 k 4.6 k</cell></row><row><cell></cell><cell>Fr</cell><cell cols="2">1100 28.7 k 5.1 k</cell></row><row><cell>phys</cell><cell cols="3">En 1000 26.1 k 5.1 k</cell></row><row><cell></cell><cell>Fr</cell><cell cols="2">1000 29.1 k 5.6 k</cell></row><row><cell>Test cs</cell><cell cols="3">En 1100 26.1 k 4.6 k</cell></row><row><cell></cell><cell>Fr</cell><cell cols="2">1100 29.2 k 5.2 k</cell></row><row><cell>phys</cell><cell cols="3">En 1000 25.9 k 5.1 k</cell></row><row><cell></cell><cell>Fr</cell><cell cols="2">1000 28.8 k 5.5 k</cell></row><row><cell cols="2">Monolingual data</cell><cell></cell></row><row><cell>Train cs</cell><cell cols="2">En 2.5 M</cell><cell>54 M 457 k</cell></row><row><cell></cell><cell cols="2">Fr 761 k</cell><cell>19 M 274 k</cell></row><row><cell>phys</cell><cell cols="2">En 2.1 M</cell><cell>50 M 646 k</cell></row><row><cell></cell><cell cols="2">Fr 662 k</cell><cell>17 M 292 k</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Out-of-domain development and training data used (number of words after tokenisation).</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>http://www.cosmat.fr/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>http://hal.archives-ouvertes.fr/?langue=en</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>http://www.termsciences.fr</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3"><p>http://www.tei-c.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_4"><p>http://www.statmt.org/wmt11/translation-task.html Set Domain Lg Sent. Words Vocab.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work has been partially funded by the French Government under the project COSMAT (ANR ANR-09-CORD-004).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Back to meaning -information structuring in the PEER project</title>
		<author>
			<persName><forename type="first">Foudil</forename><surname>Bretel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrice</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maud</forename><surname>Medves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alain</forename><surname>Monteil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Romary</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TEI Conference</title>
		<meeting><address><addrLine>Zadar, Croatie</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Moses: Open source toolkit for statistical machine translation</title>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hieu</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicola</forename><surname>Bertoldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brooke</forename><surname>Cowan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wade</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christine</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Zens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ondrej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evan</forename><surname>Herbst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 45th Annual Meeting of the Association for Computational Linguistics (Demo and Poster Sessions)</title>
		<meeting>of the 45th Annual Meeting of the Association for Computational Linguistics (Demo and Poster Sessions)<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007-06">2007. June</date>
			<biblScope unit="page" from="177" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">GROBID: Combining automatic bibliographic data recognition and term extraction for scholarship publications</title>
		<author>
			<persName><forename type="first">Patrice</forename><surname>Lopez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ECDL 2009, 13th European Conference on Digital Library</title>
		<meeting>ECDL 2009, 13th European Conference on Digital Library<address><addrLine>Corfu, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Investigations on large-scale lightly-supervised training for statistical machine translation</title>
		<author>
			<persName><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IWSLT</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="182" to="189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">SRILM: an extensible language modeling toolkit</title>
		<author>
			<persName><forename type="first">A</forename><surname>Stolcke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Int. Conf. on Spoken Language Processing</title>
		<meeting>of the Int. Conf. on Spoken Language essing<address><addrLine>Denver, CO</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="901" to="904" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
