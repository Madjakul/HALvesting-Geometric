<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Reference interpretation in a multimodal environment combining speech and gesture</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Nadia</forename><surname>Bellalem</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">CRIN-CNRS &amp; INRIA Lorraine Bâtiment LORIA BP 239</orgName>
								<address>
									<postCode>F-54506</postCode>
									<settlement>Vandoeuvre-lès-Nancy</settlement>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Laurent</forename><surname>Romary</surname></persName>
							<email>romary@loria.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">CRIN-CNRS &amp; INRIA Lorraine Bâtiment LORIA BP 239</orgName>
								<address>
									<postCode>F-54506</postCode>
									<settlement>Vandoeuvre-lès-Nancy</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Reference interpretation in a multimodal environment combining speech and gesture</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C3B30BF85F241CF68F277271A4C4C69D</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-08-24T15:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The study presented in this paper is dedicated to the integration of pointing gestures within a task oriented man-machine dialogue system. From our point of view, it is natural to see this problem as a sub-part of the more general study of reference in a dialogue since we took the option to limit the analysis of gestures to those explicitly associated with speech and more specifically for singling out objects in the task. Even under these hypotheses, understanding the global message resulting from the combinaison of speech and gesture implies that a precise analysis of the gestural trajectory should be done. This analysis may be split up into two main steps. The first, which we may call structural, is centred upon the shape of the gestural trajectory to mark the meaningful parts to which a specific designation role will be given. The second step has to do with the contextual interpretation of the gesture for which one has to take into account a) the features of the application and the way it is visualized and b) the oral dialogue and more specifically the instructional content of the referring expression accompanying the gesture.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Using speech as the sole means of communication between a human and a machine may seem inappropriate when the problem at hand is to manage and pilot an application with a strong visual component (e.g. presented on a graphical display). Indeed, the task constraints may force the user/ speaker to create utterances containing complex referential expressions to isolate a specific object among others with very similar characteristics, in particular their categories and thus the noun used to refer to them. Nevertheless, considerable progress has been made in unravelling the mechanisms underlying the interpretation of spatial prepositions such as on the right of, above, behind etc. <ref type="bibr">[Pribbenow,</ref><ref type="bibr">93]</ref>, <ref type="bibr">[Schang,</ref><ref type="bibr">94]</ref>.</p><p>The other possibility at hand to refer to objects in the task to be managed is to use, in close connection with specific linguistic expressions bearing a deictic value, a designation gesture which has the strong advantage of providing a quick and direct access to visual objects <ref type="bibr">[Wahlster,</ref><ref type="bibr">91]</ref>. As a matter of fact, this is very similar to what happens during human to human communication when reference is made to the surrounding environment. These two ways of referring to objects in a man-machine dialogue are to be seen as complementary, and neither of them must be left aside when designing dialogue systems as it has been proved in Wizard of Oz simulations [e.g. <ref type="bibr">Mignot,</ref><ref type="bibr">93</ref>] that both are to be observed. In this framework, our study will focus upon the specific problem of designating gestures, seeing them as participating in the overall communicative framework within man-machine dialogue. To this end, we will present the main linguistic elements which may be interpreted in combination with gesture, as well as the main steps leading to the understanding of the corresponding trajectories in dialogue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Linguistic expressions and designation</head><p>A classical view of natural language reference to objects in discourse could lead to the following classification of French linguistic markers which are presenting a deictic spatial value <ref type="bibr">[Cosnier,</ref><ref type="bibr">82]</ref>: demonstrative adjectives (ce, cet, cette, ces), demonstrative pronouns <ref type="bibr">(ça, celui-ci, celui-là)</ref>, "pure" deictics such as ici (here) and là (there). These markers take part in the construction of demonstrative Noun Phrases. It may appear strange to limit ourselves to such restricted set when intuition seems to indicate that gesture may appear together with many other indicators (e.g. definite description, pronouns, etc.). For more details relating to this issue, cf. <ref type="bibr">[Corblin,</ref><ref type="bibr">87]</ref> and <ref type="bibr">[Kleiber,</ref><ref type="bibr">92]</ref>.</p><p>Within a natural language dialogue context, it is necessary to define precisely the respective roles of both the designation gesture and the referential expression which supports it up. The designation gesture may be roughly characterized as a hand movement whose role is to direct the user's gaze towards a specific area in the shared visual space. The aim is thus to focalize the addressee's attention upon a given region in order to isolate either certain objects which are being presented, or simply a locus in the scene. As a counterpart, the verbal channel provides a frame for the interpretation of reference. In particular, it provide specific categorial information which a gesture cannot provide, as well as some constraints regarding the number of objects belonging to the sub-space marked out by the gesture. To give a more precise account of this contrastive analysis of the pair [referential expression+gesture], we may briefly look at the specific case of demonstrative NPs of the type ce N (this N). In previous works <ref type="bibr">[Gaiffe,</ref><ref type="bibr">94]</ref>, following some orientations given by <ref type="bibr">[Corblin,</ref><ref type="bibr">87]</ref> and others it has been shown, that such an expression carried an intra categorial contrast within a set. This means that an element which can be attached to the category 'N' is to be distinguished from other elements of the same category, because of its specific focal situation. In the specific case of a graphical presentation of a task, this principle may be seen as equivalent to a sifting of the presentation space so that only objects of the type 'N' are considered, any other referent being made opaque at this step of the interpretation. Considering this, the analysis of the designation trajectory may be carried out on the basis of the level of granularity (i.e. the scale) providing by this N-filtering, without taking into account finer grained levels of precision. The final interpretation thus corresponds to the more focal element, taking into account the different singularities (we will explain this notion in section 3.1.1) encountered within the gestural trajectory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Analysing the designation gesture</head><p>To illustrate our views, we will consider an application to interior furnishing which seems to correspond clearly to the kind of tasks where a gestural component could be beneficially introduced. In this context, we will try to make clear the different steps leading to a proper understanding of the oral + gestural message. The task consists in manipulating graphical objects which are viewed in a scene. The verbal utterances are essentially positioning statements containing the following elements:</p><p>-action -set of objects (possibly one) More specifically, we will centre our analysis upon the example shown in figure one corresponding to the utterance "put this armchair here".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">A structural analysis of gesture</head><p>The first step in the recognition and understanding process for a referring gesture consists in analysing the gestural signal independently from the scene upon which it has occurred, in order to detect the different components of meaning that it may contain. As a matter of fact, it should be noticed that the gestural signal coming from the pointing device is a stream of data corresponding to a complete hand motion, that is, comprising a motion towards the designation area, the actual designation associated with the verbal message and finally a motion away from the designated area. It is clear that only the central portion is of importance to us since it embodies most of the meaning of the gesture. The main problem is to be able to differentiate their position from the rest of the signal. To this end, we will put forward the idea that the designation gesture aims at singling out a sub-space of the overall space which has specific contrasting features. We thus propose a model for these contrasting features, which we name "singularities", providing us with, on the one hand, a way to take into account different patterns as potential designations, and, on the other hand, a solution for the resolution of possible ambiguities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Defining a singularity</head><p>The meaningful part of a gesture is characterized by two aspects: from the point of view of the surface expression, the gesture will have a particular shape which we will call singularity and from the point of view of meaning, the gesture shape may be associated with semantic component of an act of designation. A singularity is to be observed relative to an overall property of the trajectory (e.g. curvature) and relative to a specific segment of the trajectory which is considered as stable for this property. It is thus a local event. A complete analysis of a gesture should be carried out on all the possible properties and for the whole signal; the global meaning of the gesture is obtained by associating and combining the different singularities which have been detected. Indeed, the notion of singularity provides the means to relate the structure and the meaning of the gesture.</p><p>The main idea is to build a symbolic representation from the original structure of the trajectory within which singularities will be identified, with the underlying hypothesis that no singularity is accidental but results from the user's intention to mean something (e.g. to designate something). When really accidental singularities are encountered, they will be automatically eliminated at the interpretation stage, either because no linguistic expression may be associated to them or because they do not correspond to any object which could be contrasted. From a general perspective, three kinds of singularities may be distinguished: a) punctual singularities such as abrupt changes of directions corresponding to important variations in the curvature. These may correspond to the designation of the reduced areas where the curvature reaches its maximum; b) simple trajectory singularities such as a circling trajectory with straight segments at its ends; c) repetitive trajectory singularities which may be exemplified by the zigzag used to designate a whole region. They usually correspond to a combination of punctual singularities and trajectory segments which form a regular pattern.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Modelling the gestural trajectory</head><p>In order to be able to observe the different singularities, it is mandatory to achieve a proper modelling of the gestural trajectory. To do so, we have studied several kinds of properties, among which we may mention <ref type="bibr">[Bellalem,</ref><ref type="bibr">93]</ref>:</p><p>-the motion speed along the trajectory, -the different crossing points, -curvature, -device specific features (e.g. mouse). Figure <ref type="figure" target="#fig_2">2</ref> illustrates the structural analysis of the trajectory presented in our example. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Syntactic modelling</head><p>Segment (P 0 , P 1 ) Corner-point(P 1 ) Curve(P 1 , P 2 , C 1 ) Curve(P 2 , P 3 , C 2 ) Corner-poin(P 3 ) Segment(P 3 , P 4 ) P 0 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">Studying the meaningful elements</head><p>The second step in the structural analysis consists in recognizing, within the trajectory representation, the different singularities and to build up the global meaning represented by a proper association of these singularities. In the case of our example, this leads to two possible hypotheses corresponding to two different presences of the punctual and trajectory singularities observed in the gesture. The first one has preserved the information carried by the punctual singularities, whereas the second one stresses upon the partial circling (figure <ref type="figure">3</ref>). The ambiguity will only be resolved at the interpretation stage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Towards a contextual interpretation of gesture</head><p>This interpretation process in context poses the problem of obtaining a model of the visual space in order to take a proper account not only of the spatial layout of the different objects, but also of the different (spatial or functional) relations between the objects, since these may evolve depending on the kind of visualization which is being chosen (2D,3D). The final aim is to build a representation which is as close as possible to that which is considered by the human operator when uttering a referring expression. Among the different spatial relations that have to be considered, we may quote proximity and superposition, to which we may add some specific compositional relations (e.g. the fact that the living room is composed of tables, chairs etc.). Moreover, it is important to be able to deal with ambiguities resulting either from a possible imprecision in the gestural trajectory, from different possible spatial or functional configurations between objects or even from a difficulty in contrasting different candidates. The solution we have adopted is to manage a set of hypotheses which are ordered according to the likelihood of being designated in the context of a given demonstrative natural language expression. At this stage, we may mention the possible role of the dialogue context in the interpretation process. Until now, we have made the implicit assumption that the interpretation was made relatively to the complete graphical space presented to the user. However, it appeared to us that it is often relevant to constrain the interpretation of a multimodal referring expression to particular subspaces where objects may be contrasted. Such sub-spaces will typically correspond to stable working zones at a given step in the dialogue process and which may detected by means of different clues: referential expressions from preceding utterances, specific markers of intentional break (e.g. "Now, we turn to the living room"), markers of continuity, overall structure of the task (the decomposition of a flat into rooms etc.).</p><p>In our example, we suppose that such phenomena have been taken into account in describing the object structure given to the interpretation process. In the example, the utterance "place this armchair here", which contains both a demonstrative NP and a "pure" deictic, allows us to infer that the associated gesture is made of maximally two designating portions. The two hypotheses that we have put forward are thus valid since they both correspond to two such designations. The integration of these within the object universe leads to the following result for the first hypothesis (cf. figure <ref type="figure" target="#fig_4">4</ref>):</p><p>-the first designation leads to the selection of {armchair1}, -the second designation isolate the object {carpet}, For the second hypothesis, we have the following interpretation:</p><p>-the first designation selects the objects {armchair2, armchair1, sofa} in the order given by their likelihood of being designated by the gesture (depending upon different numerical criteria), -the second designation gives the same result as for hypothesis 1. The study of the demonstrative NP indicates that the candidate to be considered for the first designation is unique and is of the category "armchair". There again, both hypotheses remain valid since hypothesis 1 proposes armchair1 and hypothesis 2 armchair2. Consequently, we have to look again at the trajectory to differentiate the two. Indeed, we observe that hypothesis two may be favoured, considering that the corner point P1 may be integrated in the circling hypothesis since it is its beginning element whereas the circling shape cannot be explained and is thus not relevant if we consider that P1 is directly pointing at a localized area.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>The notion of singularity that we have introduced corresponds to a specific conception of gesture interpretation closely related to the dialogue system in which it is to be integrated. Indeed, it allows us to identify a close interaction between the gesture and the task as it is visualized on a graphical space. In addition, it provides a plausible account of linguistic information and of the overall process of dialogue management.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Designation gesture for an application to interior furnishing.</figDesc><graphic coords="3,162.72,499.78,226.77,184.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Modelling the gestural trajectory</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Final interpretation of the designation gesture</figDesc><graphic coords="6,96.38,217.25,226.77,184.25" type="bitmap" /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Le dialogue homme-machine multimodal, vers la compréhension du geste de désignation, Actes des 2èmes journées internationales, L&apos;interface des mondes réels et virtuels, Montpellier 22-26 Mars</title>
		<author>
			<persName><forename type="first">N</forename><surname>Bellalem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Romary</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="217" to="228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<author>
			<persName><forename type="first">J</forename><surname>Caelen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Garcin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wret</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Reynier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Actes du Workshop IHM&apos;91</title>
		<meeting>s du Workshop IHM&apos;91<address><addrLine>Dourdan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1991-12">December 1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">F</forename><surname>Corblin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Droz</forename><surname>Indéfini</surname></persName>
		</author>
		<imprint>
			<pubPlace>Genève-Paris</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Communications et langages gestuels, Les voies du langage</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cosnier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Berrendoner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Orecchioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications verbales gestuelles et animales</title>
		<imprint>
			<date type="published" when="1982">1982</date>
			<publisher>Edition Dunod-Bordas</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Références et gestion du dialogue, Actes de TALN&apos;94, Marseille Kleiber G., Y a-t-il un il ostensif ?</title>
		<author>
			<persName><forename type="first">B</forename><surname>Gaiffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Reboul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Romary</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Actas do XIX Congreso Internacional de Lingüística e Filoloxía Románicas</title>
		<meeting><address><addrLine>Lorenzo, A Coruña</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1989">1994. 1989. 1992</date>
		</imprint>
		<respStmt>
			<orgName>Universidade de Santiago de Compostela</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">An experimental study of future &quot;natural&quot; multimodal human-computer interaction, INTERCHI&apos;93</title>
		<author>
			<persName><forename type="first">C</forename><surname>Mignot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Valot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Carbonell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<pubPlace>Amsterdam</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Computing the meaning of localization expressions involving prepositions: the role of concepts and spatial context</title>
		<author>
			<persName><forename type="first">S</forename><surname>Pribbenow</surname></persName>
		</author>
		<editor>Mouton de Gruyter, Cornelia Zelinsky-Wibbelt</editor>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="441" to="470" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Mets ça ici&quot; où quand &quot;ici&quot; dépend de &quot;ça</title>
		<author>
			<persName><forename type="first">L</forename><surname>Romary</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">L&apos;interprétation de &quot;ici&quot; dans des énoncés de positionnement</title>
		<meeting><address><addrLine>Workshop Caen</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Frames, 1994, a unified model for the representation of reference and space in a Man-Machine Dialogue</title>
		<author>
			<persName><forename type="first">D</forename><surname>Schang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Romary</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Spoken Language Processing</title>
		<meeting><address><addrLine>Yokohama</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">User and discourse models for multimodal communication</title>
		<author>
			<persName><forename type="first">W</forename><surname>Wahlster</surname></persName>
		</author>
		<editor>J. Sullivan and S. Tymler</editor>
		<imprint>
			<date type="published" when="1991">1991</date>
			<publisher>Adisson-Wesley</publisher>
		</imprint>
	</monogr>
	<note>Intelligent user interface</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
