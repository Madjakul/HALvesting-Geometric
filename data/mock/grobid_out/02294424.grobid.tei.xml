<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Automatic Identification and Normalisation of Physical Measurements in Scientific Literature</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Luca</forename><surname>Foppiano</surname></persName>
							<email>foppiano.luca@nims.go.jp</email>
						</author>
						<author>
							<persName><forename type="first">Laurent</forename><surname>Romary</surname></persName>
							<email>laurent.romary@inria.fr</email>
						</author>
						<author>
							<persName><forename type="first">Masashi</forename><surname>Ishii</surname></persName>
							<email>ishii.masashi@nims.go.jp</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">National Institute for Materials Science (NIMS</orgName>
								<address>
									<settlement>Tsukuba</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<address>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">National Institute for Materials Science (NIMS</orgName>
								<address>
									<settlement>Tsukuba</settlement>
									<country>Japan Mikiko Tanifuji</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">National Institute for Materials Science (NIMS</orgName>
								<address>
									<settlement>Tsukuba</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Automatic Identification and Normalisation of Physical Measurements in Scientific Literature</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E74F9706491BF4AE10FE10B0D24714D7</idno>
					<idno type="DOI">10.1145/3342558.3345411</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.3" ident="GROBID" when="2023-08-24T14:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Machine Learning</term>
					<term>TDM</term>
					<term>Measurements</term>
					<term>Physical quantities</term>
					<term>Units of measurements</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present Grobid-quantities, an open-source application for extracting and normalising measurements from scientific and patent literature. Tools of this kind, aiming to understand and make unstructured information accessible, represent the building blocks for large-scale Text and Data Mining (TDM) systems. Grobid-quantities is a module built on top of Grobid [6]  [13], a machine learning framework for parsing and structuring PDF documents. Designed to process large quantities of data, it provides a robust implementation accessible in batch mode or via a REST API. The machine learning engine architecture follows the cascade approach, where each model is specialised in the resolution of a specific task. The models are trained using CRF (Conditional Random Field) algorithm <ref type="bibr" target="#b11">[12]</ref> for extracting quantities (atomic values, intervals and lists), units (such as length, weight) and different value representations (numeric, alphabetic or scientific notation). Identified measurements are normalised according to the International System of Units (SI). Thanks to its stable recall and reliable precision, Grobid-quantities has been integrated as the measurement-extraction engine in various TDM projects, such as Marve (Measurement Context Extraction from Text), for extracting semantic measurements and meaning in Earth Science <ref type="bibr" target="#b9">[10]</ref>. At the National Institute for Materials Science in Japan (NIMS), it is used in an ongoing project to discover new superconducting materials. Normalised materials characteristics (such as critical temperature, pressure) extracted from scientific literature are a key resource for materials informatics (MI) <ref type="bibr" target="#b8">[9]</ref>.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The data overflow in scientific publications makes rapid access to relevant information a challenging issue, for both researchers and readers. One of the essential element found in scientific literature is the physical quantity or measurement, which combine quantification of units (such as grams or micrometres) and quantified object or substances. The automatic extraction of measurements has been studied for many years. Nowadays, although the technology has been evolved, there are still several challenges to overcome: (1) natural language and writing style have varieties of expressions (for example length can be expressed as m, meter, metre). <ref type="bibr" target="#b1">(2)</ref> Overlaps between the different units of measurement (pico Henry inductance and acidity share the same notation, pH ). <ref type="bibr" target="#b2">(3)</ref> The physical quantities or measurements are scalable by accompanying units (e.g., 1 pl. = 453.6 g), meaning that value and unit combination and its normalisation are necessary for semantic recognition. The need for a precise automatic generation of databases from physical measurements is common to a wide range of domains.</p><p>In this paper, we present Grobid-quantities, an open-source application for identifying, parsing and normalising measurements from scientific and patent literature. Using Conditional Random Field (CRF) <ref type="bibr" target="#b11">[12]</ref>, it provides a machine learning framework for extracting information in a robust manner, and then normalise them toward the International System of Units (SI). This article is organised as follow. In Section 2 we introduce related work. Then, we describe the system in Section 3 and report its evaluation results in Sections 4. Use cases and future scopes are described in Section 5. Section 6 concludes this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Attempts to extract measurements from text have been made using rule-based (formal grammars engines, lookups in terminological databases) and ML approaches. A known commercial tool, Quantalyze 1 , was reported by <ref type="bibr" target="#b9">[10]</ref> showing weak recall and supporting only a limited subset of units <ref type="bibr" target="#b2">[3]</ref>. Another approach <ref type="bibr" target="#b0">[1]</ref>, using GATE (General Architecture for Text Engineering), addressed the identification of numeric properties from patents. <ref type="bibr" target="#b1">[2]</ref> investigated issues applied to Russian-derived languages. These approaches lack either the generalisation to an extensive corpus or deal mainly with specific languages. <ref type="bibr" target="#b3">[4]</ref> described an attempt to recognise units by looking up terms from an ontology, using ML in combination with pattern matching and string metrics. Other ML-based approaches exist, although limited to specific domains: <ref type="bibr" target="#b10">[11]</ref> and <ref type="bibr" target="#b7">[8]</ref> describe measurements extraction from experimental results in biology and nanocrystal device development, respectively. Our work is not restricted to a specific domain or subset of measurements and includes a normalisation process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">SYSTEM DESCRIPTION</head><p>Grobid-quantities is a Java web application, based on Grobid (Gen-eRation Of BIbliographic Data) <ref type="bibr" target="#b5">[6]</ref> [13], a machine learning framework for parsing and structuring raw documents such as PDF or plain text. Grobid-quantities is designed to process large quantity of data, via web, through a REST (Representation State Transfer) API or locally, via the file-system (batch mode). Output information are standardised as stand-off annotations, and they can be stored in databases or indexed in search engines. Each annotation can be visualised on top of PDFs using the GROBID build-in positional coordinates. The data model (Figure <ref type="figure" target="#fig_0">1</ref>) lay its foundation on the concept of Measurement, which links an object or a substance with one or more quantities. We defined four Measurements types: (a) atomic, in case of a single measurement (e.g., 10 grams). (b) interval (from 3 to 5 km) and (c) range (100 ± 4 mm) for continuous values, and, (d) a list of discrete values. A Quantity links the quantitative value and the unit. Since data extracted from PDFs unavoidably present irregular tokens from wrong UTF-8 encoding or missing fonts, we designed 1 https://www.quantalyze.com/ this model to allow partial results. The Value and Unit entities allow three different representations (Figure <ref type="figure" target="#fig_0">1</ref>): Raw as appear in input, Parsed unifies the value into the numerical expression, and the unit with its properties (system, type). Finally, Normalised contains the transformed unit and values to the SI system. Value object supports four types of representations: numeric (2, 1000), alphabetic (two, thousand), scientific notation (3 • 10 5 ), and time, which is also an expression of measurement. Units objects are organised following the SI, which allows representing units as products of simpler compounds (e.g. m/s to m • s -1 ) further decomposed as triples (prefix, base and power).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Architecture</head><p>The system takes in input text or PDF (the content is extracted in a structured way using the Grobid framework) and performs three steps: (a) tokenisation, (b) measurement extraction and parsing and (c) quantity normalisation. The details of each step are summarised as follows.   Table <ref type="table" target="#tab_0">1</ref> describes the labels predicted by the Quantities CRF model. Notice that, to reconstruct complex structured objects from the flat sequence generated by the engine, additional labels are necessary (such as &lt;unitLeft&gt;, &lt;unitRight&gt;, for units).</p><p>Previous work (Section 2) presented extensive use of databases or ontologies. In our solution, we used a similar approach. We created a list of units (in English, French and German) with their characteristics: system (SI base, SI derived, imperial, ...) and type Features in the Quantities CRF model are generated from preceding and following tokens, presence of capital, digits. Orthogonal features are obtained through the Unit Lexicon, like a Boolean indicating whether a token is a known unit or not. Typographical information (such as format, fonts, subscript and superscript) are ignored.</p><p>The Units CRF model works at character level and uses the Unit Lexicon to highlight known units or prefixes. The input tokens are parsed and transformed to a product of triples (prefix, base, power) as shown in Table <ref type="table" target="#tab_1">2</ref>. For example Kg/mm 2 , corresponds to Kд •mm -2 and becomes [(K, g, 1), (m, m, -2)] as product of triples. We then use the structured triples to fetch the corresponding information (system, type) from the Unit Lexicon and attach them to the resulting object. This implementation processes the unit characters using right-to-left order. Priority modifiers, such as parenthesis, are ignored. They are generally not frequent in units expressions, and require a more complex logic.</p><p>In parallel, the CRF Values model unifies the format of identified values into numerical formats. It supports four types: numeric, alphabetic, scientific notation, and time expression (see Table <ref type="table" target="#tab_2">3</ref>). Different techniques are applied for each type: alphabetic expressions are looked up in the word-to-number gazetteer, scientific notations are parsed and calculated mathematically. Time expressions are further segmented using the Grobid built-in Date CRF model. ). We used an external Java library called Units of Measurement <ref type="bibr" target="#b4">[5]</ref>, which provides a set of standard interfaces and implementations for safely handling units and quantities. Manipulating measurements with transformations often lead to common mistakes due to wrong rounding and approximations. At the time this paper is being written, the final revised version of this library has been accepted under the Java Standardisation Process JSR-385.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EVALUATION AND RESULTS</head><p>We trained and evaluated our system's models using a dataset based on 32 scientific publication (English, Open Access (OA)) and three patents (with translation in English, French and German) randomly selected from different domains such as medicine, robotics, astronomy, and physiology. The training data was generated automatically and then corrected and cross-checked by three annotators. We used 10-fold cross-validation to evaluate each CRF model, independently, and produce precision, recall and f1 scores, as summarised in Table <ref type="table" target="#tab_3">4</ref>.</p><p>The Quantities CRF model reported an f1 macro average of 80.14% with precision and recall of 84.93% and 76.86%, respectively. The paragraph accuracy was 68.97%, indicating that more than half of the evaluated paragraphs were correctly labelled. These scores are promising, considering the complexity of the task and the rather small size of the training corpus. In particular, &lt;list&gt; and &lt;unitRight&gt; require more example.</p><p>The Units CRF model f1 macro average was 98.86%, with precision and recall reaching 98.75% and 98.97%, respectively. Compared with our other models, performances were extremely high (more than 10% for f1 score). Such difference can be attributed to the data distribution and the lower variability of unit expressions. We analysed the training data, and we noticed that the distribution is biased toward simple units (composed by a single triple). Intuitively, this makes sense, because simple units are statistically more frequent; on the other hand, it highlights the necessity of having more complex examples in our dataset. Secondly, unit expressions appear, by nature, with lower variability, leading to the generation of more duplicates than in other models' training datasets. For example, the expressions 1% and 2% have two different values (1, 2) and the same unit (%), which would appear twice. Since we cannot alter the statistical distribution of the dataset, we would obtain better and more precise measurements of the model generalisation capabilities by using a separate and independent evaluation corpus. The Value CRF model scored average macro f1 at 85.64% with precision and recall at 81.82% and 93.29%, respectively. We noticed that both &lt;base&gt;, &lt;pow&gt; and &lt;time&gt; have lower f1-score. While &lt;base&gt; and &lt;pow&gt; require more training data, &lt;time&gt; expressions may overlap with &lt;number&gt; suggesting more contextual information should be introduced.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">APPLICATIONS</head><p>Recently, the normalised data extraction is strongly required in materials research. The inverse problem in which high-performance materials are predicted from properties is expected to be solved with well-organised big data. At the National Institute for Materials Science (NIMS), a project to discover new superconducting materials from scientific literature is in progress. The system being developed relies on Grobid-quantities to extract and normalise superconducting properties, such as critical temperature (Tc) with units of mK and K and critical pressure expressed with units of Pa, MPa, and GPa <ref type="bibr" target="#b8">[9]</ref>.</p><p>Grobid-quantities was showcased in a Text and Data Mining (TDM) platform (within the scope of the French national-wide ISTEX <ref type="bibr" target="#b6">[7]</ref> project) where it provided measurement annotations used to prototype a quantities-based semantic search 2 .</p><p>Finally, another use was made in a system for extracting semantic measurements and meaning in Earth Science, Marve <ref type="bibr" target="#b9">[10]</ref>. 2 The demo can be accessed at https://traces1.inria.fr/istex_sample/</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>In this paper, we presented Grobid-quantities, a system for extracting and normalising measurement from scientific and patent literature. The project, the training data and the documentation are accessible on Github 3 .</p><p>Results are promising, and the integration in real production platforms proved this application reached a certain level of maturity. Our dataset, although it requires more training examples, is released as open access and can be improved from external contributors. Moreover, as previously discussed, the introduction of an end to end evaluation corpus could provide more objective evaluation results.</p><p>In the future, we plan to introduce recurrent neural networks (RNN) and embeddings for sequence labelling. In particular, contextualised embeddings, trained with values and units could improve the model generalisation. Finally, we plan to integrate domain information and additional layout features (such as superscript/subscripts) to improve unit discrimination.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Schema of the data model.</figDesc><graphic coords="3,53.80,416.27,240.25,153.87" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>3. 2 . 1</head><label>21</label><figDesc>Tokenisation. This process splits input data into tokens. Grobidquantities uses a two-phase tokenisation: (1) first it splits by punctuation marks, then (2) each resulting token is re-tokenised to separate adjacent digits and alphanumeric characters. Given the example 25mˆ2, first returns a list [25m, ˆ, 2] and then recursively divides 25m as [25, m] resulting in [25, m, ˆ, 2].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>3. 2 . 2</head><label>22</label><figDesc>Extraction. The tokens are passed through three ML models, in cascade: first the Quantities CRF model determines appropriate unit and value tags. Results are further processed by the respective Units and Values CRF models as illustrated in Figure 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The cascade approach in applied CRF models. The Quantities model recognises value and units which are passed, respectively, to Values and Units CRF sub-models for further extraction.</figDesc><graphic coords="3,317.96,417.64,240.24,135.87" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Labels description for the Quantities CRF model. In bold are highlighted specific examples. , ...), and their representations: notations (m 3 , mˆ3), lemmas (cubic meter, cubic metre) and inflections (cubic meters, cubic metres). We made this list available through the Unit Lexicon, which offers unit lookups by properties (such as notation, lemma, inflexion). A second gazetteer was created to allow the transformation of alphabetic values in numeric ones (for example, twenty-one to 21).</figDesc><table><row><cell>Label</cell><cell>Description</cell><cell>Example</cell></row><row><cell cols="3">&lt;valueAtomic&gt; value of an atomic quantity 2 m</cell></row><row><cell>&lt;valueLeast&gt;</cell><cell>least value in an interval</cell><cell>from 2 m</cell></row><row><cell>&lt;valueMost&gt;</cell><cell>max value in an interval</cell><cell>up to 7 m</cell></row><row><cell>&lt;valueBase&gt;</cell><cell>base value in a range</cell><cell>20 ± 7 m</cell></row><row><cell>&lt;valueRange&gt;</cell><cell>range value in a range</cell><cell>20 ± 7 m</cell></row><row><cell>&lt;valueList&gt;</cell><cell>list of quantities</cell><cell>2, 3 and 10 m</cell></row><row><cell>&lt;unitLeft&gt;</cell><cell>left-attached unit</cell><cell>pH 2</cell></row><row><cell>&lt;unitRight&gt;</cell><cell>right-attached unit</cell><cell>2 m</cell></row><row><cell>&lt;other&gt;</cell><cell>everything else</cell><cell>-</cell></row><row><cell>(volume, length</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Labels description for the Units CRF model. In bold are highlighted specific examples.</figDesc><table><row><cell>Label</cell><cell>Description</cell><cell>Example</cell></row><row><cell cols="3">&lt;prefix&gt; prefix of the unit km 2</cell></row><row><cell>&lt;base&gt;</cell><cell>unit base</cell><cell>km 2</cell></row><row><cell>&lt;pow&gt;</cell><cell>unit power</cell><cell>km 2</cell></row><row><cell cols="2">&lt;other&gt; everything else</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Labels description for the Values CRF model. In bold are highlighted specific examples. The measurements extracted are transformed to the base SI unit (grams to kg, Celsius to Kelvin, etc.</figDesc><table><row><cell>Label</cell><cell>Description</cell><cell>Example</cell></row><row><cell cols="2">&lt;number&gt; numeric value / coefficient</cell><cell>2.5 • 10 5</cell></row><row><cell>&lt;alpha&gt;</cell><cell>alphabetic value</cell><cell>twenty</cell></row><row><cell>&lt;time&gt;</cell><cell>time expression</cell><cell>in 1970-01-02</cell></row><row><cell>&lt;base&gt;</cell><cell>base in scientific notation</cell><cell>2.5 • 10 5</cell></row><row><cell>&lt;pow&gt;</cell><cell cols="2">exponent in scientific notation 2.5 • 10 5</cell></row><row><cell>&lt;other&gt;</cell><cell>everything else</cell><cell>-</cell></row><row><cell cols="2">3.2.3 Normalisation.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Summary of the evaluation scores (precision, recall, F1-score) and label contribution (support) for Quantities, Units and Values CRF models, respectively.</figDesc><table><row><cell>Label</cell><cell cols="2">Precision Recall</cell><cell>F1</cell><cell>Support</cell></row><row><cell cols="4">Quantities CRF model</cell><cell></cell></row><row><cell>&lt;unitLeft&gt;</cell><cell>96.76</cell><cell cols="2">94.71 95.71</cell><cell>2805</cell></row><row><cell>&lt;unitRight&gt;</cell><cell>93.06</cell><cell>72.1</cell><cell>80.02</cell><cell>120</cell></row><row><cell>&lt;valueAtomic&gt;</cell><cell>85</cell><cell cols="2">84.77 84.84</cell><cell>3599</cell></row><row><cell>&lt;valueBase&gt;</cell><cell>78.82</cell><cell cols="2">76.52 77.53</cell><cell>94</cell></row><row><cell>&lt;valueLeast&gt;</cell><cell>85.05</cell><cell cols="2">77.39 80.94</cell><cell>862</cell></row><row><cell>&lt;valueList&gt;</cell><cell>72.09</cell><cell cols="2">54.87 61.33</cell><cell>494</cell></row><row><cell>&lt;valueMost&gt;</cell><cell>84.09</cell><cell cols="2">73.03 78.07</cell><cell>878</cell></row><row><cell>&lt;valueRange&gt;</cell><cell>84.56</cell><cell>81.5</cell><cell>82.68</cell><cell>93</cell></row><row><cell>all (macro avg.)</cell><cell>84.93</cell><cell cols="2">76.86 80.14</cell><cell></cell></row><row><cell></cell><cell cols="2">Unit CRF model</cell><cell></cell><cell></cell></row><row><cell>&lt;base&gt;</cell><cell>99.02</cell><cell cols="2">99.22 99.12</cell><cell>3075</cell></row><row><cell>&lt;pow&gt;</cell><cell>98.04</cell><cell>98.9</cell><cell>98.46</cell><cell>322</cell></row><row><cell>&lt;prefix&gt;</cell><cell>99.19</cell><cell>98.8</cell><cell>98.99</cell><cell>821</cell></row><row><cell>all (macro avg.)</cell><cell>98.75</cell><cell cols="2">98.97 98.86</cell><cell></cell></row><row><cell></cell><cell cols="2">Values CRF model</cell><cell></cell><cell></cell></row><row><cell>&lt;alpha&gt;</cell><cell>96.64</cell><cell cols="2">98.65 97.62</cell><cell>826</cell></row><row><cell>&lt;base&gt;</cell><cell>83.06</cell><cell cols="2">69.23 72.77</cell><cell>58</cell></row><row><cell>&lt;number&gt;</cell><cell>98.01</cell><cell cols="2">99.02 98.52</cell><cell>3858</cell></row><row><cell>&lt;pow&gt;</cell><cell>76.45</cell><cell cols="2">74.67 74.58</cell><cell>56</cell></row><row><cell>&lt;time&gt;</cell><cell>72.54</cell><cell cols="2">87.83 79.34</cell><cell>322</cell></row><row><cell>all (macro avg.)</cell><cell>85.34</cell><cell cols="2">85.88 84.57</cell><cell>-</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>Our warmest thanks to Patrice Lopez (author of Grobid and many other open-source TDM tools), who initiated and supported Grobidquantities. Thanks our colleagues at NIMS Thaer M. Dieb, and Akira Suzuki for the support received. Finally, thanks to Units of Measurements's contributors <ref type="bibr" target="#b3">4</ref> .</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Large-scale, parallel automatic patent annotation</title>
		<author>
			<persName><forename type="first">Milan</forename><surname>Agatonovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niraj</forename><surname>Aswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kalina</forename><surname>Bontcheva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamish</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Heitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaoyong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Valentin</forename><surname>Tablan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st ACM workshop on Patent information retrieval</title>
		<meeting>the 1st ACM workshop on Patent information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Processing of quantitative exPressions with units of measurement in scientific texts as aPPlied to Belarusian and russian text-to-sPeech synthesis</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Skopinava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Lobanov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Applications and Challenges of Text Mining with Patents</title>
		<author>
			<persName><forename type="first">Hidir</forename><surname>Aras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">René</forename><surname>Hackl-Sommer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Schwantner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mustafa</forename><surname>Sofean</surname></persName>
		</author>
		<editor>IPaMin@ KONVENS</editor>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">Lilia</forename><surname>Soumia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrice</forename><surname>Berrahou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juliette</forename><surname>Buche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mathieu</forename><surname>Dibie-Barthélemy</surname></persName>
		</author>
		<author>
			<persName><surname>Roche</surname></persName>
		</author>
		<title level="m">How to Extract Unit of Measure in Scientific Documents</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<ptr target="https://github.com/unitsofmeasurement" />
		<title level="m">Units of Measurement</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">GROBID (GeneRation Of BIbliographic Data</title>
		<ptr target="https://github.com/kermitt2/grobid.swh:1" />
		<imprint>
			<date type="published" when="2008">2008 -2019. 2008913</date>
		</imprint>
	</monogr>
	<note>d62e01e5bc967510500f80710</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">ISTEX: a powerful project for scientific and technical electronic resources archives</title>
		<author>
			<persName><forename type="first">André</forename><surname>Dazy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Insights</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Framework for automatic information extraction from research papers on nanocrystal devices</title>
		<author>
			<persName><forename type="first">Masaharu</forename><surname>Thaer M Dieb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shinjiro</forename><surname>Yoshioka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcus</forename><forename type="middle">C</forename><surname>Hara</surname></persName>
		</author>
		<author>
			<persName><surname>Newton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Beilstein journal of nanotechnology</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1872" to="1882" />
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Proposal for Automatic Extraction Framework of Superconductors Related Information from Scientific Literature</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Dieb</forename><surname>Luca Foppiano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akira</forename><surname>Thaer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Masashi</forename><surname>Suzuki</surname></persName>
		</author>
		<author>
			<persName><surname>Ishii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Letters and Technology News</title>
		<meeting><address><addrLine>Tsukuba</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
	<note>SC2019-1</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Measurement Context Extraction from Text: Discovering Opportunities and Gaps in Earth Science</title>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Hundman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><forename type="middle">A</forename><surname>Mattmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Extracting laboratory test information from biomedical text</title>
		<author>
			<persName><forename type="first">Yanna</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kang</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Mehmet</forename><surname>Kayaalp</surname></persName>
		</author>
		<idno type="DOI">10.4103/2153-3539.117450</idno>
		<ptr target="https://doi.org/10.4103/2153-3539.117450" />
	</analytic>
	<monogr>
		<title level="j">Journal of pathology informatics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="23" to="23" />
			<date type="published" when="2013-08">2013. Aug. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fernando Cn</forename><surname>Pereira</surname></persName>
		</author>
		<title level="m">Conditional random fields: Probabilistic models for segmenting and labeling sequence data</title>
		<imprint>
			<date type="published" when="2001">2001. 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">GROBID: Combining automatic bibliographic data recognition and term extraction for scholarship publications</title>
		<author>
			<persName><forename type="first">Patrice</forename><surname>Lopez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on theory and practice of digital libraries</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="473" to="474" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
